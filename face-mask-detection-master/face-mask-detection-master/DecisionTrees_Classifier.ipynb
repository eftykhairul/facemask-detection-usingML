{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Classifier (Mask, No Mask, Incorrect Mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics, Classifier and Graphing Packages\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "import seaborn as sns # for confusion matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # to plot image, graph\n",
    "\n",
    "import pickle\n",
    "import time # for computation time assessment\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FEATURES AND LABELS FROM PICKLE\n",
    "\n",
    "# Note: Pickles are mask, no mask, incorrect wear of mask dataset in grayscale\n",
    "# See data pre-processing for more information\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in) # 3D Feature set\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in) # 1D Target set\n",
    "\n",
    "pickle_in = open(\"data.pickle\", \"rb\")\n",
    "data = pickle.load(pickle_in) # 2-D Feature Set, Data matrix will serve as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Classification Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Samples: 17687\n",
      "# of Without A Mask: 5909\n",
      "# of Incorrectly Worn Mask: 5895\n",
      "# of With A Mask: 5883\n"
     ]
    }
   ],
   "source": [
    "# Dataset class distribution for mask, no mask, incorrect wear of mask\n",
    "\n",
    "print('# of Samples:', len(y))\n",
    "print('# of Without A Mask:', (y == 0).sum())\n",
    "print('# of Incorrectly Worn Mask:', (y == 1).sum())\n",
    "print('# of With A Mask:', (y == 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Numpy to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    P0   P1   P2   P3   P4   P5   P6   P7   P8   P9  ... P4086 P4087 P4088  \\\n",
      "0   20   21   19   22   29   31   37   51   54   37  ...   132   131   106   \n",
      "1  127  127  125  126   87   69   34   30   33   37  ...   141   156   156   \n",
      "2   48   43   37   34   34   40   49   83  100  106  ...    79    58    41   \n",
      "3  184   91   63   25   14   17   15   35   44   41  ...    84    86    53   \n",
      "4  111  125  126   97  109  140  168  185  166   91  ...   138    61    27   \n",
      "\n",
      "  P4089 P4090 P4091 P4092 P4093 P4094 P4095  \n",
      "0   158   125    43    24    21    21    34  \n",
      "1   149   150   149   145   125   115   103  \n",
      "2    21    14    19    22    23    20    21  \n",
      "3    17    13    13    14    11    13    15  \n",
      "4    35    30    38    34    45    54    48  \n",
      "\n",
      "[5 rows x 4096 columns]\n",
      "   Mask_Target\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n"
     ]
    }
   ],
   "source": [
    "# Get Column Names\n",
    "cols = []\n",
    "for i in range(0, len(data[0])):\n",
    "    cols.append(\"P\" + str(i))\n",
    "\n",
    "# Convert to Dataframe\n",
    "numpy_data = data\n",
    "X = pd.DataFrame(data=numpy_data, columns=[cols])\n",
    "print(X.head())\n",
    "\n",
    "y = pd.DataFrame(data=y, columns=[\"Mask_Target\"])\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Data Shape: (17687, 4096)\n",
      "Image Data Shape Features: (17687, 4096)\n",
      "Image Data Shape Target: (17687, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of Feature and Target Sets\n",
    "# There are 17,687 samples\n",
    "# See Data preprocessing for more information\n",
    "\n",
    "print('\\nImage Data Shape:', X.shape) # Feature sets are 64X64 images flatten to a 4096 feature vector\n",
    "print('Image Data Shape Features:', data.shape)\n",
    "print('Image Data Shape Target:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train + Test, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our Training data:  14149 \n",
      "Length of our Testing data:  3538\n"
     ]
    }
   ],
   "source": [
    "# Split our data into testing and training.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Print the length and width of our testing data.\n",
    "print('Length of our Training data: ', len(X_train), '\\nLength of our Testing data: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Classifier\n",
    "Build and Train Decision Trees model, No Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Trees model, No hyperparameter Tuning\n",
    "decision_trees = DecisionTreeClassifier()\n",
    "\n",
    "# Use training data to fit Decision Trees model\n",
    "decision_trees.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict Train Data Labels\n",
    "predictions_set = decision_trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67 ms, sys: 6.4 ms, total: 73.4 ms\n",
      "Wall time: 71.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict Train Data Labels\n",
    "predictions_set = decision_trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"predictions_set1_dt.pickle\", \"wb\")\n",
    "pickle.dump(predictions_set1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics, No Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Score: 0.828151498021481')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions_set)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score, No Hyperparameter Tuning: {0}'.format(accuracy_score(y_test, predictions_set))\n",
    "plt.title(title,size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Precision: 0.828\n"
     ]
    }
   ],
   "source": [
    "print('Decision Trees Precision: %.3f' % precision_score(y_test, predictions_set1, average='micro'))\n",
    "print('Decision Trees Recall: %.3f' % recall_score(y_test, predictions_set1, average='micro'))\n",
    "print('Decision Trees F1 Score: %.3f' % f1_score(y_test, predictions_set1, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RECALL\n",
    "# CLASS 0: NO MASK\n",
    "# CLASS 1: INCORRECT WEAR OF MASK\n",
    "# CLASS 2: CORRECT WEAR OF MASK\n",
    "\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, predictions_set1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(121.81862950297959, 214.57894736842104, 'X[1944] <= 0.351\\ngini = 0.667\\nsamples = 14149\\nvalue = [4731, 4715, 4703]'),\n",
       " Text(45.87494153549294, 208.85684210526315, 'X[3422] <= 0.512\\ngini = 0.371\\nsamples = 5018\\nvalue = [304, 3878, 836]'),\n",
       " Text(31.09707310422937, 203.13473684210527, 'X[2709] <= 0.686\\ngini = 0.631\\nsamples = 972\\nvalue = [224, 278, 470]'),\n",
       " Text(25.454869595310257, 197.41263157894736, 'X[3548] <= 0.686\\ngini = 0.566\\nsamples = 745\\nvalue = [223, 95, 427]'),\n",
       " Text(17.316333357802783, 191.69052631578947, 'X[1560] <= 0.265\\ngini = 0.523\\nsamples = 689\\nvalue = [222, 49, 418]'),\n",
       " Text(8.033205742630326, 185.96842105263158, 'X[3941] <= 0.261\\ngini = 0.528\\nsamples = 417\\nvalue = [190, 13, 214]'),\n",
       " Text(2.4717556131170233, 180.24631578947367, 'X[2333] <= 0.249\\ngini = 0.367\\nsamples = 158\\nvalue = [34, 3, 121]'),\n",
       " Text(0.8988202229516449, 174.52421052631578, 'X[3451] <= 0.963\\ngini = 0.033\\nsamples = 60\\nvalue = [1, 0, 59]'),\n",
       " Text(0.44941011147582244, 168.8021052631579, 'gini = 0.0\\nsamples = 59\\nvalue = [0, 0, 59]'),\n",
       " Text(1.3482303344274673, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(4.044691003282402, 174.52421052631578, 'X[1584] <= 0.253\\ngini = 0.485\\nsamples = 98\\nvalue = [33, 3, 62]'),\n",
       " Text(2.2470505573791124, 168.8021052631579, 'X[2512] <= 0.194\\ngini = 0.521\\nsamples = 53\\nvalue = [30, 2, 21]'),\n",
       " Text(1.3482303344274673, 163.07999999999998, 'X[2661] <= 0.659\\ngini = 0.153\\nsamples = 12\\nvalue = [1, 0, 11]'),\n",
       " Text(0.8988202229516449, 157.3578947368421, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(1.7976404459032898, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(3.145870780330757, 163.07999999999998, 'X[1326] <= 0.037\\ngini = 0.438\\nsamples = 41\\nvalue = [29, 2, 10]'),\n",
       " Text(2.6964606688549346, 157.3578947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(3.5952808918065795, 157.3578947368421, 'X[1453] <= 0.306\\ngini = 0.329\\nsamples = 36\\nvalue = [29, 2, 5]'),\n",
       " Text(2.6964606688549346, 151.6357894736842, 'X[2166] <= 0.614\\ngini = 0.121\\nsamples = 31\\nvalue = [29, 0, 2]'),\n",
       " Text(2.2470505573791124, 145.9136842105263, 'gini = 0.0\\nsamples = 29\\nvalue = [29, 0, 0]'),\n",
       " Text(3.145870780330757, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(4.494101114758225, 151.6357894736842, 'X[2561] <= 0.412\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 2, 3]'),\n",
       " Text(4.044691003282402, 145.9136842105263, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(4.943511226234047, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(5.842331449185692, 168.8021052631579, 'X[3638] <= 0.029\\ngini = 0.165\\nsamples = 45\\nvalue = [3, 1, 41]'),\n",
       " Text(4.943511226234047, 163.07999999999998, 'X[4053] <= 0.045\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(4.494101114758225, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(5.392921337709869, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(6.741151672137336, 163.07999999999998, 'X[1342] <= 0.022\\ngini = 0.089\\nsamples = 43\\nvalue = [2, 0, 41]'),\n",
       " Text(6.291741560661514, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(7.190561783613159, 157.3578947368421, 'X[2396] <= 0.239\\ngini = 0.046\\nsamples = 42\\nvalue = [1, 0, 41]'),\n",
       " Text(6.741151672137336, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(7.639971895088982, 151.6357894736842, 'gini = 0.0\\nsamples = 41\\nvalue = [0, 0, 41]'),\n",
       " Text(13.594655872143628, 180.24631578947367, 'X[1696] <= 0.294\\ngini = 0.507\\nsamples = 259\\nvalue = [156, 10, 93]'),\n",
       " Text(9.887022452468093, 174.52421052631578, 'X[3243] <= 0.457\\ngini = 0.439\\nsamples = 58\\nvalue = [14, 3, 41]'),\n",
       " Text(8.98820222951645, 168.8021052631579, 'X[1427] <= 0.28\\ngini = 0.561\\nsamples = 29\\nvalue = [14, 2, 13]'),\n",
       " Text(8.538792118040627, 163.07999999999998, 'X[1582] <= 0.212\\ngini = 0.46\\nsamples = 20\\nvalue = [14, 2, 4]'),\n",
       " Text(8.089382006564804, 157.3578947368421, 'gini = 0.0\\nsamples = 13\\nvalue = [13, 0, 0]'),\n",
       " Text(8.98820222951645, 157.3578947368421, 'X[2646] <= 0.378\\ngini = 0.571\\nsamples = 7\\nvalue = [1, 2, 4]'),\n",
       " Text(8.538792118040627, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(9.43761234099227, 151.6357894736842, 'X[217] <= 0.078\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(8.98820222951645, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(9.887022452468093, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(9.43761234099227, 163.07999999999998, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(10.785842675419739, 168.8021052631579, 'X[1917] <= 0.961\\ngini = 0.067\\nsamples = 29\\nvalue = [0, 1, 28]'),\n",
       " Text(10.336432563943916, 163.07999999999998, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 0, 28]'),\n",
       " Text(11.235252786895561, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(17.302289291819164, 174.52421052631578, 'X[2969] <= 0.518\\ngini = 0.433\\nsamples = 201\\nvalue = [142, 7, 52]'),\n",
       " Text(14.83053367870214, 168.8021052631579, 'X[1448] <= 0.425\\ngini = 0.36\\nsamples = 179\\nvalue = [139, 6, 34]'),\n",
       " Text(13.03289323279885, 163.07999999999998, 'X[2378] <= 0.784\\ngini = 0.266\\nsamples = 156\\nvalue = [132, 3, 21]'),\n",
       " Text(12.134073009847206, 157.3578947368421, 'X[2135] <= 0.704\\ngini = 0.206\\nsamples = 148\\nvalue = [131, 2, 15]'),\n",
       " Text(11.684662898371384, 151.6357894736842, 'X[2018] <= 0.276\\ngini = 0.166\\nsamples = 144\\nvalue = [131, 2, 11]'),\n",
       " Text(10.785842675419739, 145.9136842105263, 'X[1034] <= 0.18\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 2, 3]'),\n",
       " Text(10.336432563943916, 140.19157894736844, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(11.235252786895561, 140.19157894736844, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(12.583483121323027, 145.9136842105263, 'X[1613] <= 0.018\\ngini = 0.108\\nsamples = 139\\nvalue = [131, 0, 8]'),\n",
       " Text(12.134073009847206, 140.19157894736844, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(13.03289323279885, 140.19157894736844, 'X[647] <= 0.006\\ngini = 0.071\\nsamples = 136\\nvalue = [131, 0, 5]'),\n",
       " Text(12.134073009847206, 134.46947368421053, 'X[2175] <= 0.194\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(11.684662898371384, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(12.583483121323027, 128.7473684210526, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(13.931713455750495, 134.46947368421053, 'X[2087] <= 0.08\\ngini = 0.044\\nsamples = 133\\nvalue = [130, 0, 3]'),\n",
       " Text(13.482303344274673, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(14.381123567226318, 128.7473684210526, 'X[3877] <= 0.212\\ngini = 0.03\\nsamples = 132\\nvalue = [130, 0, 2]'),\n",
       " Text(13.931713455750495, 123.02526315789474, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(14.83053367870214, 123.02526315789474, 'X[1056] <= 0.206\\ngini = 0.015\\nsamples = 131\\nvalue = [130, 0, 1]'),\n",
       " Text(14.381123567226318, 117.30315789473684, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(15.279943790177963, 117.30315789473684, 'gini = 0.0\\nsamples = 130\\nvalue = [130, 0, 0]'),\n",
       " Text(12.583483121323027, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(13.931713455750495, 157.3578947368421, 'X[3649] <= 0.804\\ngini = 0.406\\nsamples = 8\\nvalue = [1, 1, 6]'),\n",
       " Text(13.482303344274673, 151.6357894736842, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(14.381123567226318, 151.6357894736842, 'X[1620] <= 0.092\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(13.931713455750495, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(14.83053367870214, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(16.62817412460543, 163.07999999999998, 'X[1196] <= 0.471\\ngini = 0.571\\nsamples = 23\\nvalue = [7, 3, 13]'),\n",
       " Text(15.729353901653786, 157.3578947368421, 'X[3611] <= 0.649\\ngini = 0.153\\nsamples = 12\\nvalue = [0, 1, 11]'),\n",
       " Text(15.279943790177963, 151.6357894736842, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(16.17876401312961, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(17.526994347557075, 157.3578947368421, 'X[1151] <= 0.547\\ngini = 0.529\\nsamples = 11\\nvalue = [7, 2, 2]'),\n",
       " Text(17.077584236081254, 151.6357894736842, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(17.9764044590329, 151.6357894736842, 'X[3993] <= 0.306\\ngini = 0.5\\nsamples = 4\\nvalue = [0, 2, 2]'),\n",
       " Text(17.526994347557075, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(18.42581457050872, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(19.774044904936186, 168.8021052631579, 'X[3488] <= 0.559\\ngini = 0.31\\nsamples = 22\\nvalue = [3, 1, 18]'),\n",
       " Text(18.87522468198454, 163.07999999999998, 'X[2506] <= 0.845\\ngini = 0.1\\nsamples = 19\\nvalue = [1, 0, 18]'),\n",
       " Text(18.42581457050872, 157.3578947368421, 'gini = 0.0\\nsamples = 18\\nvalue = [0, 0, 18]'),\n",
       " Text(19.324634793460366, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(20.67286512788783, 163.07999999999998, 'X[972] <= 0.169\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(20.22345501641201, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(21.122275239363656, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(26.59946097297524, 185.96842105263158, 'X[1896] <= 0.19\\ngini = 0.406\\nsamples = 272\\nvalue = [32, 36, 204]'),\n",
       " Text(23.369325796742768, 180.24631578947367, 'X[3483] <= 0.269\\ngini = 0.499\\nsamples = 56\\nvalue = [0, 27, 29]'),\n",
       " Text(22.919915685266943, 174.52421052631578, 'gini = 0.0\\nsamples = 19\\nvalue = [0, 0, 19]'),\n",
       " Text(23.81873590821859, 174.52421052631578, 'X[577] <= 0.157\\ngini = 0.394\\nsamples = 37\\nvalue = [0, 27, 10]'),\n",
       " Text(22.919915685266943, 168.8021052631579, 'X[328] <= 0.069\\ngini = 0.375\\nsamples = 12\\nvalue = [0, 3, 9]'),\n",
       " Text(22.470505573791122, 163.07999999999998, 'X[526] <= 0.463\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(22.021095462315298, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(22.919915685266943, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(23.369325796742768, 163.07999999999998, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(24.717556131170234, 168.8021052631579, 'X[767] <= 0.996\\ngini = 0.077\\nsamples = 25\\nvalue = [0, 24, 1]'),\n",
       " Text(24.268146019694413, 163.07999999999998, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 24, 0]'),\n",
       " Text(25.166966242646055, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(29.829596149207713, 180.24631578947367, 'X[3750] <= 0.355\\ngini = 0.32\\nsamples = 216\\nvalue = [32, 9, 175]'),\n",
       " Text(27.41401680002517, 174.52421052631578, 'X[2712] <= 0.733\\ngini = 0.109\\nsamples = 105\\nvalue = [4, 2, 99]'),\n",
       " Text(26.964606688549345, 168.8021052631579, 'X[916] <= 0.198\\ngini = 0.075\\nsamples = 103\\nvalue = [4, 0, 99]'),\n",
       " Text(26.0657864655977, 163.07999999999998, 'X[2350] <= 0.557\\ngini = 0.49\\nsamples = 7\\nvalue = [3, 0, 4]'),\n",
       " Text(25.61637635412188, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(26.515196577073525, 157.3578947368421, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(27.86342691150099, 163.07999999999998, 'X[1684] <= 0.733\\ngini = 0.021\\nsamples = 96\\nvalue = [1, 0, 95]'),\n",
       " Text(27.41401680002517, 157.3578947368421, 'gini = 0.0\\nsamples = 94\\nvalue = [0, 0, 94]'),\n",
       " Text(28.312837022976815, 157.3578947368421, 'X[1447] <= 0.61\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(27.86342691150099, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(28.762247134452636, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(27.86342691150099, 168.8021052631579, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(32.24517549839026, 174.52421052631578, 'X[2587] <= 0.429\\ngini = 0.464\\nsamples = 111\\nvalue = [28, 7, 76]'),\n",
       " Text(30.110477468880102, 168.8021052631579, 'X[1640] <= 0.461\\ngini = 0.5\\nsamples = 49\\nvalue = [24, 0, 25]'),\n",
       " Text(29.66106735740428, 163.07999999999998, 'X[2135] <= 0.245\\ngini = 0.397\\nsamples = 33\\nvalue = [24, 0, 9]'),\n",
       " Text(29.211657245928457, 157.3578947368421, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(30.110477468880102, 157.3578947368421, 'X[1999] <= 0.235\\ngini = 0.198\\nsamples = 27\\nvalue = [24, 0, 3]'),\n",
       " Text(29.66106735740428, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(30.559887580355927, 151.6357894736842, 'gini = 0.0\\nsamples = 24\\nvalue = [24, 0, 0]'),\n",
       " Text(30.559887580355927, 163.07999999999998, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 0, 16]'),\n",
       " Text(34.379873527900415, 168.8021052631579, 'X[3165] <= 0.598\\ngini = 0.306\\nsamples = 62\\nvalue = [4, 7, 51]'),\n",
       " Text(32.80693813773504, 163.07999999999998, 'X[37] <= 0.067\\ngini = 0.172\\nsamples = 54\\nvalue = [3, 2, 49]'),\n",
       " Text(31.908117914783393, 157.3578947368421, 'X[2094] <= 0.641\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(31.458707803307572, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(32.35752802625922, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(33.70575836068668, 157.3578947368421, 'X[3551] <= 0.208\\ngini = 0.076\\nsamples = 51\\nvalue = [1, 1, 49]'),\n",
       " Text(33.25634824921086, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(34.15516847216251, 151.6357894736842, 'X[2988] <= 0.165\\ngini = 0.039\\nsamples = 50\\nvalue = [0, 1, 49]'),\n",
       " Text(33.70575836068668, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(34.60457858363833, 145.9136842105263, 'gini = 0.0\\nsamples = 49\\nvalue = [0, 0, 49]'),\n",
       " Text(35.9528089180658, 163.07999999999998, 'X[2538] <= 0.527\\ngini = 0.531\\nsamples = 8\\nvalue = [1, 5, 2]'),\n",
       " Text(35.50339880658997, 157.3578947368421, 'X[3294] <= 0.649\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(35.05398869511415, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(35.9528089180658, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(36.40221902954162, 157.3578947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(33.59340583281773, 191.69052631578947, 'X[2023] <= 0.688\\ngini = 0.299\\nsamples = 56\\nvalue = [1, 46, 9]'),\n",
       " Text(33.1439957213419, 185.96842105263158, 'X[3493] <= 0.196\\ngini = 0.15\\nsamples = 50\\nvalue = [1, 46, 3]'),\n",
       " Text(32.69458560986608, 180.24631578947367, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(33.59340583281773, 180.24631578947367, 'X[1316] <= 0.092\\ngini = 0.042\\nsamples = 47\\nvalue = [1, 46, 0]'),\n",
       " Text(33.1439957213419, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(34.04281594429355, 174.52421052631578, 'gini = 0.0\\nsamples = 46\\nvalue = [0, 46, 0]'),\n",
       " Text(34.04281594429355, 185.96842105263158, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(36.73927661314848, 197.41263157894736, 'X[2794] <= 0.69\\ngini = 0.314\\nsamples = 227\\nvalue = [1, 183, 43]'),\n",
       " Text(35.391046278721014, 191.69052631578947, 'X[3171] <= 0.608\\ngini = 0.343\\nsamples = 47\\nvalue = [1, 9, 37]'),\n",
       " Text(34.94163616724519, 185.96842105263158, 'gini = 0.0\\nsamples = 31\\nvalue = [0, 0, 31]'),\n",
       " Text(35.84045639019684, 185.96842105263158, 'X[3811] <= 0.51\\ngini = 0.539\\nsamples = 16\\nvalue = [1, 9, 6]'),\n",
       " Text(35.391046278721014, 180.24631578947367, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9, 0]'),\n",
       " Text(36.28986650167266, 180.24631578947367, 'X[1418] <= 0.318\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 0, 6]'),\n",
       " Text(35.84045639019684, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(36.73927661314848, 174.52421052631578, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(38.08750694757595, 191.69052631578947, 'X[3234] <= 0.788\\ngini = 0.064\\nsamples = 180\\nvalue = [0, 174, 6]'),\n",
       " Text(37.63809683610013, 185.96842105263158, 'X[2612] <= 0.004\\ngini = 0.033\\nsamples = 177\\nvalue = [0, 174, 3]'),\n",
       " Text(37.188686724624304, 180.24631578947367, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(38.08750694757595, 180.24631578947367, 'X[3769] <= 0.008\\ngini = 0.011\\nsamples = 175\\nvalue = [0, 174, 1]'),\n",
       " Text(37.63809683610013, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(38.536917059051774, 174.52421052631578, 'gini = 0.0\\nsamples = 174\\nvalue = [0, 174, 0]'),\n",
       " Text(38.536917059051774, 185.96842105263158, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(60.65280996675651, 203.13473684210527, 'X[1959] <= 0.457\\ngini = 0.2\\nsamples = 4046\\nvalue = [80, 3600, 366]'),\n",
       " Text(53.19189991295867, 197.41263157894736, 'X[3489] <= 0.814\\ngini = 0.108\\nsamples = 3579\\nvalue = [40, 3376, 163]'),\n",
       " Text(48.466071709470725, 191.69052631578947, 'X[1510] <= 0.273\\ngini = 0.093\\nsamples = 3522\\nvalue = [37, 3352, 133]'),\n",
       " Text(43.873662132827164, 185.96842105263158, 'X[3041] <= 0.735\\ngini = 0.398\\nsamples = 366\\nvalue = [31, 276, 59]'),\n",
       " Text(40.67161508856193, 180.24631578947367, 'X[804] <= 0.271\\ngini = 0.653\\nsamples = 125\\nvalue = [30, 46, 49]'),\n",
       " Text(39.435737282003416, 174.52421052631578, 'X[2528] <= 0.18\\ngini = 0.175\\nsamples = 31\\nvalue = [0, 28, 3]'),\n",
       " Text(38.986327170527595, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(39.885147393479244, 168.8021052631579, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 28, 0]'),\n",
       " Text(41.90749289512044, 174.52421052631578, 'X[1696] <= 0.463\\ngini = 0.622\\nsamples = 94\\nvalue = [30, 18, 46]'),\n",
       " Text(40.783967616430886, 168.8021052631579, 'X[3426] <= 0.718\\ngini = 0.499\\nsamples = 55\\nvalue = [5, 14, 36]'),\n",
       " Text(39.885147393479244, 163.07999999999998, 'X[3094] <= 0.245\\ngini = 0.234\\nsamples = 38\\nvalue = [4, 1, 33]'),\n",
       " Text(39.435737282003416, 157.3578947368421, 'X[2387] <= 0.482\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 1, 0]'),\n",
       " Text(38.986327170527595, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(39.885147393479244, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(40.334557504955065, 157.3578947368421, 'gini = 0.0\\nsamples = 33\\nvalue = [0, 0, 33]'),\n",
       " Text(41.682787839382534, 163.07999999999998, 'X[2065] <= 0.267\\ngini = 0.381\\nsamples = 17\\nvalue = [1, 13, 3]'),\n",
       " Text(41.233377727906706, 157.3578947368421, 'X[4001] <= 0.231\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(40.783967616430886, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(41.682787839382534, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(42.132197950858355, 157.3578947368421, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 13, 0]'),\n",
       " Text(43.03101817381, 168.8021052631579, 'X[1644] <= 0.159\\ngini = 0.513\\nsamples = 39\\nvalue = [25, 4, 10]'),\n",
       " Text(42.581608062334176, 163.07999999999998, 'gini = 0.0\\nsamples = 21\\nvalue = [21, 0, 0]'),\n",
       " Text(43.48042828528582, 163.07999999999998, 'X[1324] <= 0.58\\ngini = 0.593\\nsamples = 18\\nvalue = [4, 4, 10]'),\n",
       " Text(43.03101817381, 157.3578947368421, 'X[3484] <= 0.616\\ngini = 0.408\\nsamples = 14\\nvalue = [4, 0, 10]'),\n",
       " Text(42.581608062334176, 151.6357894736842, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(43.48042828528582, 151.6357894736842, 'X[1296] <= 0.498\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(43.03101817381, 145.9136842105263, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(43.929838396761646, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(43.929838396761646, 157.3578947368421, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(47.0757091770924, 180.24631578947367, 'X[2594] <= 0.869\\ngini = 0.087\\nsamples = 241\\nvalue = [1, 230, 10]'),\n",
       " Text(46.17688895414076, 174.52421052631578, 'X[2216] <= 0.912\\ngini = 0.05\\nsamples = 235\\nvalue = [1, 229, 5]'),\n",
       " Text(45.72747884266494, 168.8021052631579, 'X[3045] <= 0.902\\ngini = 0.034\\nsamples = 233\\nvalue = [1, 229, 3]'),\n",
       " Text(45.27806873118911, 163.07999999999998, 'X[3163] <= 0.363\\ngini = 0.026\\nsamples = 232\\nvalue = [0, 229, 3]'),\n",
       " Text(44.82865861971329, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(45.72747884266494, 157.3578947368421, 'X[3300] <= 0.818\\ngini = 0.017\\nsamples = 231\\nvalue = [0, 229, 2]'),\n",
       " Text(45.27806873118911, 151.6357894736842, 'X[3391] <= 0.004\\ngini = 0.009\\nsamples = 230\\nvalue = [0, 229, 1]'),\n",
       " Text(44.82865861971329, 145.9136842105263, 'X[2291] <= 0.129\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(44.37924850823747, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(45.27806873118911, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(45.72747884266494, 145.9136842105263, 'gini = 0.0\\nsamples = 228\\nvalue = [0, 228, 0]'),\n",
       " Text(46.17688895414076, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(46.17688895414076, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(46.62629906561658, 168.8021052631579, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(47.97452940004405, 174.52421052631578, 'X[3976] <= 0.637\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 1, 5]'),\n",
       " Text(47.52511928856822, 168.8021052631579, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(48.42393951151987, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(53.05848128611429, 185.96842105263158, 'X[3035] <= 0.918\\ngini = 0.05\\nsamples = 3156\\nvalue = [6, 3076, 74]'),\n",
       " Text(52.159661063162645, 180.24631578947367, 'X[2792] <= 0.959\\ngini = 0.045\\nsamples = 3147\\nvalue = [6, 3075, 66]'),\n",
       " Text(51.71025095168682, 174.52421052631578, 'X[3424] <= 0.531\\ngini = 0.041\\nsamples = 3141\\nvalue = [6, 3075, 60]'),\n",
       " Text(49.32275973447151, 168.8021052631579, 'X[2539] <= 0.551\\ngini = 0.386\\nsamples = 90\\nvalue = [1, 67, 22]'),\n",
       " Text(48.42393951151987, 163.07999999999998, 'X[3046] <= 0.39\\ngini = 0.41\\nsamples = 19\\nvalue = [1, 4, 14]'),\n",
       " Text(47.97452940004405, 157.3578947368421, 'X[3451] <= 0.886\\ngini = 0.5\\nsamples = 6\\nvalue = [1, 4, 1]'),\n",
       " Text(47.52511928856822, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(48.42393951151987, 151.6357894736842, 'X[3049] <= 0.312\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(47.97452940004405, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(48.87334962299569, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(48.87334962299569, 157.3578947368421, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(50.22157995742316, 163.07999999999998, 'X[2665] <= 0.837\\ngini = 0.2\\nsamples = 71\\nvalue = [0, 63, 8]'),\n",
       " Text(49.77216984594733, 157.3578947368421, 'X[2655] <= 0.31\\ngini = 0.087\\nsamples = 66\\nvalue = [0, 63, 3]'),\n",
       " Text(49.32275973447151, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(50.22157995742316, 151.6357894736842, 'X[1629] <= 0.314\\ngini = 0.031\\nsamples = 64\\nvalue = [0, 63, 1]'),\n",
       " Text(49.77216984594733, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(50.67099006889898, 145.9136842105263, 'gini = 0.0\\nsamples = 63\\nvalue = [0, 63, 0]'),\n",
       " Text(50.67099006889898, 157.3578947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(54.09774216890212, 168.8021052631579, 'X[2919] <= 0.033\\ngini = 0.028\\nsamples = 3051\\nvalue = [5, 3008, 38]'),\n",
       " Text(52.69333557054018, 163.07999999999998, 'X[1121] <= 0.604\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(52.24392545906436, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(53.142745682016006, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(55.502148767264075, 163.07999999999998, 'X[3109] <= 0.916\\ngini = 0.027\\nsamples = 3048\\nvalue = [5, 3007, 36]'),\n",
       " Text(54.04156590496765, 157.3578947368421, 'X[1499] <= 0.257\\ngini = 0.025\\nsamples = 3045\\nvalue = [5, 3006, 34]'),\n",
       " Text(52.46863051480227, 151.6357894736842, 'X[1944] <= 0.253\\ngini = 0.238\\nsamples = 89\\nvalue = [2, 77, 10]'),\n",
       " Text(51.56981029185062, 145.9136842105263, 'X[3426] <= 0.837\\ngini = 0.027\\nsamples = 72\\nvalue = [0, 71, 1]'),\n",
       " Text(51.1204001803748, 140.19157894736844, 'gini = 0.0\\nsamples = 71\\nvalue = [0, 71, 0]'),\n",
       " Text(52.01922040332645, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(53.36745073775391, 145.9136842105263, 'X[1834] <= 0.302\\ngini = 0.581\\nsamples = 17\\nvalue = [2, 6, 9]'),\n",
       " Text(52.91804062627809, 140.19157894736844, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(53.816860849229734, 140.19157894736844, 'X[2660] <= 0.375\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 6, 0]'),\n",
       " Text(53.36745073775391, 134.46947368421053, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(54.26627096070556, 134.46947368421053, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(55.614501295133024, 151.6357894736842, 'X[2137] <= 0.004\\ngini = 0.018\\nsamples = 2956\\nvalue = [3, 2929, 24]'),\n",
       " Text(55.1650911836572, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(56.06391140660885, 145.9136842105263, 'X[1891] <= 0.976\\ngini = 0.017\\nsamples = 2955\\nvalue = [3, 2929, 23]'),\n",
       " Text(55.614501295133024, 140.19157894736844, 'X[3234] <= 0.929\\ngini = 0.017\\nsamples = 2954\\nvalue = [3, 2929, 22]'),\n",
       " Text(55.1650911836572, 134.46947368421053, 'X[1642] <= 0.016\\ngini = 0.016\\nsamples = 2953\\nvalue = [3, 2929, 21]'),\n",
       " Text(54.71568107218138, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(55.614501295133024, 128.7473684210526, 'X[3165] <= 0.496\\ngini = 0.015\\nsamples = 2952\\nvalue = [3, 2929, 20]'),\n",
       " Text(53.592594670553815, 123.02526315789474, 'X[1959] <= 0.404\\ngini = 0.133\\nsamples = 155\\nvalue = [2, 144, 9]'),\n",
       " Text(52.693774447602166, 117.30315789473684, 'X[2520] <= 0.853\\ngini = 0.079\\nsamples = 146\\nvalue = [1, 140, 5]'),\n",
       " Text(52.244364336126345, 111.58105263157894, 'X[1822] <= 0.851\\ngini = 0.054\\nsamples = 144\\nvalue = [1, 140, 3]'),\n",
       " Text(51.794954224650525, 105.85894736842106, 'X[2787] <= 0.898\\ngini = 0.041\\nsamples = 143\\nvalue = [0, 140, 3]'),\n",
       " Text(51.345544113174704, 100.13684210526316, 'X[1762] <= 0.084\\ngini = 0.028\\nsamples = 142\\nvalue = [0, 140, 2]'),\n",
       " Text(50.896134001698876, 94.41473684210527, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(51.794954224650525, 94.41473684210527, 'X[575] <= 0.006\\ngini = 0.014\\nsamples = 141\\nvalue = [0, 140, 1]'),\n",
       " Text(51.345544113174704, 88.69263157894736, 'X[1224] <= 0.42\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(50.896134001698876, 82.97052631578947, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(51.794954224650525, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.244364336126345, 88.69263157894736, 'gini = 0.0\\nsamples = 138\\nvalue = [0, 138, 0]'),\n",
       " Text(52.244364336126345, 100.13684210526316, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.693774447602166, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(53.143184559077994, 111.58105263157894, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(54.49141489350546, 117.30315789473684, 'X[3872] <= 0.445\\ngini = 0.593\\nsamples = 9\\nvalue = [1, 4, 4]'),\n",
       " Text(54.042004782029636, 111.58105263157894, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(54.94082500498128, 111.58105263157894, 'X[2627] <= 0.531\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(54.49141489350546, 105.85894736842106, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(55.390235116457106, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(57.63640791971224, 123.02526315789474, 'X[1507] <= 0.055\\ngini = 0.009\\nsamples = 2797\\nvalue = [1, 2785, 11]'),\n",
       " Text(56.28905533940875, 117.30315789473684, 'X[2206] <= 0.667\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(55.83964522793293, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(56.73846545088457, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(58.983760500015734, 117.30315789473684, 'X[3488] <= 0.063\\ngini = 0.008\\nsamples = 2795\\nvalue = [0, 2784, 11]'),\n",
       " Text(57.63728567383622, 111.58105263157894, 'X[822] <= 0.271\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(57.1878755623604, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(58.08669578531204, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(60.33023532619524, 111.58105263157894, 'X[3428] <= 0.892\\ngini = 0.007\\nsamples = 2793\\nvalue = [0, 2783, 10]'),\n",
       " Text(58.98551600826368, 105.85894736842106, 'X[3167] <= 0.284\\ngini = 0.006\\nsamples = 2791\\nvalue = [0, 2782, 9]'),\n",
       " Text(57.64430770682802, 100.13684210526316, 'X[739] <= 0.678\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(57.1948975953522, 94.41473684210527, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(58.09371781830385, 94.41473684210527, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(60.326724309699344, 100.13684210526316, 'X[3390] <= 0.002\\ngini = 0.006\\nsamples = 2788\\nvalue = [0, 2780, 8]'),\n",
       " Text(58.99253804125549, 94.41473684210527, 'X[2937] <= 0.545\\ngini = 0.231\\nsamples = 15\\nvalue = [0, 13, 2]'),\n",
       " Text(58.54312792977967, 88.69263157894736, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 13, 0]'),\n",
       " Text(59.441948152731314, 88.69263157894736, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(61.66091057814319, 94.41473684210527, 'X[1899] <= 0.006\\ngini = 0.004\\nsamples = 2773\\nvalue = [0, 2767, 6]'),\n",
       " Text(60.34076837568296, 88.69263157894736, 'X[749] <= 0.361\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(59.891358264207135, 82.97052631578947, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(60.790178487158784, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(62.98105278060342, 88.69263157894736, 'X[1959] <= 0.453\\ngini = 0.004\\nsamples = 2769\\nvalue = [0, 2764, 5]'),\n",
       " Text(61.688998710110425, 82.97052631578947, 'X[2828] <= 0.002\\ngini = 0.003\\nsamples = 2765\\nvalue = [0, 2761, 4]'),\n",
       " Text(60.45312090355191, 77.24842105263158, 'X[3259] <= 0.561\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 6, 1]'),\n",
       " Text(60.00371079207609, 71.5263157894737, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(60.90253101502774, 71.5263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(62.92487651666894, 77.24842105263158, 'X[2770] <= 0.941\\ngini = 0.002\\nsamples = 2758\\nvalue = [0, 2755, 3]'),\n",
       " Text(61.80135123797938, 71.5263157894737, 'X[1382] <= 0.096\\ngini = 0.001\\nsamples = 2750\\nvalue = [0, 2748, 2]'),\n",
       " Text(60.90253101502774, 65.80421052631579, 'X[788] <= 0.433\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 8, 1]'),\n",
       " Text(60.45312090355191, 60.0821052631579, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(61.35194112650356, 60.0821052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(62.70017146093103, 65.80421052631579, 'X[3117] <= 0.971\\ngini = 0.001\\nsamples = 2741\\nvalue = [0, 2740, 1]'),\n",
       " Text(62.2507613494552, 60.0821052631579, 'gini = 0.0\\nsamples = 2731\\nvalue = [0, 2731, 0]'),\n",
       " Text(63.14958157240685, 60.0821052631579, 'X[14] <= 0.849\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 9, 1]'),\n",
       " Text(62.70017146093103, 54.360000000000014, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9, 0]'),\n",
       " Text(63.59899168388267, 54.360000000000014, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(64.0484017953585, 71.5263157894737, 'X[3424] <= 0.622\\ngini = 0.219\\nsamples = 8\\nvalue = [0, 7, 1]'),\n",
       " Text(63.59899168388267, 65.80421052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(64.49781190683431, 65.80421052631579, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(64.2731068510964, 82.97052631578947, 'X[2558] <= 0.204\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(63.82369673962059, 77.24842105263158, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(64.72251696257223, 77.24842105263158, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(61.67495464412681, 105.85894736842106, 'X[3766] <= 0.547\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(61.225544532650986, 100.13684210526316, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(62.12436475560263, 100.13684210526316, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(56.06391140660885, 134.46947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(56.51332151808467, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(56.962731629560494, 157.3578947368421, 'X[1904] <= 0.775\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(56.51332151808467, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(57.412141741036315, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(52.609071174638466, 174.52421052631578, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(53.95730150906593, 180.24631578947367, 'X[735] <= 0.247\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 1, 8]'),\n",
       " Text(53.50789139759011, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(54.406711620541756, 174.52421052631578, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(57.91772811644662, 191.69052631578947, 'X[3171] <= 0.786\\ngini = 0.543\\nsamples = 57\\nvalue = [3, 24, 30]'),\n",
       " Text(56.79420283775706, 185.96842105263158, 'X[2283] <= 0.527\\ngini = 0.395\\nsamples = 29\\nvalue = [3, 22, 4]'),\n",
       " Text(55.89538261480541, 180.24631578947367, 'X[1277] <= 0.527\\ngini = 0.612\\nsamples = 7\\nvalue = [3, 1, 3]'),\n",
       " Text(55.44597250332959, 174.52421052631578, 'X[3600] <= 0.314\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(54.99656239185377, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(55.89538261480541, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(56.34479272628124, 174.52421052631578, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(57.693023060708704, 180.24631578947367, 'X[2928] <= 0.929\\ngini = 0.087\\nsamples = 22\\nvalue = [0, 21, 1]'),\n",
       " Text(57.24361294923288, 174.52421052631578, 'gini = 0.0\\nsamples = 21\\nvalue = [0, 21, 0]'),\n",
       " Text(58.142433172184525, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(59.041253395136174, 185.96842105263158, 'X[990] <= 0.265\\ngini = 0.133\\nsamples = 28\\nvalue = [0, 2, 26]'),\n",
       " Text(58.59184328366035, 180.24631578947367, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(59.490663506611995, 180.24631578947367, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(68.11372002055434, 197.41263157894736, 'X[1896] <= 0.351\\ngini = 0.574\\nsamples = 467\\nvalue = [40, 224, 203]'),\n",
       " Text(63.31064945415648, 191.69052631578947, 'X[1768] <= 0.318\\ngini = 0.253\\nsamples = 181\\nvalue = [6, 155, 20]'),\n",
       " Text(61.288303952515285, 185.96842105263158, 'X[2721] <= 0.602\\ngini = 0.598\\nsamples = 41\\nvalue = [5, 19, 17]'),\n",
       " Text(60.38948372956364, 180.24631578947367, 'X[3365] <= 0.655\\ngini = 0.322\\nsamples = 21\\nvalue = [3, 17, 1]'),\n",
       " Text(59.940073618087816, 174.52421052631578, 'X[504] <= 0.296\\ngini = 0.56\\nsamples = 5\\nvalue = [3, 1, 1]'),\n",
       " Text(59.490663506611995, 168.8021052631579, 'X[1620] <= 0.678\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(59.041253395136174, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(59.940073618087816, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(60.38948372956364, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(60.838893841039464, 174.52421052631578, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 16, 0]'),\n",
       " Text(62.18712417546693, 180.24631578947367, 'X[1791] <= 0.241\\ngini = 0.34\\nsamples = 20\\nvalue = [2, 2, 16]'),\n",
       " Text(61.737714063991106, 174.52421052631578, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 0, 15]'),\n",
       " Text(62.636534286942755, 174.52421052631578, 'X[3881] <= 0.724\\ngini = 0.64\\nsamples = 5\\nvalue = [2, 2, 1]'),\n",
       " Text(62.18712417546693, 168.8021052631579, 'X[636] <= 0.308\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(61.737714063991106, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(62.636534286942755, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(63.085944398418576, 168.8021052631579, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(65.33299495579769, 185.96842105263158, 'X[2909] <= 0.929\\ngini = 0.056\\nsamples = 140\\nvalue = [1, 136, 3]'),\n",
       " Text(64.88358484432186, 180.24631578947367, 'X[2518] <= 0.38\\ngini = 0.029\\nsamples = 138\\nvalue = [1, 136, 1]'),\n",
       " Text(64.43417473284605, 174.52421052631578, 'X[558] <= 0.669\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(63.98476462137022, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(64.88358484432186, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(65.33299495579769, 174.52421052631578, 'gini = 0.0\\nsamples = 136\\nvalue = [0, 136, 0]'),\n",
       " Text(65.78240506727352, 180.24631578947367, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(72.91679058695219, 191.69052631578947, 'X[1446] <= 0.604\\ngini = 0.518\\nsamples = 286\\nvalue = [34, 69, 183]'),\n",
       " Text(68.47886573612844, 185.96842105263158, 'X[2837] <= 0.382\\ngini = 0.36\\nsamples = 193\\nvalue = [30, 12, 151]'),\n",
       " Text(66.68122529022516, 180.24631578947367, 'X[995] <= 0.382\\ngini = 0.493\\nsamples = 34\\nvalue = [21, 1, 12]'),\n",
       " Text(66.23181517874933, 174.52421052631578, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(67.13063540170097, 174.52421052631578, 'X[2192] <= 0.153\\ngini = 0.322\\nsamples = 26\\nvalue = [21, 1, 4]'),\n",
       " Text(66.23181517874933, 168.8021052631579, 'X[3122] <= 0.549\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(65.78240506727352, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(66.68122529022516, 163.07999999999998, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(68.02945562465263, 168.8021052631579, 'X[3674] <= 0.618\\ngini = 0.087\\nsamples = 22\\nvalue = [21, 0, 1]'),\n",
       " Text(67.5800455131768, 163.07999999999998, 'gini = 0.0\\nsamples = 21\\nvalue = [21, 0, 0]'),\n",
       " Text(68.47886573612844, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(70.27650618203174, 180.24631578947367, 'X[1958] <= 0.392\\ngini = 0.228\\nsamples = 159\\nvalue = [9, 11, 139]'),\n",
       " Text(69.82709607055591, 174.52421052631578, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(70.72591629350755, 174.52421052631578, 'X[2934] <= 0.129\\ngini = 0.17\\nsamples = 153\\nvalue = [9, 5, 139]'),\n",
       " Text(69.82709607055591, 168.8021052631579, 'X[1140] <= 0.096\\ngini = 0.571\\nsamples = 7\\nvalue = [4, 1, 2]'),\n",
       " Text(69.37768595908008, 163.07999999999998, 'X[3339] <= 0.52\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(68.92827584760427, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(69.82709607055591, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(70.27650618203174, 163.07999999999998, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(71.6247365164592, 168.8021052631579, 'X[2586] <= 0.245\\ngini = 0.118\\nsamples = 146\\nvalue = [5, 4, 137]'),\n",
       " Text(71.17532640498338, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(72.07414662793502, 163.07999999999998, 'X[1177] <= 0.1\\ngini = 0.093\\nsamples = 144\\nvalue = [5, 2, 137]'),\n",
       " Text(71.6247365164592, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(72.52355673941085, 157.3578947368421, 'X[230] <= 0.88\\ngini = 0.069\\nsamples = 142\\nvalue = [3, 2, 137]'),\n",
       " Text(71.4000314607213, 151.6357894736842, 'X[3097] <= 0.329\\ngini = 0.042\\nsamples = 139\\nvalue = [3, 0, 136]'),\n",
       " Text(70.50121123776964, 145.9136842105263, 'X[586] <= 0.257\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(70.05180112629382, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(70.95062134924547, 140.19157894736844, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(72.29885168367294, 145.9136842105263, 'X[1544] <= 0.947\\ngini = 0.015\\nsamples = 136\\nvalue = [1, 0, 135]'),\n",
       " Text(71.84944157219711, 140.19157894736844, 'gini = 0.0\\nsamples = 135\\nvalue = [0, 0, 135]'),\n",
       " Text(72.74826179514876, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(73.6470820181004, 151.6357894736842, 'X[2217] <= 0.812\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(73.19767190662458, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(74.09649212957622, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(77.35471543777594, 185.96842105263158, 'X[1957] <= 0.655\\ngini = 0.504\\nsamples = 93\\nvalue = [4, 57, 32]'),\n",
       " Text(75.44472246400369, 180.24631578947367, 'X[2596] <= 0.831\\ngini = 0.263\\nsamples = 60\\nvalue = [2, 51, 7]'),\n",
       " Text(74.32119718531413, 174.52421052631578, 'X[964] <= 0.025\\ngini = 0.106\\nsamples = 54\\nvalue = [1, 51, 2]'),\n",
       " Text(73.42237696236249, 168.8021052631579, 'X[740] <= 0.665\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(72.97296685088666, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(73.87178707383832, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(75.22001740826578, 168.8021052631579, 'X[3175] <= 0.306\\ngini = 0.038\\nsamples = 52\\nvalue = [0, 51, 1]'),\n",
       " Text(74.77060729678996, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(75.6694275197416, 163.07999999999998, 'gini = 0.0\\nsamples = 51\\nvalue = [0, 51, 0]'),\n",
       " Text(76.56824774269325, 174.52421052631578, 'X[2380] <= 0.076\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 0, 5]'),\n",
       " Text(76.11883763121743, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(77.01765785416907, 168.8021052631579, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(79.26470841154818, 180.24631578947367, 'X[1267] <= 0.331\\ngini = 0.389\\nsamples = 33\\nvalue = [2, 6, 25]'),\n",
       " Text(78.36588818859654, 174.52421052631578, 'X[4040] <= 0.265\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 5, 1]'),\n",
       " Text(77.91647807712071, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(78.81529830007236, 168.8021052631579, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(80.16352863449983, 174.52421052631578, 'X[1319] <= 0.586\\ngini = 0.203\\nsamples = 27\\nvalue = [2, 1, 24]'),\n",
       " Text(79.714118523024, 168.8021052631579, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(80.61293874597565, 168.8021052631579, 'X[1057] <= 0.882\\ngini = 0.077\\nsamples = 25\\nvalue = [0, 1, 24]'),\n",
       " Text(80.16352863449983, 163.07999999999998, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(81.06234885745147, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(197.76231747046626, 208.85684210526315, 'X[1555] <= 0.406\\ngini = 0.577\\nsamples = 9131\\nvalue = [4427, 837, 3867]'),\n",
       " Text(149.23016047589584, 203.13473684210527, 'X[1247] <= 0.52\\ngini = 0.488\\nsamples = 5275\\nvalue = [3382, 236, 1657]'),\n",
       " Text(115.66341642459389, 197.41263157894736, 'X[2660] <= 0.563\\ngini = 0.516\\nsamples = 1513\\nvalue = [529, 77, 907]'),\n",
       " Text(102.75340876915172, 191.69052631578947, 'X[1247] <= 0.367\\ngini = 0.53\\nsamples = 857\\nvalue = [452, 31, 374]'),\n",
       " Text(94.01097769434861, 185.96842105263158, 'X[3931] <= 0.41\\ngini = 0.49\\nsamples = 374\\nvalue = [111, 21, 242]'),\n",
       " Text(89.0955546000818, 180.24631578947367, 'X[3099] <= 0.731\\ngini = 0.325\\nsamples = 207\\nvalue = [31, 9, 167]'),\n",
       " Text(86.34291766729238, 174.52421052631578, 'X[1815] <= 0.343\\ngini = 0.259\\nsamples = 196\\nvalue = [30, 0, 166]'),\n",
       " Text(83.5341044705685, 168.8021052631579, 'X[1835] <= 0.271\\ngini = 0.459\\nsamples = 73\\nvalue = [26, 0, 47]'),\n",
       " Text(81.96116908040312, 163.07999999999998, 'X[1758] <= 0.261\\ngini = 0.451\\nsamples = 32\\nvalue = [21, 0, 11]'),\n",
       " Text(81.5117589689273, 157.3578947368421, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(82.41057919187894, 157.3578947368421, 'X[3906] <= 0.878\\ngini = 0.269\\nsamples = 25\\nvalue = [21, 0, 4]'),\n",
       " Text(81.96116908040312, 151.6357894736842, 'X[1628] <= 0.573\\ngini = 0.087\\nsamples = 22\\nvalue = [21, 0, 1]'),\n",
       " Text(81.5117589689273, 145.9136842105263, 'gini = 0.0\\nsamples = 21\\nvalue = [21, 0, 0]'),\n",
       " Text(82.41057919187894, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(82.85998930335477, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(85.10703986073388, 163.07999999999998, 'X[2461] <= 0.563\\ngini = 0.214\\nsamples = 41\\nvalue = [5, 0, 36]'),\n",
       " Text(84.20821963778224, 157.3578947368421, 'X[2911] <= 0.551\\ngini = 0.102\\nsamples = 37\\nvalue = [2, 0, 35]'),\n",
       " Text(83.75880952630641, 151.6357894736842, 'X[781] <= 0.006\\ngini = 0.054\\nsamples = 36\\nvalue = [1, 0, 35]'),\n",
       " Text(83.30939941483058, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(84.20821963778224, 145.9136842105263, 'gini = 0.0\\nsamples = 35\\nvalue = [0, 0, 35]'),\n",
       " Text(84.65762974925805, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(86.00586008368552, 157.3578947368421, 'X[3967] <= 0.125\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(85.55644997220969, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(86.45527019516135, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(89.15173086401627, 168.8021052631579, 'X[1060] <= 0.753\\ngini = 0.063\\nsamples = 123\\nvalue = [4, 0, 119]'),\n",
       " Text(88.25291064106463, 163.07999999999998, 'X[2273] <= 0.847\\ngini = 0.033\\nsamples = 120\\nvalue = [2, 0, 118]'),\n",
       " Text(87.8035005295888, 157.3578947368421, 'X[3184] <= 0.043\\ngini = 0.017\\nsamples = 119\\nvalue = [1, 0, 118]'),\n",
       " Text(87.35409041811299, 151.6357894736842, 'X[910] <= 0.276\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(86.90468030663716, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(87.8035005295888, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(88.25291064106463, 151.6357894736842, 'gini = 0.0\\nsamples = 116\\nvalue = [0, 0, 116]'),\n",
       " Text(88.70232075254046, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(90.05055108696791, 163.07999999999998, 'X[1384] <= 0.565\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(89.6011409754921, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(90.49996119844374, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(91.84819153287121, 174.52421052631578, 'X[3358] <= 0.382\\ngini = 0.314\\nsamples = 11\\nvalue = [1, 9, 1]'),\n",
       " Text(91.39878142139538, 168.8021052631579, 'X[3318] <= 0.222\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(90.94937130991957, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(91.84819153287121, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(92.29760164434704, 168.8021052631579, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9, 0]'),\n",
       " Text(98.92640078861541, 180.24631578947367, 'X[56] <= 0.706\\ngini = 0.564\\nsamples = 167\\nvalue = [80, 12, 75]'),\n",
       " Text(96.79170275910526, 174.52421052631578, 'X[3036] <= 0.578\\ngini = 0.547\\nsamples = 137\\nvalue = [79, 12, 46]'),\n",
       " Text(93.87053703451241, 168.8021052631579, 'X[1885] <= 0.375\\ngini = 0.358\\nsamples = 90\\nvalue = [69, 0, 21]'),\n",
       " Text(92.74701175582285, 163.07999999999998, 'X[633] <= 0.52\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 0, 9]'),\n",
       " Text(92.29760164434704, 157.3578947368421, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(93.19642186729868, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(94.99406231320197, 163.07999999999998, 'X[1710] <= 0.49\\ngini = 0.258\\nsamples = 79\\nvalue = [67, 0, 12]'),\n",
       " Text(94.09524209025032, 157.3578947368421, 'X[1980] <= 0.006\\ngini = 0.134\\nsamples = 69\\nvalue = [64, 0, 5]'),\n",
       " Text(93.6458319787745, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(94.54465220172615, 151.6357894736842, 'X[1758] <= 0.186\\ngini = 0.059\\nsamples = 66\\nvalue = [64, 0, 2]'),\n",
       " Text(94.09524209025032, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(94.99406231320197, 145.9136842105263, 'X[3035] <= 0.704\\ngini = 0.03\\nsamples = 65\\nvalue = [64, 0, 1]'),\n",
       " Text(94.54465220172615, 140.19157894736844, 'gini = 0.0\\nsamples = 64\\nvalue = [64, 0, 0]'),\n",
       " Text(95.4434724246778, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(95.8928825361536, 157.3578947368421, 'X[1753] <= 0.32\\ngini = 0.42\\nsamples = 10\\nvalue = [3, 0, 7]'),\n",
       " Text(95.4434724246778, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(96.34229264762944, 151.6357894736842, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(99.7128684836981, 168.8021052631579, 'X[3102] <= 0.759\\ngini = 0.607\\nsamples = 47\\nvalue = [10, 12, 25]'),\n",
       " Text(98.58934320500855, 163.07999999999998, 'X[2565] <= 0.371\\ngini = 0.423\\nsamples = 35\\nvalue = [9, 1, 25]'),\n",
       " Text(97.6905229820569, 157.3578947368421, 'X[2579] <= 0.782\\ngini = 0.34\\nsamples = 10\\nvalue = [8, 1, 1]'),\n",
       " Text(97.24111287058108, 151.6357894736842, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(98.13993309353272, 151.6357894736842, 'X[1779] <= 0.224\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(97.6905229820569, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(98.58934320500855, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(99.48816342796019, 157.3578947368421, 'X[691] <= 0.708\\ngini = 0.077\\nsamples = 25\\nvalue = [1, 0, 24]'),\n",
       " Text(99.03875331648437, 151.6357894736842, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(99.93757353943602, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(100.83639376238766, 163.07999999999998, 'X[773] <= 0.024\\ngini = 0.153\\nsamples = 12\\nvalue = [1, 11, 0]'),\n",
       " Text(100.38698365091183, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(101.28580387386349, 157.3578947368421, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 11, 0]'),\n",
       " Text(101.06109881812557, 174.52421052631578, 'X[1978] <= 0.29\\ngini = 0.064\\nsamples = 30\\nvalue = [1, 0, 29]'),\n",
       " Text(100.61168870664974, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(101.5105089296014, 168.8021052631579, 'gini = 0.0\\nsamples = 29\\nvalue = [0, 0, 29]'),\n",
       " Text(111.49583984395483, 185.96842105263158, 'X[3931] <= 0.339\\ngini = 0.426\\nsamples = 483\\nvalue = [341, 10, 132]'),\n",
       " Text(106.22931510009752, 180.24631578947367, 'X[1642] <= 0.206\\ngini = 0.548\\nsamples = 115\\nvalue = [47, 7, 61]'),\n",
       " Text(103.5328544312426, 174.52421052631578, 'X[2027] <= 0.233\\ngini = 0.466\\nsamples = 54\\nvalue = [36, 2, 16]'),\n",
       " Text(102.40932915255304, 168.8021052631579, 'X[3802] <= 0.21\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 1, 9]'),\n",
       " Text(101.95991904107721, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(102.85873926402886, 163.07999999999998, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(104.65637970993215, 168.8021052631579, 'X[2796] <= 0.588\\ngini = 0.305\\nsamples = 44\\nvalue = [36, 1, 7]'),\n",
       " Text(103.75755948698051, 163.07999999999998, 'X[1428] <= 0.475\\ngini = 0.1\\nsamples = 38\\nvalue = [36, 0, 2]'),\n",
       " Text(103.30814937550468, 157.3578947368421, 'gini = 0.0\\nsamples = 36\\nvalue = [36, 0, 0]'),\n",
       " Text(104.20696959845633, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(105.5551999328838, 163.07999999999998, 'X[393] <= 0.735\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 1, 5]'),\n",
       " Text(105.10578982140797, 157.3578947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(106.00461004435962, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(108.92577576895246, 174.52421052631578, 'X[3099] <= 0.714\\ngini = 0.417\\nsamples = 61\\nvalue = [11, 5, 45]'),\n",
       " Text(108.47636565747663, 168.8021052631579, 'X[1584] <= 0.225\\ngini = 0.316\\nsamples = 56\\nvalue = [11, 0, 45]'),\n",
       " Text(107.35284037878708, 163.07999999999998, 'X[3343] <= 0.465\\ngini = 0.42\\nsamples = 10\\nvalue = [7, 0, 3]'),\n",
       " Text(106.90343026731126, 157.3578947368421, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(107.8022504902629, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(109.59989093616619, 163.07999999999998, 'X[1686] <= 0.125\\ngini = 0.159\\nsamples = 46\\nvalue = [4, 0, 42]'),\n",
       " Text(108.70107071321455, 157.3578947368421, 'X[1402] <= 0.724\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(108.25166060173873, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(109.15048082469038, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(110.49871115911785, 157.3578947368421, 'X[1176] <= 0.116\\ngini = 0.046\\nsamples = 42\\nvalue = [1, 0, 41]'),\n",
       " Text(110.04930104764202, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(110.94812127059366, 151.6357894736842, 'gini = 0.0\\nsamples = 41\\nvalue = [0, 0, 41]'),\n",
       " Text(109.37518588042829, 168.8021052631579, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(116.76236458781212, 180.24631578947367, 'X[3223] <= 0.576\\ngini = 0.324\\nsamples = 368\\nvalue = [294, 3, 71]'),\n",
       " Text(113.86928699518651, 174.52421052631578, 'X[1836] <= 0.667\\ngini = 0.203\\nsamples = 288\\nvalue = [255, 0, 33]'),\n",
       " Text(112.74576171649696, 168.8021052631579, 'X[1695] <= 0.273\\ngini = 0.158\\nsamples = 277\\nvalue = [253, 0, 24]'),\n",
       " Text(111.84694149354532, 163.07999999999998, 'X[2625] <= 0.882\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 0, 6]'),\n",
       " Text(111.39753138206949, 157.3578947368421, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(112.29635160502113, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(113.6445819394486, 163.07999999999998, 'X[2141] <= 0.249\\ngini = 0.124\\nsamples = 270\\nvalue = [252, 0, 18]'),\n",
       " Text(113.19517182797277, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(114.09399205092443, 157.3578947368421, 'X[2329] <= 0.304\\ngini = 0.106\\nsamples = 267\\nvalue = [252, 0, 15]'),\n",
       " Text(112.74576171649696, 151.6357894736842, 'X[265] <= 0.273\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(112.29635160502113, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(113.19517182797277, 145.9136842105263, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(115.44222238535188, 151.6357894736842, 'X[432] <= 0.708\\ngini = 0.087\\nsamples = 263\\nvalue = [251, 0, 12]'),\n",
       " Text(114.09399205092443, 145.9136842105263, 'X[2659] <= 0.492\\ngini = 0.055\\nsamples = 247\\nvalue = [240, 0, 7]'),\n",
       " Text(113.6445819394486, 140.19157894736844, 'gini = 0.0\\nsamples = 205\\nvalue = [205, 0, 0]'),\n",
       " Text(114.54340216240024, 140.19157894736844, 'X[1766] <= 0.343\\ngini = 0.278\\nsamples = 42\\nvalue = [35, 0, 7]'),\n",
       " Text(114.09399205092443, 134.46947368421053, 'X[4063] <= 0.547\\ngini = 0.497\\nsamples = 13\\nvalue = [6, 0, 7]'),\n",
       " Text(113.6445819394486, 128.7473684210526, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(114.54340216240024, 128.7473684210526, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(114.99281227387607, 134.46947368421053, 'gini = 0.0\\nsamples = 29\\nvalue = [29, 0, 0]'),\n",
       " Text(116.79045271977935, 145.9136842105263, 'X[2606] <= 0.437\\ngini = 0.43\\nsamples = 16\\nvalue = [11, 0, 5]'),\n",
       " Text(116.34104260830354, 140.19157894736844, 'X[748] <= 0.376\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 0, 5]'),\n",
       " Text(115.89163249682771, 134.46947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(116.79045271977935, 134.46947368421053, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(117.23986283125518, 140.19157894736844, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(114.99281227387607, 168.8021052631579, 'X[1740] <= 0.422\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 0, 9]'),\n",
       " Text(114.54340216240024, 163.07999999999998, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(115.44222238535188, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(119.65544218043772, 174.52421052631578, 'X[3237] <= 0.378\\ngini = 0.535\\nsamples = 80\\nvalue = [39, 3, 38]'),\n",
       " Text(118.36338810994474, 168.8021052631579, 'X[1750] <= 0.633\\ngini = 0.172\\nsamples = 21\\nvalue = [19, 0, 2]'),\n",
       " Text(117.91397799846891, 163.07999999999998, 'gini = 0.0\\nsamples = 19\\nvalue = [19, 0, 0]'),\n",
       " Text(118.81279822142055, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(120.94749625093071, 168.8021052631579, 'X[792] <= 0.712\\ngini = 0.51\\nsamples = 59\\nvalue = [20, 3, 36]'),\n",
       " Text(119.7116184443722, 163.07999999999998, 'X[798] <= 0.412\\ngini = 0.421\\nsamples = 48\\nvalue = [10, 3, 35]'),\n",
       " Text(118.58809316568265, 157.3578947368421, 'X[2316] <= 0.645\\ngini = 0.494\\nsamples = 9\\nvalue = [6, 2, 1]'),\n",
       " Text(118.13868305420682, 151.6357894736842, 'X[3351] <= 0.72\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(117.689272942731, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(118.58809316568265, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(119.03750327715846, 151.6357894736842, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(120.83514372306176, 157.3578947368421, 'X[2634] <= 0.312\\ngini = 0.229\\nsamples = 39\\nvalue = [4, 1, 34]'),\n",
       " Text(119.93632350011012, 151.6357894736842, 'X[3090] <= 0.359\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1, 0]'),\n",
       " Text(119.48691338863429, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(120.38573361158593, 145.9136842105263, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(121.7339639460134, 151.6357894736842, 'X[3161] <= 0.331\\ngini = 0.056\\nsamples = 35\\nvalue = [1, 0, 34]'),\n",
       " Text(121.28455383453758, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(122.18337405748923, 145.9136842105263, 'gini = 0.0\\nsamples = 34\\nvalue = [0, 0, 34]'),\n",
       " Text(122.18337405748923, 163.07999999999998, 'X[784] <= 0.622\\ngini = 0.165\\nsamples = 11\\nvalue = [10, 0, 1]'),\n",
       " Text(121.7339639460134, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(122.63278416896505, 157.3578947368421, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(128.57342408003606, 191.69052631578947, 'X[671] <= 0.249\\ngini = 0.321\\nsamples = 656\\nvalue = [77, 46, 533]'),\n",
       " Text(123.7563094476546, 185.96842105263158, 'X[3410] <= 0.288\\ngini = 0.598\\nsamples = 67\\nvalue = [8, 29, 30]'),\n",
       " Text(122.63278416896505, 180.24631578947367, 'X[2349] <= 0.1\\ngini = 0.083\\nsamples = 23\\nvalue = [0, 22, 1]'),\n",
       " Text(122.18337405748923, 174.52421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(123.08219428044087, 174.52421052631578, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 22, 0]'),\n",
       " Text(124.87983472634416, 180.24631578947367, 'X[904] <= 0.092\\ngini = 0.507\\nsamples = 44\\nvalue = [8, 7, 29]'),\n",
       " Text(123.98101450339252, 174.52421052631578, 'X[1903] <= 0.516\\ngini = 0.34\\nsamples = 10\\nvalue = [8, 1, 1]'),\n",
       " Text(123.53160439191669, 168.8021052631579, 'X[3411] <= 0.527\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(123.08219428044087, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(123.98101450339252, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(124.43042461486834, 168.8021052631579, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(125.7786549492958, 174.52421052631578, 'X[241] <= 0.457\\ngini = 0.291\\nsamples = 34\\nvalue = [0, 6, 28]'),\n",
       " Text(125.32924483781999, 168.8021052631579, 'gini = 0.0\\nsamples = 27\\nvalue = [0, 0, 27]'),\n",
       " Text(126.22806506077163, 168.8021052631579, 'X[1417] <= 0.645\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 6, 1]'),\n",
       " Text(125.7786549492958, 163.07999999999998, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(126.67747517224745, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(133.39053871241754, 185.96842105263158, 'X[2716] <= 0.449\\ngini = 0.256\\nsamples = 589\\nvalue = [69, 17, 503]'),\n",
       " Text(129.14923078536447, 180.24631578947367, 'X[1705] <= 0.378\\ngini = 0.506\\nsamples = 77\\nvalue = [30, 2, 45]'),\n",
       " Text(127.5762953951991, 174.52421052631578, 'X[928] <= 0.441\\ngini = 0.368\\nsamples = 37\\nvalue = [28, 0, 9]'),\n",
       " Text(127.12688528372327, 168.8021052631579, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(128.0257055066749, 168.8021052631579, 'X[2599] <= 0.275\\ngini = 0.124\\nsamples = 30\\nvalue = [28, 0, 2]'),\n",
       " Text(127.5762953951991, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(128.47511561815074, 163.07999999999998, 'gini = 0.0\\nsamples = 28\\nvalue = [28, 0, 0]'),\n",
       " Text(130.72216617552985, 174.52421052631578, 'X[2587] <= 0.647\\ngini = 0.185\\nsamples = 40\\nvalue = [2, 2, 36]'),\n",
       " Text(129.8233459525782, 168.8021052631579, 'X[2303] <= 0.888\\ngini = 0.053\\nsamples = 37\\nvalue = [1, 0, 36]'),\n",
       " Text(129.3739358411024, 163.07999999999998, 'gini = 0.0\\nsamples = 36\\nvalue = [0, 0, 36]'),\n",
       " Text(130.27275606405402, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(131.6209863984815, 168.8021052631579, 'X[1599] <= 0.453\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(131.17157628700568, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(132.0703965099573, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(137.6318466394706, 180.24631578947367, 'X[1120] <= 0.624\\ngini = 0.193\\nsamples = 512\\nvalue = [39, 15, 458]'),\n",
       " Text(134.6545046509433, 174.52421052631578, 'X[990] <= 0.08\\ngini = 0.118\\nsamples = 454\\nvalue = [15, 13, 426]'),\n",
       " Text(133.4186268443848, 168.8021052631579, 'X[3458] <= 0.139\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(132.96921673290896, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(133.86803695586062, 163.07999999999998, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(135.8903824575018, 168.8021052631579, 'X[1943] <= 0.222\\ngini = 0.098\\nsamples = 449\\nvalue = [14, 9, 426]'),\n",
       " Text(134.76685717881224, 163.07999999999998, 'X[404] <= 0.12\\ngini = 0.531\\nsamples = 8\\nvalue = [1, 5, 2]'),\n",
       " Text(134.31744706733645, 157.3578947368421, 'X[3599] <= 0.08\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(133.86803695586062, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(134.76685717881224, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(135.21626729028807, 157.3578947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(137.01390773619136, 163.07999999999998, 'X[3110] <= 0.269\\ngini = 0.075\\nsamples = 441\\nvalue = [13, 4, 424]'),\n",
       " Text(136.11508751323973, 157.3578947368421, 'X[3055] <= 0.057\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(135.6656774017639, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(136.56449762471556, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(137.912727959143, 157.3578947368421, 'X[165] <= 0.953\\ngini = 0.058\\nsamples = 436\\nvalue = [9, 4, 423]'),\n",
       " Text(137.46331784766718, 151.6357894736842, 'X[1493] <= 0.839\\ngini = 0.054\\nsamples = 435\\nvalue = [9, 3, 423]'),\n",
       " Text(137.01390773619136, 145.9136842105263, 'X[20] <= 0.98\\ngini = 0.05\\nsamples = 434\\nvalue = [9, 2, 423]'),\n",
       " Text(136.56449762471556, 140.19157894736844, 'X[3604] <= 0.939\\ngini = 0.045\\nsamples = 433\\nvalue = [9, 1, 423]'),\n",
       " Text(136.11508751323973, 134.46947368421053, 'X[1350] <= 0.002\\ngini = 0.041\\nsamples = 432\\nvalue = [8, 1, 423]'),\n",
       " Text(135.6656774017639, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(136.56449762471556, 128.7473684210526, 'X[4074] <= 0.014\\ngini = 0.037\\nsamples = 431\\nvalue = [7, 1, 423]'),\n",
       " Text(136.11508751323973, 123.02526315789474, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(137.01390773619136, 123.02526315789474, 'X[2589] <= 0.259\\ngini = 0.032\\nsamples = 430\\nvalue = [6, 1, 423]'),\n",
       " Text(135.8903824575018, 117.30315789473684, 'X[1440] <= 0.253\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(135.440972346026, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(136.33979256897763, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(138.1374330148809, 117.30315789473684, 'X[1117] <= 0.812\\ngini = 0.028\\nsamples = 428\\nvalue = [6, 0, 422]'),\n",
       " Text(137.23861279192928, 111.58105263157894, 'X[1176] <= 0.82\\ngini = 0.023\\nsamples = 426\\nvalue = [5, 0, 421]'),\n",
       " Text(136.78920268045346, 105.85894736842106, 'X[3301] <= 0.104\\ngini = 0.019\\nsamples = 425\\nvalue = [4, 0, 421]'),\n",
       " Text(135.55332487389495, 100.13684210526316, 'X[3123] <= 0.227\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(135.10391476241912, 94.41473684210527, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(136.00273498537078, 94.41473684210527, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(138.02508048701196, 100.13684210526316, 'X[3037] <= 0.176\\ngini = 0.014\\nsamples = 423\\nvalue = [3, 0, 420]'),\n",
       " Text(136.9015552083224, 94.41473684210527, 'X[3664] <= 0.394\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(136.45214509684658, 88.69263157894736, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(137.35096531979823, 88.69263157894736, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(139.14860576570152, 94.41473684210527, 'X[1182] <= 0.653\\ngini = 0.009\\nsamples = 421\\nvalue = [2, 0, 419]'),\n",
       " Text(138.2497855427499, 88.69263157894736, 'X[307] <= 0.963\\ngini = 0.005\\nsamples = 418\\nvalue = [1, 0, 417]'),\n",
       " Text(137.80037543127406, 82.97052631578947, 'gini = 0.0\\nsamples = 414\\nvalue = [0, 0, 414]'),\n",
       " Text(138.6991956542257, 82.97052631578947, 'X[3324] <= 0.237\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(138.2497855427499, 77.24842105263158, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(139.14860576570152, 77.24842105263158, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(140.04742598865317, 88.69263157894736, 'X[2350] <= 0.633\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(139.59801587717735, 82.97052631578947, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(140.496836100129, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(137.6880229034051, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(139.03625323783257, 111.58105263157894, 'X[668] <= 0.624\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(138.58684312635674, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(139.4856633493084, 105.85894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(137.01390773619136, 134.46947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(137.46331784766718, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(137.912727959143, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(138.36213807061884, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(140.60918862799795, 174.52421052631578, 'X[2985] <= 0.743\\ngini = 0.523\\nsamples = 58\\nvalue = [24, 2, 32]'),\n",
       " Text(139.7103684050463, 168.8021052631579, 'X[2535] <= 0.627\\ngini = 0.391\\nsamples = 30\\nvalue = [22, 0, 8]'),\n",
       " Text(139.26095829357047, 163.07999999999998, 'X[548] <= 0.753\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 0, 8]'),\n",
       " Text(138.81154818209467, 157.3578947368421, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(139.7103684050463, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(140.15977851652212, 163.07999999999998, 'gini = 0.0\\nsamples = 20\\nvalue = [20, 0, 0]'),\n",
       " Text(141.50800885094958, 168.8021052631579, 'X[685] <= 0.89\\ngini = 0.255\\nsamples = 28\\nvalue = [2, 2, 24]'),\n",
       " Text(141.05859873947378, 163.07999999999998, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(141.9574189624254, 163.07999999999998, 'X[1512] <= 0.478\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(141.50800885094958, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(142.40682907390124, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(182.7969045271978, 197.41263157894736, 'X[2533] <= 0.837\\ngini = 0.383\\nsamples = 3762\\nvalue = [2853, 159, 750]'),\n",
       " Text(158.58427645584487, 191.69052631578947, 'X[2384] <= 0.402\\ngini = 0.318\\nsamples = 3413\\nvalue = [2770, 136, 507]'),\n",
       " Text(145.88975743783885, 185.96842105263158, 'X[3425] <= 0.533\\ngini = 0.599\\nsamples = 187\\nvalue = [23, 77, 87]'),\n",
       " Text(143.7550594083287, 180.24631578947367, 'X[3807] <= 0.535\\ngini = 0.243\\nsamples = 80\\nvalue = [9, 2, 69]'),\n",
       " Text(142.85623918537706, 174.52421052631578, 'X[413] <= 0.094\\ngini = 0.084\\nsamples = 69\\nvalue = [1, 2, 66]'),\n",
       " Text(142.40682907390124, 168.8021052631579, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(143.3056492968529, 168.8021052631579, 'X[2844] <= 0.016\\ngini = 0.029\\nsamples = 67\\nvalue = [1, 0, 66]'),\n",
       " Text(142.85623918537706, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(143.7550594083287, 163.07999999999998, 'gini = 0.0\\nsamples = 66\\nvalue = [0, 0, 66]'),\n",
       " Text(144.65387963128035, 174.52421052631578, 'X[2529] <= 0.459\\ngini = 0.397\\nsamples = 11\\nvalue = [8, 0, 3]'),\n",
       " Text(144.20446951980452, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(145.10328974275617, 168.8021052631579, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(148.02445546734901, 180.24631578947367, 'X[541] <= 0.58\\ngini = 0.463\\nsamples = 107\\nvalue = [14, 75, 18]'),\n",
       " Text(146.45152007718363, 174.52421052631578, 'X[3485] <= 0.476\\ngini = 0.144\\nsamples = 78\\nvalue = [5, 72, 1]'),\n",
       " Text(146.0021099657078, 168.8021052631579, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(146.90093018865946, 168.8021052631579, 'X[1830] <= 0.841\\ngini = 0.027\\nsamples = 73\\nvalue = [0, 72, 1]'),\n",
       " Text(146.45152007718363, 163.07999999999998, 'gini = 0.0\\nsamples = 72\\nvalue = [0, 72, 0]'),\n",
       " Text(147.3503403001353, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(149.5973908575144, 174.52421052631578, 'X[3877] <= 0.661\\ngini = 0.549\\nsamples = 29\\nvalue = [9, 3, 17]'),\n",
       " Text(148.69857063456274, 168.8021052631579, 'X[1877] <= 0.269\\ngini = 0.349\\nsamples = 19\\nvalue = [1, 3, 15]'),\n",
       " Text(148.2491605230869, 163.07999999999998, 'X[1271] <= 0.439\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3, 0]'),\n",
       " Text(147.79975041161111, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(148.69857063456274, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(149.14798074603857, 163.07999999999998, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 0, 15]'),\n",
       " Text(150.49621108046603, 168.8021052631579, 'X[1446] <= 0.663\\ngini = 0.32\\nsamples = 10\\nvalue = [8, 0, 2]'),\n",
       " Text(150.04680096899023, 163.07999999999998, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(150.94562119194185, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(171.2787954738509, 185.96842105263158, 'X[1959] <= 0.367\\ngini = 0.258\\nsamples = 3226\\nvalue = [2747, 59, 420]'),\n",
       " Text(158.24853550342397, 180.24631578947367, 'X[3175] <= 0.525\\ngini = 0.644\\nsamples = 202\\nvalue = [69, 45, 88]'),\n",
       " Text(154.54090208374845, 174.52421052631578, 'X[3931] <= 0.433\\ngini = 0.503\\nsamples = 105\\nvalue = [66, 6, 33]'),\n",
       " Text(152.29385152636934, 168.8021052631579, 'X[1499] <= 0.267\\ngini = 0.526\\nsamples = 35\\nvalue = [9, 4, 22]'),\n",
       " Text(151.8444414148935, 163.07999999999998, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(152.74326163784514, 163.07999999999998, 'X[3179] <= 0.475\\ngini = 0.357\\nsamples = 28\\nvalue = [2, 4, 22]'),\n",
       " Text(151.8444414148935, 157.3578947368421, 'X[2721] <= 0.157\\ngini = 0.083\\nsamples = 23\\nvalue = [1, 0, 22]'),\n",
       " Text(151.39503130341768, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(152.29385152636934, 151.6357894736842, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 22]'),\n",
       " Text(153.6420818607968, 157.3578947368421, 'X[2717] <= 0.482\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(153.19267174932097, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(154.09149197227262, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(156.78795264112756, 168.8021052631579, 'X[2535] <= 0.586\\ngini = 0.311\\nsamples = 70\\nvalue = [57, 2, 11]'),\n",
       " Text(155.8891324181759, 163.07999999999998, 'X[1887] <= 0.331\\ngini = 0.069\\nsamples = 56\\nvalue = [54, 0, 2]'),\n",
       " Text(155.43972230670008, 157.3578947368421, 'X[607] <= 0.553\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(154.99031219522428, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(155.8891324181759, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(156.33854252965173, 157.3578947368421, 'gini = 0.0\\nsamples = 53\\nvalue = [53, 0, 0]'),\n",
       " Text(157.6867728640792, 163.07999999999998, 'X[1608] <= 0.645\\ngini = 0.52\\nsamples = 14\\nvalue = [3, 2, 9]'),\n",
       " Text(157.2373627526034, 157.3578947368421, 'X[27] <= 0.214\\ngini = 0.298\\nsamples = 11\\nvalue = [0, 2, 9]'),\n",
       " Text(156.78795264112756, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(157.6867728640792, 151.6357894736842, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(158.13618297555502, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(161.9561689230995, 174.52421052631578, 'X[3104] <= 0.759\\ngini = 0.516\\nsamples = 97\\nvalue = [3, 39, 55]'),\n",
       " Text(160.38323353293413, 168.8021052631579, 'X[1294] <= 0.159\\ngini = 0.354\\nsamples = 65\\nvalue = [3, 11, 51]'),\n",
       " Text(159.4844133099825, 163.07999999999998, 'X[1626] <= 0.324\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6, 0]'),\n",
       " Text(159.03500319850667, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(159.9338234214583, 157.3578947368421, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(161.28205375588578, 163.07999999999998, 'X[3109] <= 0.767\\ngini = 0.218\\nsamples = 58\\nvalue = [2, 5, 51]'),\n",
       " Text(160.83264364440996, 157.3578947368421, 'X[1999] <= 0.157\\ngini = 0.138\\nsamples = 55\\nvalue = [2, 2, 51]'),\n",
       " Text(160.38323353293413, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(161.28205375588578, 151.6357894736842, 'X[1638] <= 0.127\\ngini = 0.073\\nsamples = 53\\nvalue = [2, 0, 51]'),\n",
       " Text(160.83264364440996, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(161.7314638673616, 145.9136842105263, 'gini = 0.0\\nsamples = 51\\nvalue = [0, 0, 51]'),\n",
       " Text(161.7314638673616, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(163.5291043132649, 168.8021052631579, 'X[1444] <= 0.541\\ngini = 0.219\\nsamples = 32\\nvalue = [0, 28, 4]'),\n",
       " Text(163.07969420178907, 163.07999999999998, 'X[2879] <= 0.165\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 1, 4]'),\n",
       " Text(162.63028409031324, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(163.5291043132649, 157.3578947368421, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(163.97851442474072, 163.07999999999998, 'gini = 0.0\\nsamples = 27\\nvalue = [0, 27, 0]'),\n",
       " Text(184.30905544427782, 180.24631578947367, 'X[1712] <= 0.72\\ngini = 0.204\\nsamples = 3024\\nvalue = [2678, 14, 332]'),\n",
       " Text(172.78765481296603, 174.52421052631578, 'X[2348] <= 0.449\\ngini = 0.168\\nsamples = 2882\\nvalue = [2616, 11, 255]'),\n",
       " Text(166.45027003785773, 168.8021052631579, 'X[1558] <= 0.312\\ngini = 0.45\\nsamples = 67\\nvalue = [21, 1, 45]'),\n",
       " Text(165.32674475916818, 163.07999999999998, 'X[3404] <= 0.388\\ngini = 0.494\\nsamples = 38\\nvalue = [21, 0, 17]'),\n",
       " Text(164.42792453621652, 157.3578947368421, 'X[1436] <= 0.237\\ngini = 0.231\\nsamples = 15\\nvalue = [2, 0, 13]'),\n",
       " Text(163.97851442474072, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(164.87733464769235, 151.6357894736842, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(166.22556498211983, 157.3578947368421, 'X[871] <= 0.694\\ngini = 0.287\\nsamples = 23\\nvalue = [19, 0, 4]'),\n",
       " Text(165.776154870644, 151.6357894736842, 'gini = 0.0\\nsamples = 18\\nvalue = [18, 0, 0]'),\n",
       " Text(166.67497509359563, 151.6357894736842, 'X[3439] <= 0.2\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(166.22556498211983, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(167.12438520507146, 145.9136842105263, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(167.5737953165473, 163.07999999999998, 'X[3282] <= 0.861\\ngini = 0.067\\nsamples = 29\\nvalue = [0, 1, 28]'),\n",
       " Text(167.12438520507146, 157.3578947368421, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 0, 28]'),\n",
       " Text(168.02320542802312, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(179.1250395880743, 168.8021052631579, 'X[3287] <= 0.747\\ngini = 0.145\\nsamples = 2815\\nvalue = [2595, 10, 210]'),\n",
       " Text(172.9245844563063, 163.07999999999998, 'X[1568] <= 0.449\\ngini = 0.104\\nsamples = 2600\\nvalue = [2457, 7, 136]'),\n",
       " Text(169.93319840179535, 157.3578947368421, 'X[2465] <= 0.516\\ngini = 0.484\\nsamples = 95\\nvalue = [58, 1, 36]'),\n",
       " Text(168.47261553949895, 151.6357894736842, 'X[2613] <= 0.751\\ngini = 0.111\\nsamples = 34\\nvalue = [32, 0, 2]'),\n",
       " Text(168.02320542802312, 145.9136842105263, 'gini = 0.0\\nsamples = 32\\nvalue = [32, 0, 0]'),\n",
       " Text(168.92202565097475, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(171.39378126409179, 151.6357894736842, 'X[2843] <= 0.567\\ngini = 0.507\\nsamples = 61\\nvalue = [26, 1, 34]'),\n",
       " Text(169.8208458739264, 145.9136842105263, 'X[3555] <= 0.498\\ngini = 0.447\\nsamples = 32\\nvalue = [22, 1, 9]'),\n",
       " Text(168.92202565097475, 140.19157894736844, 'X[2161] <= 0.637\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 0, 8]'),\n",
       " Text(168.47261553949895, 134.46947368421053, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(169.37143576245057, 134.46947368421053, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(170.71966609687806, 140.19157894736844, 'X[1201] <= 0.345\\ngini = 0.169\\nsamples = 22\\nvalue = [20, 1, 1]'),\n",
       " Text(170.27025598540223, 134.46947368421053, 'X[2153] <= 0.565\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(169.8208458739264, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(170.71966609687806, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(171.16907620835386, 134.46947368421053, 'gini = 0.0\\nsamples = 20\\nvalue = [20, 0, 0]'),\n",
       " Text(172.96671665425717, 145.9136842105263, 'X[3240] <= 0.382\\ngini = 0.238\\nsamples = 29\\nvalue = [4, 0, 25]'),\n",
       " Text(172.51730654278134, 140.19157894736844, 'X[2030] <= 0.578\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(172.0678964313055, 134.46947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(172.96671665425717, 134.46947368421053, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(173.416126765733, 140.19157894736844, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(175.91597051081723, 157.3578947368421, 'X[2771] <= 0.116\\ngini = 0.081\\nsamples = 2505\\nvalue = [2399, 6, 100]'),\n",
       " Text(175.0171502878656, 151.6357894736842, 'X[4075] <= 0.665\\ngini = 0.165\\nsamples = 11\\nvalue = [1, 0, 10]'),\n",
       " Text(174.56774017638978, 145.9136842105263, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(175.46656039934143, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(176.8147907337689, 151.6357894736842, 'X[2219] <= 0.408\\ngini = 0.074\\nsamples = 2494\\nvalue = [2398, 6, 90]'),\n",
       " Text(176.36538062229306, 145.9136842105263, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(177.26420084524472, 145.9136842105263, 'X[1940] <= 0.28\\ngini = 0.068\\nsamples = 2486\\nvalue = [2398, 6, 82]'),\n",
       " Text(174.31494698868462, 140.19157894736844, 'X[489] <= 0.714\\ngini = 0.541\\nsamples = 14\\nvalue = [5, 1, 8]'),\n",
       " Text(173.8655368772088, 134.46947368421053, 'X[4055] <= 0.106\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 1, 8]'),\n",
       " Text(173.416126765733, 128.7473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(174.31494698868462, 128.7473684210526, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(174.76435710016045, 134.46947368421053, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(180.2134547018048, 140.19157894736844, 'X[2329] <= 0.9\\ngini = 0.062\\nsamples = 2472\\nvalue = [2393, 5, 74]'),\n",
       " Text(177.1237601854085, 134.46947368421053, 'X[3158] <= 0.743\\ngini = 0.055\\nsamples = 2455\\nvalue = [2385, 4, 66]'),\n",
       " Text(175.21376721163628, 128.7473684210526, 'X[2449] <= 0.388\\ngini = 0.042\\nsamples = 2368\\nvalue = [2317, 2, 49]'),\n",
       " Text(174.31494698868462, 123.02526315789474, 'X[1623] <= 0.276\\ngini = 0.469\\nsamples = 8\\nvalue = [3, 0, 5]'),\n",
       " Text(173.8655368772088, 117.30315789473684, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(174.76435710016045, 117.30315789473684, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(176.1125874345879, 123.02526315789474, 'X[2414] <= 0.941\\ngini = 0.038\\nsamples = 2360\\nvalue = [2314, 2, 44]'),\n",
       " Text(175.6631773231121, 117.30315789473684, 'X[2961] <= 0.104\\ngini = 0.036\\nsamples = 2357\\nvalue = [2314, 2, 41]'),\n",
       " Text(175.21376721163628, 111.58105263157894, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(176.1125874345879, 111.58105263157894, 'X[3792] <= 0.006\\ngini = 0.034\\nsamples = 2355\\nvalue = [2314, 2, 39]'),\n",
       " Text(174.59582830835703, 105.85894736842106, 'X[1768] <= 0.459\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 0, 3]'),\n",
       " Text(174.1464181968812, 100.13684210526316, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(175.04523841983283, 100.13684210526316, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(177.62934656081882, 105.85894736842106, 'X[2539] <= 0.206\\ngini = 0.032\\nsamples = 2350\\nvalue = [2312, 2, 36]'),\n",
       " Text(175.94405864278448, 100.13684210526316, 'X[3965] <= 0.478\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(175.49464853130866, 94.41473684210527, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(176.3934687542603, 94.41473684210527, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(179.31463447885315, 100.13684210526316, 'X[2350] <= 0.504\\ngini = 0.03\\nsamples = 2347\\nvalue = [2311, 2, 34]'),\n",
       " Text(177.29228897721194, 94.41473684210527, 'X[3236] <= 0.539\\ngini = 0.275\\nsamples = 63\\nvalue = [53, 2, 8]'),\n",
       " Text(175.94405864278448, 88.69263157894736, 'X[1187] <= 0.347\\ngini = 0.071\\nsamples = 54\\nvalue = [52, 0, 2]'),\n",
       " Text(175.49464853130866, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(176.3934687542603, 82.97052631578947, 'X[2325] <= 0.463\\ngini = 0.037\\nsamples = 53\\nvalue = [52, 0, 1]'),\n",
       " Text(175.94405864278448, 77.24842105263158, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(176.84287886573614, 77.24842105263158, 'gini = 0.0\\nsamples = 52\\nvalue = [52, 0, 0]'),\n",
       " Text(178.64051931163942, 88.69263157894736, 'X[2094] <= 0.476\\ngini = 0.494\\nsamples = 9\\nvalue = [1, 2, 6]'),\n",
       " Text(178.1911092001636, 82.97052631578947, 'X[861] <= 0.486\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(177.74169908868777, 77.24842105263158, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(178.64051931163942, 77.24842105263158, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(179.08992942311525, 82.97052631578947, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(181.33697998049436, 94.41473684210527, 'X[1896] <= 0.269\\ngini = 0.023\\nsamples = 2284\\nvalue = [2258, 0, 26]'),\n",
       " Text(180.4381597575427, 88.69263157894736, 'X[1897] <= 0.216\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(179.98874964606688, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(180.88756986901853, 82.97052631578947, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(182.235800203446, 88.69263157894736, 'X[1818] <= 0.933\\ngini = 0.021\\nsamples = 2281\\nvalue = [2257, 0, 24]'),\n",
       " Text(181.78639009197016, 82.97052631578947, 'X[1520] <= 0.818\\ngini = 0.02\\nsamples = 2280\\nvalue = [2257, 0, 23]'),\n",
       " Text(181.33697998049436, 77.24842105263158, 'X[2798] <= 0.931\\ngini = 0.019\\nsamples = 2279\\nvalue = [2257, 0, 22]'),\n",
       " Text(180.88756986901853, 71.5263157894737, 'X[1453] <= 0.014\\ngini = 0.018\\nsamples = 2278\\nvalue = [2257, 0, 21]'),\n",
       " Text(180.4381597575427, 65.80421052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(181.33697998049436, 65.80421052631579, 'X[3222] <= 0.696\\ngini = 0.017\\nsamples = 2277\\nvalue = [2257, 0, 20]'),\n",
       " Text(178.87049089212118, 60.0821052631579, 'X[1247] <= 0.524\\ngini = 0.01\\nsamples = 2167\\nvalue = [2156, 0, 11]'),\n",
       " Text(177.52577157418963, 54.360000000000014, 'X[1113] <= 0.586\\ngini = 0.408\\nsamples = 7\\nvalue = [5, 0, 2]'),\n",
       " Text(177.0763614627138, 48.6378947368421, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(177.97518168566546, 48.6378947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(180.21521021005276, 54.360000000000014, 'X[2513] <= 0.371\\ngini = 0.008\\nsamples = 2160\\nvalue = [2151, 0, 9]'),\n",
       " Text(178.8740019086171, 48.6378947368421, 'X[47] <= 0.118\\ngini = 0.408\\nsamples = 7\\nvalue = [5, 0, 2]'),\n",
       " Text(178.42459179714126, 42.915789473684214, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(179.32341202009292, 42.915789473684214, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(181.5564185114884, 48.6378947368421, 'X[395] <= 0.002\\ngini = 0.006\\nsamples = 2153\\nvalue = [2146, 0, 7]'),\n",
       " Text(180.22223224304457, 42.915789473684214, 'X[3711] <= 0.267\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(179.77282213156874, 37.19368421052633, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(180.67164235452037, 37.19368421052633, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(182.89060477993226, 42.915789473684214, 'X[1709] <= 0.908\\ngini = 0.006\\nsamples = 2151\\nvalue = [2145, 0, 6]'),\n",
       " Text(181.57046257747203, 37.19368421052633, 'X[261] <= 0.994\\ngini = 0.005\\nsamples = 2149\\nvalue = [2144, 0, 5]'),\n",
       " Text(180.27840850697905, 31.471578947368414, 'X[2156] <= 0.433\\ngini = 0.004\\nsamples = 2147\\nvalue = [2143, 0, 4]'),\n",
       " Text(179.0425307004205, 25.74947368421053, 'X[473] <= 0.808\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(178.5931205889447, 20.027368421052643, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(179.49194081189634, 20.027368421052643, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(181.51428631353755, 25.74947368421053, 'X[2897] <= 0.157\\ngini = 0.003\\nsamples = 2144\\nvalue = [2141, 0, 3]'),\n",
       " Text(180.390761034848, 20.027368421052643, 'X[1661] <= 0.159\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(179.94135092337217, 14.305263157894728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(180.84017114632383, 14.305263157894728, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(182.6378115922271, 20.027368421052643, 'X[354] <= 0.061\\ngini = 0.002\\nsamples = 2139\\nvalue = [2137, 0, 2]'),\n",
       " Text(181.73899136927545, 14.305263157894728, 'X[2028] <= 0.547\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(181.28958125779963, 8.583157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(182.18840148075128, 8.583157894736843, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(183.53663181517874, 14.305263157894728, 'X[1962] <= 0.327\\ngini = 0.001\\nsamples = 2134\\nvalue = [2133, 0, 1]'),\n",
       " Text(183.08722170370294, 8.583157894736843, 'X[2994] <= 0.588\\ngini = 0.165\\nsamples = 11\\nvalue = [10, 0, 1]'),\n",
       " Text(182.6378115922271, 2.861052631578957, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(183.53663181517874, 2.861052631578957, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(183.98604192665456, 8.583157894736843, 'gini = 0.0\\nsamples = 2123\\nvalue = [2123, 0, 0]'),\n",
       " Text(182.862516647965, 31.471578947368414, 'X[3526] <= 0.669\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(182.41310653648918, 25.74947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(183.31192675944084, 25.74947368421053, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(184.2107469823925, 37.19368421052633, 'X[1119] <= 0.72\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(183.76133687091667, 31.471578947368414, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(184.6601570938683, 31.471578947368414, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(183.8034690688675, 60.0821052631579, 'X[3929] <= 0.531\\ngini = 0.15\\nsamples = 110\\nvalue = [101, 0, 9]'),\n",
       " Text(182.9046488459159, 54.360000000000014, 'X[3674] <= 0.704\\ngini = 0.463\\nsamples = 11\\nvalue = [4, 0, 7]'),\n",
       " Text(182.45523873444006, 48.6378947368421, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(183.3540589573917, 48.6378947368421, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(184.70228929181917, 54.360000000000014, 'X[2181] <= 0.871\\ngini = 0.04\\nsamples = 99\\nvalue = [97, 0, 2]'),\n",
       " Text(184.25287918034334, 48.6378947368421, 'gini = 0.0\\nsamples = 97\\nvalue = [97, 0, 0]'),\n",
       " Text(185.151699403295, 48.6378947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(181.78639009197016, 71.5263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(182.235800203446, 77.24842105263158, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(182.68521031492182, 82.97052631578947, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(176.56199754606374, 117.30315789473684, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(179.03375315918078, 128.7473684210526, 'X[1179] <= 0.592\\ngini = 0.35\\nsamples = 87\\nvalue = [68, 2, 17]'),\n",
       " Text(177.91022788049122, 123.02526315789474, 'X[2594] <= 0.561\\ngini = 0.398\\nsamples = 16\\nvalue = [3, 1, 12]'),\n",
       " Text(177.4608177690154, 117.30315789473684, 'X[4004] <= 0.349\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1, 0]'),\n",
       " Text(177.01140765753956, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(177.91022788049122, 111.58105263157894, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(178.35963799196702, 117.30315789473684, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(180.15727843787033, 123.02526315789474, 'X[3025] <= 0.857\\ngini = 0.157\\nsamples = 71\\nvalue = [65, 1, 5]'),\n",
       " Text(179.25845821491868, 117.30315789473684, 'X[1609] <= 0.094\\ngini = 0.058\\nsamples = 67\\nvalue = [65, 0, 2]'),\n",
       " Text(178.80904810344285, 111.58105263157894, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(179.7078683263945, 111.58105263157894, 'gini = 0.0\\nsamples = 65\\nvalue = [65, 0, 0]'),\n",
       " Text(181.05609866082196, 117.30315789473684, 'X[2905] <= 0.731\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(180.60668854934613, 111.58105263157894, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(181.5055087722978, 111.58105263157894, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(183.30314921820107, 134.46947368421053, 'X[4087] <= 0.416\\ngini = 0.554\\nsamples = 17\\nvalue = [8, 1, 8]'),\n",
       " Text(182.85373910672524, 128.7473684210526, 'X[871] <= 0.6\\ngini = 0.34\\nsamples = 10\\nvalue = [8, 1, 1]'),\n",
       " Text(182.40432899524944, 123.02526315789474, 'X[509] <= 0.492\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(181.95491888377362, 117.30315789473684, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(182.85373910672524, 117.30315789473684, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(183.30314921820107, 123.02526315789474, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(183.7525593296769, 128.7473684210526, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(185.32549471984228, 163.07999999999998, 'X[2067] <= 0.692\\ngini = 0.469\\nsamples = 215\\nvalue = [138, 3, 74]'),\n",
       " Text(182.85373910672524, 157.3578947368421, 'X[1771] <= 0.676\\ngini = 0.332\\nsamples = 41\\nvalue = [5, 3, 33]'),\n",
       " Text(181.95491888377362, 151.6357894736842, 'X[2725] <= 0.475\\ngini = 0.156\\nsamples = 36\\nvalue = [2, 1, 33]'),\n",
       " Text(181.5055087722978, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(182.40432899524944, 145.9136842105263, 'X[739] <= 0.347\\ngini = 0.057\\nsamples = 34\\nvalue = [0, 1, 33]'),\n",
       " Text(181.95491888377362, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(182.85373910672524, 140.19157894736844, 'gini = 0.0\\nsamples = 33\\nvalue = [0, 0, 33]'),\n",
       " Text(183.7525593296769, 151.6357894736842, 'X[225] <= 0.51\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2, 0]'),\n",
       " Text(183.30314921820107, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(184.20196944115273, 145.9136842105263, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(187.7972503329593, 157.3578947368421, 'X[2522] <= 0.861\\ngini = 0.36\\nsamples = 174\\nvalue = [133, 0, 41]'),\n",
       " Text(185.999609887056, 151.6357894736842, 'X[2012] <= 0.888\\ngini = 0.216\\nsamples = 138\\nvalue = [121, 0, 17]'),\n",
       " Text(185.10078966410435, 145.9136842105263, 'X[2322] <= 0.722\\ngini = 0.122\\nsamples = 123\\nvalue = [115, 0, 8]'),\n",
       " Text(184.65137955262855, 140.19157894736844, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(185.55019977558018, 140.19157894736844, 'X[1534] <= 0.931\\ngini = 0.08\\nsamples = 120\\nvalue = [115, 0, 5]'),\n",
       " Text(185.10078966410435, 134.46947368421053, 'X[1240] <= 0.225\\ngini = 0.05\\nsamples = 118\\nvalue = [115, 0, 3]'),\n",
       " Text(184.65137955262855, 128.7473684210526, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(185.55019977558018, 128.7473684210526, 'X[2069] <= 0.931\\ngini = 0.017\\nsamples = 116\\nvalue = [115, 0, 1]'),\n",
       " Text(185.10078966410435, 123.02526315789474, 'gini = 0.0\\nsamples = 115\\nvalue = [115, 0, 0]'),\n",
       " Text(185.999609887056, 123.02526315789474, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(185.999609887056, 134.46947368421053, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(186.89843011000767, 145.9136842105263, 'X[1379] <= 0.678\\ngini = 0.48\\nsamples = 15\\nvalue = [6, 0, 9]'),\n",
       " Text(186.44901999853184, 140.19157894736844, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(187.34784022148347, 140.19157894736844, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(189.59489077886258, 151.6357894736842, 'X[3240] <= 0.624\\ngini = 0.444\\nsamples = 36\\nvalue = [12, 0, 24]'),\n",
       " Text(188.69607055591095, 145.9136842105263, 'X[3596] <= 0.192\\ngini = 0.26\\nsamples = 13\\nvalue = [11, 0, 2]'),\n",
       " Text(188.24666044443512, 140.19157894736844, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(189.14548066738678, 140.19157894736844, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(190.49371100181423, 145.9136842105263, 'X[545] <= 0.914\\ngini = 0.083\\nsamples = 23\\nvalue = [1, 0, 22]'),\n",
       " Text(190.0443008903384, 140.19157894736844, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 22]'),\n",
       " Text(190.94312111329006, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(195.83045607558964, 174.52421052631578, 'X[1643] <= 0.518\\ngini = 0.515\\nsamples = 142\\nvalue = [62, 3, 77]'),\n",
       " Text(193.30252419853812, 168.8021052631579, 'X[2378] <= 0.731\\ngini = 0.423\\nsamples = 68\\nvalue = [48, 1, 19]'),\n",
       " Text(192.06664639197962, 163.07999999999998, 'X[2349] <= 0.592\\ngini = 0.279\\nsamples = 55\\nvalue = [46, 1, 8]'),\n",
       " Text(190.94312111329006, 157.3578947368421, 'X[3018] <= 0.569\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 0, 5]'),\n",
       " Text(190.49371100181423, 151.6357894736842, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(191.3925312247659, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(193.19017167066917, 157.3578947368421, 'X[3238] <= 0.853\\ngini = 0.152\\nsamples = 49\\nvalue = [45, 1, 3]'),\n",
       " Text(192.29135144771752, 151.6357894736842, 'X[2236] <= 0.959\\ngini = 0.043\\nsamples = 46\\nvalue = [45, 0, 1]'),\n",
       " Text(191.84194133624172, 145.9136842105263, 'gini = 0.0\\nsamples = 45\\nvalue = [45, 0, 0]'),\n",
       " Text(192.74076155919334, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(194.08899189362083, 151.6357894736842, 'X[2553] <= 0.437\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(193.639581782145, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(194.53840200509663, 145.9136842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(194.53840200509663, 163.07999999999998, 'X[3983] <= 0.659\\ngini = 0.26\\nsamples = 13\\nvalue = [2, 0, 11]'),\n",
       " Text(194.08899189362083, 157.3578947368421, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(194.98781211657246, 157.3578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(198.35838795264112, 168.8021052631579, 'X[3686] <= 0.818\\ngini = 0.349\\nsamples = 74\\nvalue = [14, 2, 58]'),\n",
       " Text(197.23486267395157, 163.07999999999998, 'X[1520] <= 0.349\\ngini = 0.19\\nsamples = 58\\nvalue = [4, 2, 52]'),\n",
       " Text(196.33604245099994, 157.3578947368421, 'X[546] <= 0.706\\ngini = 0.56\\nsamples = 5\\nvalue = [3, 1, 1]'),\n",
       " Text(195.8866323395241, 151.6357894736842, 'X[2891] <= 0.637\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(195.43722222804828, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(196.33604245099994, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(196.78545256247574, 151.6357894736842, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(198.13368289690322, 157.3578947368421, 'X[3877] <= 0.071\\ngini = 0.073\\nsamples = 53\\nvalue = [1, 1, 51]'),\n",
       " Text(197.6842727854274, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(198.58309300837905, 151.6357894736842, 'X[3035] <= 0.159\\ngini = 0.038\\nsamples = 52\\nvalue = [1, 0, 51]'),\n",
       " Text(198.13368289690322, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(199.03250311985485, 145.9136842105263, 'gini = 0.0\\nsamples = 51\\nvalue = [0, 0, 51]'),\n",
       " Text(199.48191323133068, 163.07999999999998, 'X[2218] <= 0.743\\ngini = 0.469\\nsamples = 16\\nvalue = [10, 0, 6]'),\n",
       " Text(199.03250311985485, 157.3578947368421, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(199.9313233428065, 157.3578947368421, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(207.00953259855072, 191.69052631578947, 'X[1568] <= 0.833\\ngini = 0.454\\nsamples = 349\\nvalue = [83, 23, 243]'),\n",
       " Text(203.30189917887517, 185.96842105263158, 'X[3166] <= 0.561\\ngini = 0.312\\nsamples = 274\\nvalue = [36, 14, 224]'),\n",
       " Text(200.83014356575816, 180.24631578947367, 'X[1517] <= 0.386\\ngini = 0.537\\nsamples = 50\\nvalue = [25, 2, 23]'),\n",
       " Text(199.7066182870686, 174.52421052631578, 'X[3977] <= 0.839\\ngini = 0.091\\nsamples = 21\\nvalue = [20, 0, 1]'),\n",
       " Text(199.25720817559278, 168.8021052631579, 'gini = 0.0\\nsamples = 20\\nvalue = [20, 0, 0]'),\n",
       " Text(200.1560283985444, 168.8021052631579, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(201.95366884444772, 174.52421052631578, 'X[1906] <= 0.802\\ngini = 0.39\\nsamples = 29\\nvalue = [5, 2, 22]'),\n",
       " Text(201.05484862149606, 168.8021052631579, 'X[3561] <= 0.155\\ngini = 0.095\\nsamples = 20\\nvalue = [0, 1, 19]'),\n",
       " Text(200.60543851002024, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(201.5042587329719, 163.07999999999998, 'gini = 0.0\\nsamples = 19\\nvalue = [0, 0, 19]'),\n",
       " Text(202.85248906739935, 168.8021052631579, 'X[3935] <= 0.422\\ngini = 0.568\\nsamples = 9\\nvalue = [5, 1, 3]'),\n",
       " Text(202.40307895592352, 163.07999999999998, 'X[2035] <= 0.853\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(201.95366884444772, 157.3578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(202.85248906739935, 157.3578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(203.30189917887517, 163.07999999999998, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(205.7736547919922, 180.24631578947367, 'X[2324] <= 0.388\\ngini = 0.19\\nsamples = 224\\nvalue = [11, 12, 201]'),\n",
       " Text(205.3242446805164, 174.52421052631578, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(206.223064903468, 174.52421052631578, 'X[165] <= 0.9\\ngini = 0.139\\nsamples = 217\\nvalue = [11, 5, 201]'),\n",
       " Text(205.7736547919922, 168.8021052631579, 'X[1443] <= 0.81\\ngini = 0.116\\nsamples = 214\\nvalue = [8, 5, 201]'),\n",
       " Text(204.65012951330263, 163.07999999999998, 'X[2334] <= 0.451\\ngini = 0.05\\nsamples = 195\\nvalue = [4, 1, 190]'),\n",
       " Text(203.751309290351, 157.3578947368421, 'X[2404] <= 0.924\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(203.30189917887517, 151.6357894736842, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(204.20071940182683, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(205.5489497362543, 157.3578947368421, 'X[1621] <= 0.714\\ngini = 0.031\\nsamples = 192\\nvalue = [2, 1, 189]'),\n",
       " Text(205.09953962477846, 151.6357894736842, 'X[3031] <= 0.202\\ngini = 0.021\\nsamples = 191\\nvalue = [2, 0, 189]'),\n",
       " Text(204.65012951330263, 145.9136842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(205.5489497362543, 145.9136842105263, 'X[1558] <= 0.788\\ngini = 0.01\\nsamples = 190\\nvalue = [1, 0, 189]'),\n",
       " Text(205.09953962477846, 140.19157894736844, 'gini = 0.0\\nsamples = 189\\nvalue = [0, 0, 189]'),\n",
       " Text(205.99835984773011, 140.19157894736844, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(205.99835984773011, 151.6357894736842, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(206.89718007068174, 163.07999999999998, 'X[610] <= 0.533\\ngini = 0.576\\nsamples = 19\\nvalue = [4, 4, 11]'),\n",
       " Text(206.44776995920594, 157.3578947368421, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(207.34659018215757, 157.3578947368421, 'X[1388] <= 0.404\\ngini = 0.391\\nsamples = 15\\nvalue = [4, 0, 11]'),\n",
       " Text(206.89718007068174, 151.6357894736842, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(207.7960002936334, 151.6357894736842, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(206.67247501494384, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(210.71716601822624, 185.96842105263158, 'X[3347] <= 0.9\\ngini = 0.529\\nsamples = 75\\nvalue = [47, 9, 19]'),\n",
       " Text(210.2677559067504, 180.24631578947367, 'X[1510] <= 0.847\\ngini = 0.411\\nsamples = 63\\nvalue = [47, 9, 7]'),\n",
       " Text(209.14423062806085, 174.52421052631578, 'X[1184] <= 0.735\\ngini = 0.145\\nsamples = 51\\nvalue = [47, 0, 4]'),\n",
       " Text(208.24541040510923, 168.8021052631579, 'X[395] <= 0.273\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(207.7960002936334, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(208.69482051658505, 163.07999999999998, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(210.0430508510125, 168.8021052631579, 'X[3518] <= 0.967\\ngini = 0.042\\nsamples = 47\\nvalue = [46, 0, 1]'),\n",
       " Text(209.59364073953668, 163.07999999999998, 'gini = 0.0\\nsamples = 46\\nvalue = [46, 0, 0]'),\n",
       " Text(210.49246096248834, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(211.39128118544, 174.52421052631578, 'X[2818] <= 0.616\\ngini = 0.375\\nsamples = 12\\nvalue = [0, 9, 3]'),\n",
       " Text(210.94187107396417, 168.8021052631579, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9, 0]'),\n",
       " Text(211.8406912969158, 168.8021052631579, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(211.16657612970207, 180.24631578947367, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(246.29447446503664, 203.13473684210527, 'X[1880] <= 0.367\\ngini = 0.574\\nsamples = 3856\\nvalue = [1045, 601, 2210]'),\n",
       " Text(219.59301571987373, 197.41263157894736, 'X[1496] <= 0.482\\ngini = 0.402\\nsamples = 482\\nvalue = [20, 357, 105]'),\n",
       " Text(216.6718499952809, 191.69052631578947, 'X[1896] <= 0.375\\ngini = 0.595\\nsamples = 101\\nvalue = [18, 28, 55]'),\n",
       " Text(214.31244691003283, 185.96842105263158, 'X[3109] <= 0.624\\ngini = 0.623\\nsamples = 55\\nvalue = [11, 27, 17]'),\n",
       " Text(212.73951151986745, 180.24631578947367, 'X[1566] <= 0.296\\ngini = 0.541\\nsamples = 22\\nvalue = [11, 1, 10]'),\n",
       " Text(212.29010140839162, 174.52421052631578, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(213.18892163134328, 174.52421052631578, 'X[3423] <= 0.68\\ngini = 0.272\\nsamples = 13\\nvalue = [11, 1, 1]'),\n",
       " Text(212.73951151986745, 168.8021052631579, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(213.6383317428191, 168.8021052631579, 'X[1616] <= 0.622\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(213.18892163134328, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(214.0877418542949, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(215.88538230019822, 180.24631578947367, 'X[2653] <= 0.771\\ngini = 0.334\\nsamples = 33\\nvalue = [0, 26, 7]'),\n",
       " Text(214.98656207724656, 174.52421052631578, 'X[2165] <= 0.941\\ngini = 0.074\\nsamples = 26\\nvalue = [0, 25, 1]'),\n",
       " Text(214.53715196577073, 168.8021052631579, 'gini = 0.0\\nsamples = 25\\nvalue = [0, 25, 0]'),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Tree Plot for Visual Representation of Tree\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(decision_trees) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis, Keep 90% of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14149, 153)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(X_train) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(X_test) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14149, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Trees model for PCA instance\n",
    "decision_trees_pca = DecisionTreeClassifier()\n",
    "\n",
    "# Use training data to fit Decision Trees model with transformed X_train\n",
    "decision_trees_pca.fit(X_transformed, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# make prediction on entire train data\n",
    "predictions_set_pca = decision_trees_pca.predict(X_train)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(y_train, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 ms, sys: 1.76 ms, total: 4.14 ms\n",
      "Wall time: 2.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire test data\n",
    "predictions_set_pca = decision_trees_pca.predict(X_test_transformed)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(y_test, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.68      0.68      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAH3CAYAAADaJXcPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABGmUlEQVR4nO3deXwURfrH8c9Dwn0knCEEVEBQwQsFRAQFRBEv8AR0V1lR1PV2dXV/u963q4u6igqi4HqAIoLKfaMoCoIgiCCKCCHcCVc4k/r90Z04hEwSWiYzMN+3r35lprq6uroZp6ufqq4x5xwiIiIihSkT7QqIiIhI7FJDQURERMJSQ0FERETCUkNBREREwlJDQURERMJSQ0FERETCSox2BURERA5Z2ZsjP8dApSSL+D6KoIiCiIiIhKWIgoiISFBxMGmhIgoiIiISliIKIiIigSmiICIiInFMEQUREZGgNEZBRERE4pkiCiIiIkEpoiAiIiLxTBEFERGRwBRREBERkTimiIKIiEhQcTBGQQ0FERGRoOKgoaCuBxEREQlLEQUREZHAFFEQERGROKaIgoiISFCHf0BBEQUREREJTxEFERGRoPTUg4iIiMQzRRREREQCU0RBRERE4pgiCiIiIkFpjIKIiIjEM0UUREREglJEQUqDmS03M2dmR0e7LrHGzI43s5FmlmFmO/xzNdTMjo923YIwsyQze8vMMs1ss5m9a2Y1i9mmg//5KGwZH5Kvd5g8NxVS5glm9plfh61m9o2ZnVogT6KZ3W9mP5nZLjNbZWb9iqhnP39/zxVIv8LMPjGzdDPbZmbfmlmvQrbvYWYj/H9rZ2a9C8kzuIhz0atA3hv8uu/093l2kLIOZr3MrLyZ/cfM1vif58/NrGWBsmqb2Uv+v8luM/s1zPkuSVklPl8i4aihEGVmdjpwlP9W/+OG8BtOs4BqwK3ABcDTQC3gxChW7Y/4AOgAXA/0BloBI4vZZi5weoGlh79ubCH5OxXIOyJ0pZmdDHwJZPnlXAF8ClQsUM5g4HbgOeBc4H5gR2EVNLNmQB9gSyGr7wa2AXcBFwNTgffM7LYC+S7H+3/hs8L24XuM/c/F28BeYGJIfXoBr/nrugKLgM8KNDBLVNbBrBfwEt55ehi4FO+8TDKzI0PypOH9u6wBvitinyUpq6T1ksBcKSzRZS4OwiaxzMxeAq4DFgLVnHPNolwlAMwsAUhwzu2OYh2eAG4C6jnndhVYZy7CH14zq+icK/TCGLC80/Eu0Gc552b4aa2Br4FznHOTDqCse/EaTQ2cc6v9tN7AW0BV59y2IradBfzinLuqiDzn4TUeTnLO/VCC+kz2j+3PwHDn3D0h62o55zYUyP8ecLpzrmFIWhnnXK6ZVQG2An9xzg0uwb4XAb8557qGpC0BZjrnrssrG5gPzHfO/ekAyzoo9TKz+sAKoK9zbpCfVh74BfjYOXdr6P78188BlzvnjipQdonKKukxyh+wcVXkL6I161vE91EERRSiyL8YXwl8ArwJHGdmJxWS70wzm+qHbTeb2TQzaxGy/kgze9/MNphZtpktMLOr/HV5YevjC5Q5zcyGh7wfbGZzzKy7/0WyEzjNzFLN7E0z+8UPby41s8fNrFyB8iqa2bNmtsK8MPVyM3vKX/esv70V2Ka3H1qtHeYUJQNZBRsJAAUbCWZ2iR+q3WFmG81sTOidlZl1MrOvzQtDrzWz/v4Xf976vPPUxbww+TbgZX/dEeZ1d2zyz+94MzsmTJ2L0hVYm9dI8I/jG2C5v+5A9AKm5zUSSsq/8z8N+G8xWa8DppSwkXA5cCxew2U/BRsJvnlAvQL5covbVyH7PhFoBrwfktYIaIoXvQkt+0OKOM+FlXUw6wWcgPedm38n73+2Z+BFyw5kfyUqq4T1kj/CucgvUaaGQnR1BFKAocBwYA8Fuh/MrAMw2V93LV5I8nO88CRmVgf4Ci+EfQ9wETAIaBCgPkcBzwJP4X2hLscL82/CCx+fB/wb+AshFxq/ATAKuBl4BTgfeMjfFrxGUEPgrAL7+wvwqXNufZj6zAUamdmL/gWuUGb2Z7zw+s94Da+/AEuB2v765sA4YANwmV+3q/DOeUGD8O48LwYGmVkN4AvgGLzoxpVAZbwQb36o3m94TQtXR9+xwI+FpC/215WImTUFWhD+y/5nM9trZkvM7MYC607z/1Y3s/l+vp/NrE8h+Zaa2ctmtsVvII0ws30u7v45eB643zm3vaTHgBcCX3oA+cPpideoHRmSlncuC57rxUCNIhqmhZV1MOtVwf9bMEq3Gzgy9PNUAkHLOpjHKHFCTz1EVy+8fuJxzrndZjYB6Glm/wi5Y34K78LVJSRtXEgZdwFJwKnOuQw/bXLA+tQEOjvnvgtJW4XXAAHAzGYC24E3zew2v2viXOAcoJtz7pOQbd8GcM796G/3F2CaX04joD3eBTmcIX7ZtwO3m9kmYAzwonNujl9OGbw72Y+dc6GNrNB6PIAXpr3YOZfjb7cJGGZmpzvnvgrJ+6Fz7oGQ430Mr2FwsnNuU8g5+BXvrvsVP2tOEceRpzrev3dBmUCjEmyfpydew/GjAukZeMf6DZDg53vNzCo55/IGIdb1/76N1yicjdcH/4aZZTjnxoTk64332esJVPXzf2xmbUI+i//w9/tOSStv3qDC7njn74/qAYxxzoWOjaju/80qkDczZH1hjdPCyjqY9Vrm/22F162T18huBZhfr5J2dQUt62AeowCl0X0f1X4HFFGIGj90fyneBS7vrmAocCTe3RZmVhnvzm5IEf3xnfAaGhlh1h+I9AKNBMxzp5n9YGY78C5Q7wLlgSNC6rCpQCOhoEHAZSHh/t7AWvZt9OzDObfXOdcDOAnvAvgt3h39V2aWF149Bi+E/VYR+26Nd55DL+Yf4Q3oalcg7+gC7zvjhXe3mPcUQCJeP/W3QP4Ic+fc2c65sykdPYEJeQ2XkDqMd8497pyb4Jwb65y7Fi/8/i+/QQW/f+e84Zx71jk31Tl3C94Aw3+EFGf+0s05N8Y5Nwxv/EFrvH9vzKwhXiPyjpKOFzGzo4D3gFEl6ecvpqzT8BpYfziMXhplOee+B2YCz5nZqX5k40m8bhKAEndxBCnrYB6jxBc1FKKnK14f/BgzSzazZLy77V383v1QHe/LuqhGQM1i1h+ItYWk3Yk36v1joBveheIWf11e+LMkdfgA78vrSv/O51rgbefc3uIq5Zxb4F8Az8VrGGQAj4fsm2L2n0qBY/MbDRuBGgXyFjwHtfDuwvYUWDpy4N07mXjRn4Kq8/vdbpHMG8NyHCX/sh+Od4xHhdQBvIZBqCl4fdehdf3eObcxJO0LvNB2Xr6n8Z66WBLyGS4DlPffFxyTUsPPvwK4uoT1L0pPvEZbwcZd3jEWPNfVC6wvSVkHs17gNZCzgTnAOryuwhfxPlMbC8lflAMt62Aeo+Q7/J96UEMhevIaAx/ifXFlAivx7tSvMG+gYybexTW1iHI2FrN+p/+3XIH06gUzUvgn8gq8Uez/9O9UZ+N1PRxIHfD7r4fifbl1wotGFBUFCFfOr3jnLK8fOu8Lsaj9ZwB1QhP881sTb/zFPrso8H4TXjdGq0KWWzgwP1L4WIRwYxcK0xMvpDyqhPldgb+L/b8Fo5nGvnehiwvJUzDfMXhRscyQpQHeo6yZ+ONoAMysEt7jheWAC51z2SWsf6H8CMmVwMhCnkzJO5cFz/WxeJGvfbodiinrYNYL59wy51wLoLFfnxPw/p+f65zbcyD7OpCyDuYxSgEazCiR4HcpXIR3V9ixwHI33gDHTv7F9WvgmoJ3ZyEmA13MLCXM+lX+3+NC9t+Akg+eq4gX5QhV8G5wMt4gsQuLKWsQ3riEh4FZzrkiL47+QM3CNOH3O/8lQDpehCKcr4FL/MZBnkvxxuh8UUydJwPNgUXOuTkFliXFbFvQWKCumeV3d5g3QU4jCp8PoTA98QaAhn38sYDL8QZxrvDff4l3Ee9UIN/ZeOMR8nwGnGBmtULSzgTKhuS7nv0/v2vxokcd8ccB+N01H+L9u53nnFtXwroX5Uy8Lqf9IivOuV/wBkpekZfmXyivoPDzHLasg1mvgnX0Pz818S7gg4LusIRlHcxjlDijwYzR0Q2ohDco7+vQFf5AuX/iRRwm4k1yMwkYa2YD8O7mTwfmOOc+A/oB1wCfmzfvwEq8RkFlvw96lZnNAR4zs2y8xuH/sf+ddDgT8QYSfo33VMHVQMEZJCcC4/Em0XkU72mFVOBM51z+qHvn3NfmPXrZDig4Gr8wD/ih9vfw7nAr413gL8IfYOm859v/DrxrZu/ifRE6vAvh+/6gx8fxHscbaWavAvWBZ4DxBQYyFuY/wJ+AKWb2X7xGSQreExxfOOfeh/x5BChqnIJz7it/wOrbZnYP3p35M345+XMomNkgvLkW9jnPZtYGrwvhrsLKN7OP8AYyLsAbzNjDX27Pe+TOHzT7KPCsmWXhDWa8DO9CEvpUygC8QaSfmtmTeIMZnwEmOee+8MuaU0gddgIrnXPTQpL74z0JcwdQ0/adiXKe/1hf3qObzfi9S6uleY+prnfOTS+wq554DaBwkwY9DLxj3qyGM/Eakk3wnnYpqMiyDma9zOx2vChYul+ffwDfU+Dibt4jp+CNOagU8n56XkSkpGWVpF7yB8TAHX/EOee0lPKCN0p5aRHr++ON2C7vvz8L7/nobD99Kt4o/Lz8RwLD8O4Us/FHqoesPxpv/MN2vDvwbv774SF5BuM1PgrWpQpeF8Emf3kDuBDvYnx8SL6KeGMZVuFFIJYDTxRS3uN+HauV4Dy18ff9k7/NBrw74p6F5L0Ub4DhTrwvz9HAkSHrz8aLLOzE68/tD1QJWd+h4DGFrMsbLLnWP7Zf8Ub5Nw/JMw2YVoJjSvbLysKbxfA9oFaBPIOBXwvZ9oXQz0Uh65/0/32z8bonvgX+HCbv3f6/0W68i8ulheQ5Gu8pk+3+Z2swUL2Y4/sVeK6QtHCdr0eF5Hs4TJ5pBcpLxItWvFZMXW7AezpgF17j9exC8hRb1sGsF3Cff9534TXqnwEqFZIv3PnqEKCsEp0vLcGW3DW/uEgv0T5GzcwopcrMvgGWOOf+HO26iIj8UW7tLxG/iFpKo6g+IamuBykVfl98J4INAhQRkShRQ0FKy2y8sPk/nPfkhIjIoS8OovJqKEipcM5Fe3IxEREJQA0FERGRwBRRiKbD/+yLiEgkKZJ5EMRyQwG3sthfuJU4Yg28mYP/atWiXBOJJf393zeaVDutmJwSTzqvTy+dHcXBGAXNzCgiIiJhxXREQUREJKYpoiAiIiLxTBEFERGRwBRREBERkTimiIKIiEhQh39AQREFERERCU8RBRERkaD01IOIiIjEM0UUREREAjv8IwpqKIiIiASlrgcRERGJZ4ooiIiIBKWIgoiIiMQzRRREREQCU0RBRERE4pgiCiIiIkFpjIKIiIjEM0UUREREgnK50a5BxCmiICIiImEpoiAiIhKUxiiIiIhIPFNEQUREJKhcjVEQERGROKaIgoiISFAaoyAiIiLxTBEFERGRoDSPgoiIiMQzRRRERESC0hgFERERiWeKKIiIiASlMQoiIiISzxRREBERCciVwhgFi/geiqaGgoiISFCawllERETimSIKIiIiQWkwo4iIiMQzRRRERESC0oRLIiIiEs8UURAREQlKYxREREQknimiICIiEpTGKIiIiEg8U0RBREQkKI1REBERkXimiIKIiEhQuRqjICIiInFMEQUREZGgNEZBRERE4pkiCiIiIkFpHgURERGJZ4ooiIiIBKUxCiIiIhLLzOwuM1tkZgvN7H0zq2BmDc3sazNbZmbDzKycn7e8/36Zv/6o4spXQ0FERCQo5yK/FMHM0oDbgZbOueOBBKAn8AzQzzl3NJAJ9PE36QNk+un9/HxFUkNBREQkKJcb+aV4iUBFM0sEKgEZQCdguL9+CNDdf93Nf4+//mwzs6IKV0NBREQkhplZXzObE7L0zVvnnEsHngN+w2sgbAa+BbKcc3v9bKuANP91GrDS33avn79mUfvXYEYREZGgSmEKZ+fcAGBAYevMrDpelKAhkAV8CJx3MPeviIKIiMihqzOw3Dm33jm3BxgBnAEk+10RAPWBdP91OtAAwF+fBGwsagdqKIiIiAQV/TEKvwFtzKySP9bgbOAHYCpwuZ/nWmCU//oT/z3++inOFT1iUg0FERGRQ5Rz7mu8QYlzge/xrusDgPuAu81sGd4YhEH+JoOAmn763cD9xe1DYxRERESCioEJl5xzDwEPFUj+BWhdSN6dwBUHUr4aChEyePgnDB87CTNo0vBInrr3NuYu/JF/DxhCrsulUoUKPPX32zkyLRWAsdNm8vLbQzEzjml0FM//8+79yly49Gf+8exL7Nq9mzNbn8o/b+mDmZG1ZSt3P/486WvXkZZSh34P3ENS1So453jilUHM+OZbKpQvz1N/v43mTRqX9qmQIjy2/Ht2bt1Gbk4OuXv38kyrDgB0uPVGzrzlBnJzclg0ejwf3/fgfts269KZK158BktI4Ms3hjDhmX4A1DzqSK4b+haVa9Zg5bfzGPznvuTs2UNiuXJc+/brNDi1Bds3bmJQj95sWvFbaR6uFKJ8vXo0f+VFytWuBc6R/r93WTlgEI3uv5fa550LzrF7/QYW3XYXu9euBaB629Np+sQjWGIiezZt4ttul+9XboUjGnDCgP6UrVGdLfO/Z9Ffb8ft2YOVK0fzV16k2kknsGdTJt/fcDM7V64C4Kg7bqXe1T1xObks+b8H2DR1eqmeC4lN6nqIgLUbNvK/kaMZ3v/ffPrGS+Tm5DJ66hc8/OJr/PsfdzLy9X5c2OlMXn33QwB+XbWaAe9/xHsvPsVng17i//56XaHlPvLiazx2918ZP6Q/K9JX8/nsuQAMHDqCNi1OYPyQ/rRpcQIDh44AYMY3c1mRvprxQ/rz6F0388iLr5fOCZAD8kLHC3iqRbv8RkLTDu05sdv5PHlSWx4//jQmPvfSfttYmTL0eOV5Xu56GY81a0XLXpdT97hjAOj+zCNM6fcKDzc5mezMLNr2uQaAtn2uITszi4ebnMyUfq9wyTOPlNoxSnguZy8/PfQIs9p1ZPZ5F1H/ut5UbtqEFS+/ytcdzuHrjueyYeIkGt1zFwCJ1apxzLNP8t2fejOrfScW9Lmx0HKbPPhPfnttIF+2bsferM3Uu7oXAGlX92Jv1ma+bN2O314byNEP/hOAyk2bkNK9G1+168S8Hldz7DNPQhldIorjnIv4Em0R+xSY2bFmdp+ZveQv95nZcZHaX6zJyclh567d7M3JYceuXdSpWQMzY1v2DgC2bs+mTs0aAHw4ZiJXdetKUtUqANSsnrxfees2bmJb9g5ObnYMZka3czoyaeY3AEz+8hu6n9sRgO7ndmTSzK/z07ud0xEz4+Rmx7Bl23bWbdwU6UOXP6j9zX0Y/3Q/9u7eDcC29Rv2y3NU65asX/YLG5f/Ss6ePXw79CNO6nYBAMd0Oot5w0cCMGvI+5zU/UIATux2AbOGvA/AvOEjOebsDpE/GCnW7rXr2LpgIQA527eTvfQnyqfWJWfbtvw8CZUq5c/QV/eyS1g/eiy70lcDsGdD4QPWq7c7g3WfjgYgY9iH1Dm/CwC1u55LxjDvJmXdp6Op0b6dn96FtSNH4XbvZudvK9nx668kndIiAkcsh5qIdD2Y2X1AL2Ao8I2fXB9438yGOueejsR+Y0VKrZpcd0U3Ol3Vl/Lly3HGqSfTruXJPP63W+j7f49RoXx5qlSqyLD/ejNn/rrK+x++1x3/IDcnl1uv6UH71qfsU+baDZuoW+v3OTHq1q7JWv8LYmNmVn6jo3aN6mzMzPK32Uhq7YLbbMrPK9HnnOO2CSPBOT5//S1mDhxMnaZHc3T7tlz8xIPs3bmTEff8ixVz5u6zXXJaKpl+uBggc9VqjjqtJZVr1iA7azO5OTkAZK1KJ9nv3grdJjcnhx2bt1C5Zg22q/EYMyo0qE/VE45n87fzAGj8f/eReuXl7N2yhW8v8bqVKzVuhJVN5NSRH5JQpQorBwwi44Ph+5RTtkZ19m7ZjPM/BztXZ1C+bl0Aytety06/keFycti7ZQtla1SnfGpdNod8znauzqB8at2IH/MhLwbGKERapCIKfYBWzrmnnXPv+MvTeAMr+oTbKHT2qQEDCp1b4pCwees2Jn/5DZPeeY0ZwwaxY+dOPpk0jSEffcKAJx9g+tA3uLRLJ55+7S0A9ubksCI9g7eff4zn/3k3D/Trz5Zt2wPt28woZjZOiSHPt+vC06eeyctdL+OsW27g6PZtSUhMpHKN6vy7TSdG3PsAfT4YHO1qSilIqFyJE98ayJJ/PZQfTfj5yWf44uRWrPnoYxr0+QsAlphAtRNPZN5V1zDvyqto+Lc7qdSoUTSrLoe5SDUUcoF6haSn+usK5Zwb4Jxr6Zxr2bdv33DZYt5Xc+dTv24KNZKTKJuYyDnt2jB34Y/8+POvnHRcUwC6dmjHvEU/At6dfsfTW1E2MZH6qSkcVb8eK/woQ56UWjVYExJiXLN+Iyl+hKFm9eT8LoV1GzdRIznJ36YmGesLbqNoQizZvDoD8LoX5n/8GUe1PpXMVav5bsQnAKyY/S0u11Gl1r4zrGalZ1C9Qf3899Xr12Nz+mq2b9xEpeQkyiQkAJBcP42s9Iz9timTkEDFpGqKJsQIS0zkxLcGsmb4x6wfPXa/9RnDR1DnwvMB705/49Rp5GbvYM+mTDK/mkWV45vtk3/PpkwSqyVh/uegQr1Udq1ZA8CuNWuokOZ9PVtCAonVqrFnUya7Mn5Pz98mY01EjvewEuUfhSoNkWoo3AlMNrOxZjbAX8YBk4E7IrTPmJFapzbzFy9lx85dOOf4at4CGh/ZgK3bs1m+ypsc68u582l0hPel3bntaXwz3+ujzNy8hV9XraZ+aso+ZdapWYMqlSry3Q9LcM4xauJUzm7rPfnS6fRWjJwwFYCRE/ZNHzVxKs45vvthCVUrV1K3QwwpV6kS5atUyX993LmdWL1wMQtGfkbTjmcCUKfJ0SSWK8u2Av3QK2Z/S50mjah51JEklC3LqT0vY8EnYwBYOnUGLS7vDkCba3uxYJTXT73gkzG0udYb0Nbi8u4smaIR7bGi2QvPs33pMn577fdIasVGDfNf1+nahe3LfgZg/djxJJ/WGktIoEzFCiSd0oLtS3/ar8zMmV9S5yJv3EpqjytYP3aCt/24CaT28Lox6lx0AZlfzMxPT+neDStXjgpHNKBiw4ZsnjsvMgcshxSL1IhKMyuD19WQ90MU6cBs51xOCYtwbuUPEalbaXhpyPuMnTaTxIQyHHd0Ix6/+xamf/MtLw1+nzJlylCtSmWevOdWGtSri3OOp197iy9mz6NMmTLcdPXlXNCxPQDdb7yLka97j719v2QZ//fvl9i5azftW5/CA7fegJmRuXkLdz3+HBnrNlCvTm36PXAPydWq4pzjsf8O4PPZ86hQvjxP3nsbJxxzdDRPyx9iDby7pr9atSjX5OCo2fAobvz4XQDKJCYy570PGffkcySULcuf3+xP/ZNPYO/u3Yy4518snTqDpNS6XP3Gy/S/wHsUrnnXc7n8hacpk5DAV2/+j3FPPpdfbp+hb1GpRnVWzZvP4D/dwN7du0ksX57e/xtA/RYnkb0pk0E9/8LG5b9G6/APmv5uCwCTaqcVkzM2JZ3WilafjWTroh/y7x6XPfE0aVf3pFLjxrjcXHauSufHe+7PjwocectNpPbqAbm5pL/7PitffwOAk99/mx/uvJfda9dS8cgjOH5Af8pWT2br94tYePNtuN27KVO+PM37v0TVE5qzJzOLhX3/yg7/Mdmj7rqder164HJyWPqvh9g4eWp0TspB0Hl9OkDE+2FzZgyL+C1/wpk9otqfHLGGwkFwSDcU5OA73BoKcnAc6g0FiQw1FA4eTbgkIiISVCn8emS0aTYNERERCUsRBRERkaA0j4KIiIjEM0UUREREgordBwIOGjUUREREglLXg4iIiMQzRRRERESCioOuB0UUREREJCxFFERERILK1RgFERERiWOKKIiIiASlMQoiIiISzxRREBERCUrzKIiIiEg8U0RBREQkKI1REBERkXimiIKIiEhQmkdBRERE4pkiCiIiIkFpjIKIiIjEM0UUREREgtI8CiIiIhLPFFEQEREJKldjFERERCSOKaIgIiISVByMUVBDQUREJCg9HikiIiLxTBEFERGRoOKg60ERBREREQlLEQUREZGg9HikiIiIxDNFFERERILSGAURERGJZ4ooiIiIBKV5FERERCSeKaIgIiISlJ56EBERkXimiIKIiEhQeupBRERE4pkiCiIiIkHpqQcRERGJZ4ooiIiIBKUxCiIiIhLPFFEQEREJSvMoiIiISDxTREFERCQojVEQERGReKaIgoiISFBxMI+CGgoiIiJB5arrQUREROKYIgoiIiJBxUHXgyIKIiIiEpYiCiIiIkHp8UgRERGJZ4ooiIiIBKUxCiIiIhLPFFEQEREJSvMoiIiISDxTREFERCQojVEQERGReBbTEQVr0CzaVZAY1N9tiXYVJAZ1Xp8e7SpIPNI8CiIiIhLPYjqicJNVi3YVJIa8lhdJyN4c3YpIbKmUBMArVWpFuSISS27ZtqF0dpSrMQoiIiISx2I6oiAiIhLTNEZBRERE4pkiCiIiIkFpHgURERGJZ4ooiIiIBBUHEQU1FERERILSj0KJiIhIPFNEQUREJKg46HpQREFERETCUkRBREQkKEUUREREJJ4poiAiIhKUIgoiIiISzxRREBERCUrzKIiIiEg8U0RBREQkKI1REBERkXimiIKIiEhQiiiIiIhIPFNEQUREJCg99SAiIiKxzMySzWy4mf1oZovN7HQzq2FmE83sJ/9vdT+vmdlLZrbMzBaY2SnFla+GgoiISFDORX4p3ovAOOfcscBJwGLgfmCyc64JMNl/D9AVaOIvfYFXiytcDQUREZFDlJklAWcCgwCcc7udc1lAN2CIn20I0N1/3Q1423lmAclmllrUPtRQEBERCSr6EYWGwHrgLTObZ2ZvmFllIMU5l+HnWQOk+K/TgJUh26/y08JSQ0FERCSGmVlfM5sTsvQNWZ0InAK86pxrAWzn924GAJxzDgj8HKeeehAREQmqFOZRcM4NAAaEWb0KWOWc+9p/PxyvobDWzFKdcxl+18I6f3060CBk+/p+WliKKIiIiASVmxv5pQjOuTXASjM7xk86G/gB+AS41k+7Fhjlv/4EuMZ/+qENsDmki6JQiiiIiIgc2m4D3jWzcsAvwF/wAgEfmFkfYAVwpZ93DHA+sAzI9vMWSQ0FERGRoGJgCmfn3HdAy0JWnV1IXgfcciDlq+tBREREwlJEQUREJKgYiChEmiIKIiIiEpYiCiIiIkEpoiAiIiLxTBEFERGRgJx+ZlpERETimSIKIiIiQcXBGIWwDQUz28rvPyJh/l/nv3bOuWoRrpuIiIhEWdiGgnOuamlWRERE5JATBxGFEo1RMLN2ZvYX/3UtM2sY2WqJiIhILCh2jIKZPYQ3h/QxwFtAOeAd4IzIVk1ERCTGKaIAwCXAxcB2AOfcakDdEiIiInGgJE897HbOOTNzAGZWOcJ1EhEROTRoHgXA+z3r14FkM7sBmAQMjGy1REREJBYUG1Fwzj1nZucAW4CmwIPOuYkRr5mIiEisi4MxCiWdcOl7oCLePArfR646IiIiEkuK7Xows+uBb4BLgcuBWWZ2XaQrJiIiEvOci/wSZSWJKNwLtHDObQQws5rAl8CbkayYiIhIzIuBC3mklWQw40Zga8j7rX6aiIiIHOaK+q2Hu/2Xy4CvzWwU3hiFbsCCUqibiIhIbIuDxyOL6nrIm1TpZ3/JMypy1REREZFYUtSPQj1SmhURERE55MTBGIWS/NZDbeDvQHOgQl66c65TBOslIiIiMaAkgxnfBX4EGgKPAL8CsyNYJxERkUNDHDweWZKGQk3n3CBgj3NuunPuOkDRBBERkThQknkU9vh/M8zsAmA1UCNyVRIRETlExMAdf6SVpKHwuJklAX8D/gtUA+6KaK1EREQkJpTkR6E+819uBjpGtjoiIiKHkHieR8HM/os3wVKhnHO3R6RGIiIiEjOKiijMKbVaiIiIHIrieYyCc25IaVbkcPfE8u/ZuXUbuTk55O7dy1OtOlCpenVuGPYWNY86ko2/rmDglb3Jzsrab9s211zF+f+6F4Axj/+bWW+/B8ARp5zMtYNfpWzFiiwcM4EP7vg7QInLldI35L2hfDhiJM45rri0O72v7sWPS5by0BNPk71jB2n1UnnuiUepUqVK/jarM9ZwwWU9uPWmG+hzzZ/2K3Nlejp33/8vsjZvpvlxx/Ls449QrmxZdu/ezd8feJhFi38kOSmJfs88Qf169QB4fdBgho/6hDJlyvCvv/+N9m1PL7VzIPvr1P9Fjux6LjvWb2Bo6/YAtH7gfhpe0BVyc8lev4HJN95G9po1ANRrfwbtn3mcMmXLsmPjJkaed/F+ZVY98gi6DB5IhRrVWffdAiZdfzO5e/ZQplw5Og/sT52TT2TnpkzGX3s9W39bCcApf7uDZtdcTW5OLp/f+w9WTp5aeidBYlZJHo+Ug+Q/HS/giRbteKpVBwDOu/8ufpw8nQebtuDHydPpcv/+Y0QrVa/OBQ/dx9OndeLp1h254KH7qJScDMBVr/bjnRtu58EmJ1OnSWOan3dOicuV0rd02c98OGIkH/5vMKOGvcu0GV+w4reV/PPRJ/jb7bfy6Yfv07ljB94Y8s4+2z39/Au0PyP8hfy5F1+m99W9mPjJCKpVrcrwj71Z1j8c+QnVqlZl4icj6H11L5578WUAlv38C6PHT2D08KG88cqLPPLUs+Tk5ETsuKV4i98dyqfde+yTNu+FlxnW5iyGte3IinETaPWPewAol1SNs/o9y+gr/8T7rdox/s/XFVpm28ce5LtXXuOdk1qzKyuL4671GpnNrr2aXVlZvHNSa7575TVOf+whAKof25Qml1/Ce63a8eklV3JWv2exMrpEFEvzKEgkndjtAr4a4kUHvhryHid1v3C/PM26nM3iiVPJzswkOyuLxROn0uy8zlSrm0KFalVZ/rU399Wst9/npO4XlLhcKX0/L1/Oicc3p2LFCiQmJtLq1FOYMGUqv/72G61ObQHAGW1OY0LIXdykqdNIS6tHk8aNCi3TOces2XPo0tmb2uSSiy5g8rTpAEyZNp1LLvI+E106d+Krb2bjnGPytBlc0OVcypUrR4O0NI5sUJ8FCxdF8tClGBkzv2JXZuY+aXu2bst/nVipUv4Fo+mVl/HLJ5+xbVU6ADvWbyi0zLSz2vPzx58A8OO7Q2l0YVcAGl7QlR/fHQrAzx9/Qv0O7fPTfxr+Mbm7d7N1xW9s/mU5dVqechCPUg5Vpd5QMLO/lPY+Y4FzjjsmjOQfc6bT7obeAFRLqc2WNWsB2LJmLdVSau+3XfW0VDJXpue/z1q1muppqSSn1SNzVWh6Oslp9UpcrpS+po0b8+2878jMymLHjp3M+GIma9aspUmjRvkX93ETJ5Gx1vu3256dzcC33ubWG68PW2Zm1maqVa1KYqLXi1g3JYW169YDsHbdelLrpgCQmJhI1SpVyMzazNr166nrpwOk1KmTv43EltMe+j+u+XE+TXtcztePPw1A8tGNKZ+cTPexo7ji88kc0+vK/barULMGu7M24/xI0fb01VSulwpA5Xqp+Y0Ml5PD7s1bqFCzhp++Or+MbemrqeJvI0WIg4hCNJ56eAR4K8w++wJ9AV5//fWAxcem59p1IWt1BlVr1+KOiaNY8+PS/fK4CH0gIlWuHJjGjRpyfe9r6PPX26lYoQLHHtOUMgkJPPHwAzzx7PP0H/gmnc5qT7my3v+WL782kGv/1IvKlSpFueYSLV8/8iRfP/Ikp/ztDk688Xq+eeIZLDGR2iefxKgLLyWxYgUumzyONbO/ZfOyn4svUCSAiDz1YGYLwq0CUsKswzk3ABiQ9/amG+8JWoWYk7U6A4Ct6zfw3cef0bD1qWxZu55qdVO8u/66KWxdt38IMTM9g6Yd2uW/T65fj6XTviArfTXV66eFpKeRle7dDZSkXImOKy7pxhWXdAPgP//tT0pKHRo3PIo3X/0vAMtXrGDa5zMBmL9wIeMnTeG5F15my9atlClThvLlyvGnnr/fQVZPTmLL1q3s3buXxMRE1qxdS0odL4KUUqc2GWvWUjclhb1797J12zaqJyeRUrs2a/yIE8Dadevyt5HYtHTYcC4cMZRvnniG7emrWbkpk73Z2ezNzmb1zC+pdULzfRoKOzduolxyEpaQgMvJoXJaPbb730HbV2dQpX4a21dnYAkJlEuqxs6Nm/z0evllVEmrxzZ/GylC7uF/Ixa268E5N6SopZhyU4BrgIsKWTYerMofKspVqkR5fxR7uUqVOO7cTqQvXMyCT8Zw+rVXAXD6tVexYNTo/bb9Yfxkmp3biUrJyVRKTqbZuZ34YfxktqxZy84tW2l4WisA2lzTiwWjxgCUqFyJjo2bNgHekwwTpkzloq5d8tNyc3N5deCb9Lz8UgDee3MgU8aMYsqYUVx7dU9u7NN7n0YCgJlxWstTGT9pCgAffzqaTh3OAqDTWWfy8afev/34SVNo06olZkanDu0ZPX4Cu3fvZmV6Or/+tpITj29eKscvJZcUMi6l4YVdyVz6EwDLR48l9fTTsIQEEitWJKXVqWQu2T9CmT7jCxpf4j0NcezVPVk+eqy3/ZhxHHt1TwAaX3Ix6dM/B+DXMeNocvkllClXjqpHHkFS40asmzM3oscoh4aS/sz0fUAzSv4z058BVZxz3xVS3rQDruUhrlpKHW76+F0AyiQmMvu9D/lh/CRWzJ7LDR8M5ow+17BxxW8MvLI3AEec2oIzb7qOd264jezMTMY89iz3z54GwOhHnyHbH/T03l/v5trBr1KuYkUWjZ3IwrETABj/dL9Cy5Xou+2e+8jK2kJiYgIP3X8v1apWZch7Q3lv2IcAnNOpI5d1u6jYcm649U4ef/CfpNSpzb133MZd9/+TF/q/xnHHNOWK7t7F4fLuF3Pvvx7inIsvJalaNfo9/QQATRo3puu5nTn/sh4kJCTw4P1/JyEhIXIHLcU6560BpLU/gwo1a3DtkgV888QzHNmlM8lNjsbl5rL1t1VMv+NvAGQu+YnfJk6h59czcLm5/DD4HTb98CMAF370PlNuuYvsNWv46oFHOXfwQNo88A/WL/ieH4Z430GLh7xL5zf686f537AzM4sJvW8AYNPiJSwbMYqr5swkd28OM+6+DxcHsw7+UfHQtWvFHaSZTQCGAfcANwHXAuudc/dFuG7uJqsW4V3IoeQ1t8V7kb05uhWR2FIpCYBXqtSKckUkltyybQN43d0Rtefm8yPeUij76piIH0dRSvKjUDWdc4PM7A7n3HRgupnNjnTFREREYl4cjFHQz0yLiIgEFQddD/qZaREREQlLPzMtIiISkFPXA5jZWxQy8ZJzrvAJxkVEROSwUZKuh89CXlcALsEbpyAiIhLfNEYBnHMfhb43s/eBLyJWIxEREYkZJYkoFNQEqHOwKyIiInLI0RgFMLOt7DtGYQ3eTI0iIiJymCtJ10PV0qiIiIjIoSYepnAO+6NQecxscknSRERE5PATNqJgZhWASkAtM6vO73NmVwPSwm0nIiISN+J8jMKNwJ1APeBbfm8obAFejmy1REREJBaEbSg4514EXjSz25xz/y3FOomIiBwSNEbBk2tmyXlvzKy6mf01clUSERGRWFGShsINzrmsvDfOuUzghojVSERE5FDhXOSXKCtJQyHBzPLGJ2BmCUC5yFVJREREYkVJZmYcBwwzs9f99zf6aSIiIvEtzp96yHMf0Be42X8/ERgYsRqJiIhIzCjJzIy5wGv+gpm1B/4L3BLZqomIiMS2eHjqoUQ/CmVmLYBewJXAcmBEJCslIiIisaGomRmb4jUOegEbgGGAOec6llLdREREYlucj1H4EfgcuNA5twzAzO4qlVqJiIgcCuKg66GoxyMvBTKAqWY20MzO5vdpnEVERCQOFDWF80hgpJlVBrrh/e5DHTN7FfjYOTehVGooIiISo1wcdD0UO+GSc267c+4959xFQH1gHt4jkyIiInKYK9FTD3n86ZsH+IuIiEh8i/MxCiIiIhLnDiiiICIiIr9zudGuQeQpoiAiIiJhKaIgIiISlMYoiIiISDxTREFERCQozaMgIiIi8UwRBRERkYDi4WemFVEQERGRsBRREBERCUpjFERERCSeKaIgIiISlMYoiIiISDxTREFERCQgpzEKIiIiEs8UURAREQkqDsYoqKEgIiISkLoeREREJK4poiAiIhJUHHQ9KKIgIiIiYSmiICIiEpTGKIiIiEg8U0RBREQkIP3MtIiIiMQ1RRRERESCUkRBRERE4pkiCiIiIkHpqQcRERGJZ2ooiIiIBOSci/hSEmaWYGbzzOwz/31DM/vazJaZ2TAzK+enl/ffL/PXH1Vc2WooiIiIHPruABaHvH8G6OecOxrIBPr46X2ATD+9n5+vSGooiIiIBORyI78Ux8zqAxcAb/jvDegEDPezDAG6+6+7+e/x15/t5w9LDQUREZEYZmZ9zWxOyNK3QJYXgL8Dec2KmkCWc26v/34VkOa/TgNWAvjrN/v5w9JTDyIiIgGVxsyMzrkBwIDC1pnZhcA659y3ZtYhEvtXQ0FEROTQdQZwsZmdD1QAqgEvAslmluhHDeoD6X7+dKABsMrMEoEkYGNRO7AYnqc6ZismIiKHhCL73g+GjacfH/FrVc2vFpboOPyIwj3OuQvN7EPgI+fcUDN7DVjgnOtvZrcAJzjnbjKznsClzrkriypXYxREREQOP/cBd5vZMrwxCIP89EFATT/9buD+4gqK6YjCmFqp0a6DxJDzN2QA8E5ynSjXRGLJn7LWAZA769Mo10RiSZk2F0EpRBQ2tGke8YtorVmLIn4cRdEYBRERkYBi91774FHXg4iIiISliIKIiEhAMdx9f9AooiAiIiJhKaIgIiISUBwEFBRREBERkfAUURAREQkoNw5CCoooiIiISFiKKIiIiAQUBwEFRRREREQkPEUUREREAnK5h39IQREFERERCUsRBRERkYA0RkFERETimiIKIiIiASmiICIiInFNEQUREZGA9OuRIiIiEtcUURAREQkoDgIKiiiIiIhIeIooiIiIBBQPvx6phoKIiEhAcdBOUNeDiIiIhKeIgoiISEB6PFJERETimiIKIiIiAcVBQEERBREREQlPEQUREZGANEZBRERE4poiCiIiIgG53GjXIPIUURAREZGwFFEQEREJSGMUREREJK4poiAiIhJQHAQUFFEQERGR8BRREBERCSgefmZaEQUREREJSxEFERGRgOIgoKCIgoiIiISniIKIiEhAmkdBRERE4poiCiIiIgHFQUBBEQUREREJTxEFERGRgOJhjIIaCiIiIgHFQTtBXQ8iIiISniIKIiIiASmiICIiInFNEQUREZGAXO7hH1JQREFERETCUkRBREQkoDgIKCiiICIiIuEpoiAiIhJQPEy4pIiCiIiIhKWIgoiISECHfzxBEQUREREpgiIKIiIiASmiICIiInFNEQUREZGA9NSDiIiIxDVFFERERAI6/OMJaihERIV69Tip/0uUq10bnGPl2+/w64A3qHvxhTT5+z1UadqEL889n83fzQeg3uWX0uiWm/O3r9q8GV90OpetCxftU27Z5GRavPEaFY9owI7fVjK3z43s3bwZgGZPPkbtzmeTs2MHC267ky0LvgcgrccVHP23OwFY9vwLpA/7sBTOgITT5uUXqN/lHHau38Bnbc/KTz+mbx+aXn8dLieH9AmTmPfQowAkN2/Gaf2eo2zVKrjcXMZ26kLurl37lFkuOZn2bw2k8hEN2P7bSj7vfT27/c9Fy2eeIO2czuzdsYOv/nobm+Z7n4tGvXpw/D13AbDwuX788v6w0jh8KcTyjHXc3f+d/Pcr123ktku7cNpxR/Pw4I/I3rWLtFrV+fdNV1OlYgU+/XIub46dlp9/ycoMPnrkTo47Mm2fcrO2ZXN3//+RviGTtFrV6XfLn0mqXAnnHE++O4oZ8xdToVw5nryhB82Pqg/AyC9m8+onkwG4+eKz6d6uVeRPgMQ8NRQiwOXsZfGDj7BlwfckVKlMu8nj2TBtBlsXL2Fu7z4c//yz++RfPXwEq4ePAKDqccdyyttv7ddIAGh0x61smPEFv7z0Mo1uv5XGd9zKkkefoHbnTlRq1IjprduSfOopHP/vp/myywWUTU6myb1/Y2bn83DO0W7yeNaOm5DfuJDS98t7Q1k6cBBtX305Py2l/RnUP78ro9t1JHf3bsrXqgWAJSRwxoD+zLzxFrIWLqJc9eq4PXv2K7P5XbezZvoMFr3wX5rfeRvN77qdeQ8/Rr1zzqZqo0aMOuU0arU8ldbPP8u4zl0pl5zMCffdw9gO54BzdJ0+iVVjxuU3LqR0NUytw8eP3Q1ATm4uHe58jM6nHs+dL7/NvT0vovWxjfloxjcMGjONOy47j4vansJFbU8BYOnKDG59cfB+jQSAgaOncHqzJtxwYScGfjaFgZ9N4Z4eFzJjwY+sWLOecc/ez/yff+PRIR8x7KE7yNqWzSsjJ/Lhw3diBpc/9AIdWzQnqXKlUj0fh5rcaFegFERsjIKZHWtmZ5tZlQLp50Vqn7Fi19p1+Xf0Odu2s23pT1RIrcv2n35i+7Kfi9w29dJLyPh4VKHrUrp2IX3YBwCkD/uAlPPP89PPI/0DL1KQ9e1cEpOqUT6lDrU6dWDD9Bnsycpi7+bNbJg+g9pndzxYhykBrPtyFrsys/ZJa3pdbxb1e4nc3bsB2LVhAwCpnTqQtfAHsvxG4+7MTFzu/l9LDc4/Lz8i8Mv7w2hwQVc/vSvLh3qflw1zvqVcUhIVU+pQ7+yOrJk6nd1ZWezevJk1U6dTr3OniByvHJhZi36iQe2apNWqwa9rNtDqmEYAtG3elIlzFuyXf/SseZzf5uRCy5oydxHd2rUEoFu7lkyeu+j39DNaYmacfPSRbMneybqsLcz8fgltmzcluUolkipXom3zpnyxYElkDlQOKRFpKJjZ7cAo4DZgoZl1C1n9ZCT2GasqNqhPtRNOIOvbuSXKn9r9YlaP+LjQdeVr12bX2nWA1xgpX7s2ABVS67IzfXV+vp2rM6iQmkqF1Lrs2C+9btBDkQipenRj6rRtw3mTxnLO6JHUbHEyANWObozD0emjYZw/fRLNbr+10O0r1KnNDv9zsWPtOirU8T4XFVPrsj3k33/76tVUTE2lYmoq29PT89Oz/XSJvjFff8cF/oX/6LSU/Iv7+Nnzydi0f8Rn7NfzwzYUNm7ZSp3kagDUTqrKxi1bAVibuZm6NZPz89WtkcS6zM1eeo3f01NqJLE2U1Gm4jgX+SXaIhVRuAE41TnXHegAPGBmd/jrLNxGZtbXzOaY2ZwBAwZEqGqlJ6FyJU4ZPIgf/vkge7dtKzZ/0iktyN2xg20/lrAVHwufIPnDyiQkUK56MuM6d2XuA4/QfvBAACwhkTptWjPzhpsZf95FNLjwfOqe2b7Y8uLhca3D0e69e5kybxFdWp8EwBN9evD+5C+57MF+bN+xi7IJCfvkn//zCiqUL0vT+sU38swMC//VK3+AK4X/oi1SDYUyzrltAM65X/EaC13N7D8U0VBwzg1wzrV0zrXs27dvhKpWOiwxkVPeGsTq4SNYO3pMibapd2l3Vo8YGXb9rvXrKZ9SB4DyKXXyQ9Q7M9ZQIa1efr4K9VLZmZHBzow1VNwvfU2Ao5FIyl6dwcpPRwOwce48XK6jfM2aZK9ezdovZ7Fr0yZyduxg9cRJ1DjpxP2237luPRX9z0XFlDrsWu99LnZkrKFyyL9/5Xr12JGRwY6MDCqn/d6nXclPl+j6fMGPNDuyPrWSqgLQqF4dBv29Lx89ehfnn96CI+rU3Cf/mFnfcUGbFmHLq1mtKuuytgCwLmsLNap5vcAp1ZNYszErP9+aTZupUz3JS9/0e/raTZtJqZ50kI5ODmWRaiisNbOT8974jYYLgVrACRHaZ0w54cX/sG3pTyx/9fWSbWBGareLWP3xyLBZ1o2bQFqPKwFI63Ela8eOB2DtuPGkXXkFAMmnnsLeLVvZtXYdG6ZMo1aHs0hMSiIxKYlaHc5iw5Rpf+SwJAJWjh5LSvt2AFRt3IgyZcuya+NGMiZPpXqz40ioWBFLSKDOGW3ZvGT/aNOqseNp1KsH4D3NsHLMOD99HA17ep+XWi1PZfeWLexYu47Vk6eS2uksyiUlUS4pidROZ7F68tRSOloJZ/Ss37sdgPyugtzcXF4bNYkenU7PX5ebm8u4b+Zz/mknE06nFs0Y9cUcAEZ9MYdOpzQHoGOLZoyaOQfnHN8tW0HVihWok1yNM044hpkLl7B5ezabt2czc+ESzjjhmIN/oIcZVwpLtEXqqYdrgL2hCc65vcA1ZlbCK+ehq/ppranf4wq2LPqBdlMnArDkiacoU648zZ5+nHI1a9Lyvf+xZeEiZl/ZC4AabduwI301O1b8tk9ZJ7zwHL8N/h+bv5vPzy++TItBr9PgT73YsXIV8/rcCMD6iZOp0/lszpr9Fbk7drDgdu+xtz1ZWSx7vh9nTBwLwLLn/sOerKxSOgtSmHZvvEZKuzMoX7MGlyz6jgVPP8vP77zH6S+/yIVfTid3zx6+/OttAOzevJnFr7xG1ynjwTnSJ04mfcIkANq89B+WvjmETd/NZ2G/l2g/eCCN/3w121eu4vPe1wOQPmES9c7pTLd537A3O5uvbvF6/3ZnZfH9v/9D16kTAFjw7PPs1uciqrJ37eLLhUt5pPdl+WmjZ33He5NmAnBOyxO4tP3vjyrOWfILdWsm06BAlOFfgz6gZ6fTOb5hA66/sBN3v/I/hs/4hno1vccjAc466ThmLPiRLvc+TYXyZXnyeq+RmVylEjd3O4crH34RgL92O4fkKnriQcBiuD/TjamlAVbyu/M3eOHxd5LrRLkmEkv+lOUN5Myd9WmUayKxpEybi6CIru6DZUZK/YhfRM9cuyqqA0w0hbOIiIiEpQmXREREAsqN2aD8waOIgoiIiISliIKIiEhAsTDPQaQpoiAiIiJhKaIgIiIS0OEfT1BEQURERIqgiIKIiEhAsTsV0cGjiIKIiIiEpYiCiIhIQHEQUFBEQURERMJTREFERCSg3DiIKSiiICIiImEpoiAiIhLQ4R9PUERBREREiqCIgoiISEDxMI+CGgoiIiIBxUE7QV0PIiIiEp4iCiIiIgHpZ6ZFREQkrimiICIiElDu4R9QUERBREREwlNEQUREJKA4CCgooiAiIiLhKaIgIiISkCIKIiIiErPMrIGZTTWzH8xskZnd4afXMLOJZvaT/7e6n25m9pKZLTOzBWZ2SnH7UENBREQkIFcK/xVjL/A351wzoA1wi5k1A+4HJjvnmgCT/fcAXYEm/tIXeLW4HaihICIicohyzmU45+b6r7cCi4E0oBswxM82BOjuv+4GvO08s4BkM0stah9qKIiIiATkXOQXM+trZnNClr6F1cXMjgJaAF8DKc65DH/VGiDFf50GrAzZbJWfFpYGM4qIiMQw59wAYEBRecysCvARcKdzbouZhW7vzCzwuEs1FERERALKjXYFADMri9dIeNc5N8JPXmtmqc65DL9rYZ2fng40CNm8vp8WlroeREREDlHmhQ4GAYudc/8JWfUJcK3/+lpgVEj6Nf7TD22AzSFdFIVSREFERCSgGJhH4Qzgz8D3Zvadn/Z/wNPAB2bWB1gBXOmvGwOcDywDsoG/FLcDNRREREQOUc65LwALs/rsQvI74JYD2YcaCiIiIgF5193Dm8YoiIiISFiKKIiIiAR0+McT1FAQEREJLB4aCup6EBERkbAUURAREQlIEQURERGJa4ooiIiIBJSrxyNFREQknimiICIiEtDhH09QREFERESKoIiCiIhIQLHwM9ORpoiCiIiIhKWIgoiISEC5cTBIQREFERERCUsRBRERkYBy4+C5B0UUREREJCxFFERERALSGAURERGJa4ooiIiIBBQHAQVFFERERCQ8RRREREQC0hgFERERiWuKKIiIiASkeRREREQkrimiICIiElA8jFFQQ0FERCSgePiZaXMuZptDMVsxERE5JFikd/BKlVoRv1bdsm1DxI+jKLEcUYjqiYklZtbXOTcg2vWQ2KLPhRRGn4vSFQ9dDxrMeGjoG+0KSEzS50IKo8+FHFSxHFEQERGJaXo8UkREROKaIgqHBvU3SmH0uZDC6HNRiuJhjEIsP/UgIiIS0/pVqhnxi+hd2Rv11IOIiMihKB7mUdAYBREREQlLDYUYZ2bnmdkSM1tmZvdHuz4SfWb2ppmtM7OF0a6LxA4za2BmU83sBzNbZGZ3RLtO8SDXRX6JNjUUYpiZJQCvAF2BZkAvM2sW3VpJDBgMnBftSkjM2Qv8zTnXDGgD3KLvCzkYNEYhtrUGljnnfgEws6FAN+CHqNZKoso5N8PMjop2PSS2OOcygAz/9VYzWwykoe+LiNI8ChJtacDKkPer/DQRkbD8hmQL4OsoV0UOA4ooiIgcRsysCvARcKdzbku063O401MPEm3pQIOQ9/X9NBGR/ZhZWbxGwrvOuRHRro8cHhRRiG2zgSZm1hCvgdATuCq6VRKRWGRmBgwCFjvn/hPt+sSLWHgqIdIUUYhhzrm9wK3AeGAx8IFzblF0ayXRZmbvA18Bx5jZKjPrE+06SUw4A/gz0MnMvvOX86NdKTn0aQpnERGRgB6rUCPiF9EHdm6K6hTOiiiIiIhIWBqjICIiElBuHETl1VAQEREJSI9HioiISFxTREFERCQgPR4pIvnMLMd/5GyhmX1oZpX+QFmDzexy//UbRf14j5l1MLO2Afbxq5nVKml6gTzbDnBfD5vZPQdaRxGJfWooiJTcDufcyc6544HdwE2hK80sUITOOXe9c66oH+7pABxwQ0FEIi+3FJZoU0NBJJjPgaP9u/3PzewT4AczSzCzf5vZbDNbYGY3gjdrnpm9bGZLzGwSUCevIDObZmYt/dfnmdlcM5tvZpP9H/e5CbjLj2a0N7PaZvaRv4/ZZnaGv21NM5tgZovM7A2g2GevzWykmX3rb9O3wLp+fvpkM6vtpzU2s3H+Np+b2bEH5WyKSMzSGAWRA+RHDroC4/ykU4DjnXPL/YvtZudcKzMrD8w0swl4v+R3DNAMSMH76d83C5RbGxgInOmXVcM5t8nMXgO2Oeee8/O9B/Rzzn1hZkfgzdx5HPAQ8IVz7lEzuwAoyYyN1/n7qAjMNrOPnHMbgcrAHOfcXWb2oF/2rcAA4Cbn3E9mdhrQH+gU4DSKHBbiYdJCNRRESq6imX3nv/4cb179tsA3zrnlfvq5wIl54w+AJKAJcCbwvnMuB1htZlMKKb8NMCOvLOfcpjD16Aw086b2B6Ca/4uBZwKX+tuONrPMEhzT7WZ2if+6gV/XjXgRz2F++jvACH8fbYEPQ/ZdvgT7EJFDmBoKIiW3wzl3cmiCf8HcHpoE3OacG18g38Gcc78M0MY5t7OQupSYmXXAa3Sc7pzLNrNpQIUw2Z2/36yC50AknsXCGIJI0xgFkYNrPHCz/3O/mFlTM6sMzAB6+GMYUoGOhWw7CzjT/7VQzKyGn74VqBqSbwJwW94bMzvZfzkD/9dFzawrUL2YuiYBmX4j4Vi8iEaeMkBeVOQqvC6NLcByM7vC34eZ2UnF7ENEDnFqKIgcXG/gjT+Ya2YLgdfxIncfAz/5697G+/XHfTjn1gN98cL88/k99P8pcEneYEbgdqClP1jyB35/+uIRvIbGIrwuiN+Kqes4INHMFgNP4zVU8mwHWvvH0Al41E+/Gujj128R0K0E50TksJXrIr9Em349UkREJKC/JyZH/CL67N6sqP56pMYoiIiIBKQxCiIiIhLXFFEQEREJKB5+ZloRBREREQlLEQUREZGANEZBRERE4poiCiIiIgHFwjwHkaaIgoiIiISliIKIiEhA8TBGQQ0FERGRgPR4pIiIiMQ1RRREREQCioeuB0UUREREJCz9eqSIiIiEpYiCiIiIhKWGgoiIiISlhoKIiIiEpYaCiIiIhKWGgoiIiISlhoKIiIiE9f+xSRkoe9VsbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix for \n",
    "cm = confusion_matrix(y_test, predictions_set_pca)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Reds_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test PCA: {0}'.format(accuracy_score(y_test, predictions_set_pca))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nPCA Classification Report\\n\", classification_report(y_test, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depths [Decision Trees Hyperparameter Tuning]\n",
    "Determines the depth of a tree. The deeper the tree, the more splits/information is garnered about the data.\n",
    "\n",
    "> Notes: As depth increases, likelihood of overfitting the data increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.587\n",
      "===== Accuracy Test: 0.585\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.42      0.58      0.48      3538\n",
      "weighted avg       0.42      0.58      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 2.0\n",
      "===== Accuracy Train: 0.683\n",
      "===== Accuracy Test: 0.669\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      1178\n",
      "           1       0.89      0.75      0.81      1180\n",
      "           2       0.54      0.56      0.55      1180\n",
      "\n",
      "    accuracy                           0.67      3538\n",
      "   macro avg       0.68      0.67      0.67      3538\n",
      "weighted avg       0.68      0.67      0.67      3538\n",
      "\n",
      "For max depth: 3.0\n",
      "===== Accuracy Train: 0.737\n",
      "===== Accuracy Test: 0.726\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65      1178\n",
      "           1       0.86      0.88      0.87      1180\n",
      "           2       0.60      0.72      0.65      1180\n",
      "\n",
      "    accuracy                           0.73      3538\n",
      "   macro avg       0.73      0.73      0.73      3538\n",
      "weighted avg       0.73      0.73      0.73      3538\n",
      "\n",
      "For max depth: 4.0\n",
      "===== Accuracy Train: 0.769\n",
      "===== Accuracy Test: 0.751\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      1178\n",
      "           1       0.93      0.86      0.89      1180\n",
      "           2       0.63      0.74      0.68      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.76      0.75      0.75      3538\n",
      "weighted avg       0.76      0.75      0.75      3538\n",
      "\n",
      "For max depth: 5.0\n",
      "===== Accuracy Train: 0.811\n",
      "===== Accuracy Test: 0.791\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.74      0.68      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max depth: 6.0\n",
      "===== Accuracy Train: 0.843\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.93      0.87      0.90      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max depth: 7.0\n",
      "===== Accuracy Train: 0.875\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.93      0.90      0.92      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 8.0\n",
      "===== Accuracy Train: 0.905\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 9.0\n",
      "===== Accuracy Train: 0.932\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.79      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 10.0\n",
      "===== Accuracy Train: 0.953\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.79      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max depth: 11.0\n",
      "===== Accuracy Train: 0.969\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.92      0.92      1180\n",
      "           2       0.79      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max depth: 12.0\n",
      "===== Accuracy Train: 0.979\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.79      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 13.0\n",
      "===== Accuracy Train: 0.985\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.79      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 14.0\n",
      "===== Accuracy Train: 0.988\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 15.0\n",
      "===== Accuracy Train: 0.990\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.79      0.74      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 16.0\n",
      "===== Accuracy Train: 0.992\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 17.0\n",
      "===== Accuracy Train: 0.993\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 18.0\n",
      "===== Accuracy Train: 0.994\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.79      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 19.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 20.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max depth: 21.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 22.0\n",
      "===== Accuracy Train: 0.997\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 23.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 24.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 25.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 26.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 27.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 28.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max depth: 29.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 30.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 31.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max depth: 32.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "\n",
    "for depth in max_depths:\n",
    "    # Initialize Classifier with max_depth\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For max depth:\", max_depth)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Depth 83.7%, max-depth=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Samples Splits [Decision Trees Hyperparameter Tuning]\n",
    "The minimum number of samples required to split a node. If increased, tree considers more samples at each decision node.\n",
    "\n",
    "> Notes: Causes more underfitting as it increases number of samples per decision node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.788\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1178\n",
      "           1       0.87      0.82      0.84      1180\n",
      "           2       0.65      0.71      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For min sample splits: 0.2\n",
      "===== Accuracy Train: 0.749\n",
      "===== Accuracy Test: 0.731\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.52      0.66      1178\n",
      "           1       0.87      0.82      0.84      1180\n",
      "           2       0.58      0.85      0.69      1180\n",
      "\n",
      "    accuracy                           0.73      3538\n",
      "   macro avg       0.78      0.73      0.73      3538\n",
      "weighted avg       0.78      0.73      0.73      3538\n",
      "\n",
      "For min sample splits: 0.30000000000000004\n",
      "===== Accuracy Train: 0.710\n",
      "===== Accuracy Test: 0.695\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65      1178\n",
      "           1       0.89      0.75      0.81      1180\n",
      "           2       0.55      0.76      0.64      1180\n",
      "\n",
      "    accuracy                           0.69      3538\n",
      "   macro avg       0.73      0.69      0.70      3538\n",
      "weighted avg       0.73      0.69      0.70      3538\n",
      "\n",
      "For min sample splits: 0.4\n",
      "===== Accuracy Train: 0.669\n",
      "===== Accuracy Test: 0.662\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.56      0.47      0.51      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.66      0.66      0.66      3538\n",
      "weighted avg       0.66      0.66      0.66      3538\n",
      "\n",
      "For min sample splits: 0.5\n",
      "===== Accuracy Train: 0.669\n",
      "===== Accuracy Test: 0.662\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.56      0.47      0.51      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.66      0.66      0.66      3538\n",
      "weighted avg       0.66      0.66      0.66      3538\n",
      "\n",
      "For min sample splits: 0.6\n",
      "===== Accuracy Train: 0.669\n",
      "===== Accuracy Test: 0.662\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.56      0.47      0.51      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.66      0.66      0.66      3538\n",
      "weighted avg       0.66      0.66      0.66      3538\n",
      "\n",
      "For min sample splits: 0.7000000000000001\n",
      "===== Accuracy Train: 0.587\n",
      "===== Accuracy Test: 0.585\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.42      0.58      0.48      3538\n",
      "weighted avg       0.42      0.58      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.8\n",
      "===== Accuracy Train: 0.587\n",
      "===== Accuracy Test: 0.585\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.42      0.58      0.48      3538\n",
      "weighted avg       0.42      0.58      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.9\n",
      "===== Accuracy Train: 0.587\n",
      "===== Accuracy Test: 0.585\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.42      0.58      0.48      3538\n",
      "weighted avg       0.42      0.58      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 1.0\n",
      "===== Accuracy Train: 0.587\n",
      "===== Accuracy Test: 0.585\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.42      0.58      0.48      3538\n",
      "weighted avg       0.42      0.58      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "\n",
    "for split in min_samples_splits:\n",
    "    # Initialize Classifier with minimum samples split\n",
    "    dt = DecisionTreeClassifier(min_samples_split=split)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For min sample splits:\", min_samples_split)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Minimum Sample Splits 75.9%, min sample splits = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Samples Leaf [Decision Trees Hyperparameter Tuning]\n",
    "The minimum number of samples required for each leaf node.\n",
    "> Notes: May cause underfitting if increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min samples leafs: [0.1 0.2 0.3 0.4 0.5]\n",
      "===== Accuracy Train: 0.696\n",
      "===== Accuracy Test: 0.688\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.57      0.67      0.61      1180\n",
      "\n",
      "    accuracy                           0.69      3538\n",
      "   macro avg       0.70      0.69      0.69      3538\n",
      "weighted avg       0.70      0.69      0.69      3538\n",
      "\n",
      "For min samples leafs: [0.1 0.2 0.3 0.4 0.5]\n",
      "===== Accuracy Train: 0.669\n",
      "===== Accuracy Test: 0.662\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.56      0.47      0.51      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.66      0.66      0.66      3538\n",
      "weighted avg       0.66      0.66      0.66      3538\n",
      "\n",
      "For min samples leafs: [0.1 0.2 0.3 0.4 0.5]\n",
      "===== Accuracy Train: 0.667\n",
      "===== Accuracy Test: 0.657\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1178\n",
      "           1       0.79      0.82      0.80      1180\n",
      "           2       0.54      0.51      0.52      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.65      0.66      0.65      3538\n",
      "weighted avg       0.65      0.66      0.65      3538\n",
      "\n",
      "For min samples leafs: [0.1 0.2 0.3 0.4 0.5]\n",
      "===== Accuracy Train: 0.590\n",
      "===== Accuracy Test: 0.588\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.89      0.64      1178\n",
      "           1       0.72      0.87      0.79      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.41      0.59      0.48      3538\n",
      "weighted avg       0.41      0.59      0.48      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min samples leafs: [0.1 0.2 0.3 0.4 0.5]\n",
      "===== Accuracy Train: 0.334\n",
      "===== Accuracy Test: 0.333\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      1178\n",
      "           1       0.00      0.00      0.00      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.33      3538\n",
      "   macro avg       0.11      0.33      0.17      3538\n",
      "weighted avg       0.11      0.33      0.17      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaves = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "\n",
    "for min_leaf in min_samples_leaves:\n",
    "    # Initialize Classifier with minimum samples leaf\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=min_leaf)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For min samples leafs:\", min_leaf)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Minimum Sample Leaf 68.8%, min sample splits = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Features [Decision Trees Hyperparameter Tuning]\n",
    "The number of features to consider when searching for best fit.\n",
    "\n",
    "> Notes: May overfit with more features\n",
    "\n",
    "> Sklearn implementation does not stop searching for a split until a valid partition of the node samples is found, including adding more features to the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.639\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1178\n",
      "           1       0.70      0.68      0.69      1180\n",
      "           2       0.56      0.58      0.57      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.64      0.64      0.64      3538\n",
      "weighted avg       0.64      0.64      0.64      3538\n",
      "\n",
      "For max feature: 2\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.690\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      1178\n",
      "           1       0.76      0.76      0.76      1180\n",
      "           2       0.61      0.60      0.61      1180\n",
      "\n",
      "    accuracy                           0.69      3538\n",
      "   macro avg       0.69      0.69      0.69      3538\n",
      "weighted avg       0.69      0.69      0.69      3538\n",
      "\n",
      "For max feature: 3\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.713\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72      1178\n",
      "           1       0.78      0.77      0.78      1180\n",
      "           2       0.64      0.64      0.64      1180\n",
      "\n",
      "    accuracy                           0.71      3538\n",
      "   macro avg       0.71      0.71      0.71      3538\n",
      "weighted avg       0.71      0.71      0.71      3538\n",
      "\n",
      "For max feature: 4\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.735\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      1178\n",
      "           1       0.81      0.79      0.80      1180\n",
      "           2       0.65      0.67      0.66      1180\n",
      "\n",
      "    accuracy                           0.74      3538\n",
      "   macro avg       0.74      0.74      0.74      3538\n",
      "weighted avg       0.74      0.74      0.74      3538\n",
      "\n",
      "For max feature: 5\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.734\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1178\n",
      "           1       0.79      0.79      0.79      1180\n",
      "           2       0.66      0.66      0.66      1180\n",
      "\n",
      "    accuracy                           0.73      3538\n",
      "   macro avg       0.73      0.73      0.73      3538\n",
      "weighted avg       0.73      0.73      0.73      3538\n",
      "\n",
      "For max feature: 6\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.727\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      1178\n",
      "           1       0.82      0.79      0.80      1180\n",
      "           2       0.64      0.64      0.64      1180\n",
      "\n",
      "    accuracy                           0.73      3538\n",
      "   macro avg       0.73      0.73      0.73      3538\n",
      "weighted avg       0.73      0.73      0.73      3538\n",
      "\n",
      "For max feature: 7\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.736\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      1178\n",
      "           1       0.81      0.80      0.80      1180\n",
      "           2       0.66      0.65      0.65      1180\n",
      "\n",
      "    accuracy                           0.74      3538\n",
      "   macro avg       0.74      0.74      0.74      3538\n",
      "weighted avg       0.74      0.74      0.74      3538\n",
      "\n",
      "For max feature: 8\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1178\n",
      "           1       0.82      0.80      0.81      1180\n",
      "           2       0.66      0.66      0.66      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max feature: 9\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.776\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1178\n",
      "           1       0.84      0.84      0.84      1180\n",
      "           2       0.71      0.71      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 10\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.752\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1178\n",
      "           1       0.83      0.82      0.83      1180\n",
      "           2       0.66      0.68      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max feature: 11\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      1178\n",
      "           1       0.83      0.84      0.84      1180\n",
      "           2       0.70      0.68      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 12\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1178\n",
      "           1       0.84      0.82      0.83      1180\n",
      "           2       0.68      0.69      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max feature: 13\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1178\n",
      "           1       0.85      0.83      0.84      1180\n",
      "           2       0.68      0.70      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 14\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.772\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1178\n",
      "           1       0.85      0.86      0.85      1180\n",
      "           2       0.70      0.69      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 15\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      1178\n",
      "           1       0.85      0.81      0.83      1180\n",
      "           2       0.66      0.69      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max feature: 16\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.773\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      1178\n",
      "           1       0.85      0.82      0.83      1180\n",
      "           2       0.70      0.69      0.70      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 17\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1178\n",
      "           1       0.85      0.82      0.83      1180\n",
      "           2       0.68      0.70      0.69      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max feature: 18\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.773\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.69      0.70      0.70      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 19\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.778\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.71      0.71      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 20\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.784\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.85      0.84      0.85      1180\n",
      "           2       0.72      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 21\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.786\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.85      0.86      0.85      1180\n",
      "           2       0.72      0.70      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.78      0.79      0.79      3538\n",
      "weighted avg       0.78      0.79      0.79      3538\n",
      "\n",
      "For max feature: 22\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.778\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1178\n",
      "           1       0.85      0.83      0.84      1180\n",
      "           2       0.71      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 23\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1178\n",
      "           1       0.85      0.83      0.84      1180\n",
      "           2       0.70      0.68      0.69      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.77      0.76      0.76      3538\n",
      "weighted avg       0.77      0.76      0.76      3538\n",
      "\n",
      "For max feature: 24\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.782\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1178\n",
      "           1       0.85      0.87      0.86      1180\n",
      "           2       0.72      0.71      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 25\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.777\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1178\n",
      "           1       0.86      0.85      0.85      1180\n",
      "           2       0.70      0.70      0.70      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 26\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 27\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.781\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.71      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 28\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1178\n",
      "           1       0.86      0.87      0.86      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 29\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.791\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      1178\n",
      "           1       0.87      0.86      0.86      1180\n",
      "           2       0.73      0.70      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 30\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.791\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.70      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 31\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.789\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.71      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 32\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.788\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.86      0.86      0.86      1180\n",
      "           2       0.72      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 33\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 34\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.72      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 35\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.780\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1178\n",
      "           1       0.85      0.86      0.85      1180\n",
      "           2       0.70      0.69      0.70      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 36\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.793\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.88      0.84      0.86      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 37\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.86      0.84      0.85      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 38\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.72      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 39\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.88      0.85      0.87      1180\n",
      "           2       0.71      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 40\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.69      0.69      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 41\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.86      0.87      0.86      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 42\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.781\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1178\n",
      "           1       0.86      0.85      0.85      1180\n",
      "           2       0.71      0.71      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 43\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.86      0.86      0.86      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 44\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.779\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      1178\n",
      "           1       0.86      0.84      0.85      1180\n",
      "           2       0.71      0.70      0.70      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.78      0.78      0.78      3538\n",
      "weighted avg       0.78      0.78      0.78      3538\n",
      "\n",
      "For max feature: 45\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.786\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.71      0.70      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 46\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 47\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1178\n",
      "           1       0.87      0.88      0.87      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 48\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 49\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.793\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.72      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 50\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 51\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 52\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 53\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 54\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 55\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1178\n",
      "           1       0.86      0.89      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 56\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1178\n",
      "           1       0.87      0.88      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 57\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 58\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.86      0.87      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 59\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.790\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.72      0.71      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 60\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.772\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1178\n",
      "           1       0.86      0.85      0.85      1180\n",
      "           2       0.69      0.70      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max feature: 61\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 62\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 63\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 64\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 65\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.788\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.71      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 66\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 67\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 68\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.793\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.73      0.70      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 69\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.86      0.87      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 70\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 71\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.74      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 72\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 73\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 74\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1178\n",
      "           1       0.87      0.86      0.86      1180\n",
      "           2       0.70      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.78      3538\n",
      "   macro avg       0.79      0.78      0.79      3538\n",
      "weighted avg       0.79      0.78      0.79      3538\n",
      "\n",
      "For max feature: 75\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 76\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.74      0.70      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 77\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 78\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.87      0.86      0.86      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 79\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 80\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.793\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.72      0.70      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 81\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.86      0.87      0.86      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 82\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.73      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 83\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 84\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 85\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 86\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.79      0.80      0.80      3538\n",
      "weighted avg       0.79      0.80      0.80      3538\n",
      "\n",
      "For max feature: 87\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.72      0.73      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 88\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 89\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 90\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 91\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.86      0.87      0.87      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 92\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.87      0.85      0.86      1180\n",
      "           2       0.74      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 93\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1178\n",
      "           1       0.87      0.88      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 94\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 95\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 96\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.87      0.88      0.87      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 97\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 98\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 99\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1178\n",
      "           1       0.86      0.87      0.87      1180\n",
      "           2       0.71      0.70      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.87      0.86      0.87      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.70      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.88      0.87      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.80      0.81      0.80      3538\n",
      "weighted avg       0.80      0.81      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.89      0.86      0.88      1180\n",
      "           2       0.72      0.73      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.71      0.72      0.71      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.87      0.86      0.87      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.79      3538\n",
      "   macro avg       0.79      0.79      0.79      3538\n",
      "weighted avg       0.79      0.79      0.79      3538\n",
      "\n",
      "For max feature: 122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.73      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.86      0.88      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.86      0.87      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.72      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.73      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.81      0.80      0.81      3538\n",
      "weighted avg       0.81      0.80      0.81      3538\n",
      "\n",
      "For max feature: 140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.74      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.88      0.86      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.87      0.87      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.86      0.87      0.86      1180\n",
      "           2       0.74      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.87      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.73      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.87      0.88      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.81      0.80      0.81      3538\n",
      "weighted avg       0.81      0.80      0.81      3538\n",
      "\n",
      "For max feature: 170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.86      0.87      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.81      0.80      0.81      3538\n",
      "weighted avg       0.81      0.80      0.81      3538\n",
      "\n",
      "For max feature: 208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.87      0.90      0.89      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1178\n",
      "           1       0.88      0.87      0.87      1180\n",
      "           2       0.72      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.82      3538\n",
      "weighted avg       0.81      0.82      0.82      3538\n",
      "\n",
      "For max feature: 238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.87      0.88      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.92      0.87      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.74      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.72      0.73      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.80      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 289\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 290\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 291\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 292\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 293\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 294\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 295\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 296\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.71      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 297\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 298\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 299\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 300\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 301\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 302\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 303\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 304\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 305\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 306\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.73      0.70      0.71      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 307\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 308\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 309\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 310\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 311\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 312\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 313\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 314\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 315\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 316\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 317\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 318\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 319\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 320\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 321\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 322\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 323\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 324\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 325\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 326\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 327\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 328\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 329\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 330\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 331\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 332\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 333\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 334\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 335\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 336\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 337\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 338\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.76      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 339\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 340\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 341\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 342\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 343\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 344\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 345\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 346\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 347\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 348\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 349\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 350\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 351\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 352\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 353\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 354\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 355\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 356\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 357\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 358\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 359\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 360\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 361\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 362\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 363\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 364\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 365\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 366\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 367\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 368\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 369\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 370\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.87      0.88      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 371\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 372\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 373\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 374\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 375\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 376\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 377\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 378\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 379\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 380\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 381\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 382\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 383\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 384\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 385\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 386\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 387\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 388\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 389\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 390\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 391\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 392\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 393\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.87      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 394\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 395\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 396\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 397\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 398\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 399\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 400\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 401\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 402\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 403\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 404\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 405\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 406\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 407\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 408\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 409\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 410\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 411\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 412\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 413\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 414\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 415\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 416\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 417\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 418\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 419\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 420\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 421\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 422\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 423\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 424\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 425\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 426\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 427\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 428\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 429\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 430\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 431\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 432\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 433\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 434\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 435\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 436\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 437\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.82      3538\n",
      "weighted avg       0.81      0.82      0.82      3538\n",
      "\n",
      "For max feature: 438\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 439\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 440\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 441\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 442\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 443\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 444\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 445\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 446\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 447\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 448\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.73      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 449\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 450\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 451\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 452\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 453\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 454\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 455\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 456\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 457\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 458\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 459\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 460\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 461\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 462\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 463\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.86      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 464\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 465\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 466\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 467\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 468\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 469\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 470\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 471\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.73      0.72      0.72      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 472\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 473\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 474\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 475\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.74      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 476\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 477\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 478\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 479\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 480\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 481\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 482\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 483\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 484\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.87      0.88      0.88      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 485\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 486\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 487\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 488\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 489\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 490\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 491\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 492\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 493\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 494\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 495\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 496\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 497\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 498\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 499\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 500\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 501\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 502\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 503\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 504\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.84      0.83      0.83      3538\n",
      "weighted avg       0.84      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 505\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 506\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 507\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.92      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 508\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 509\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.73      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 510\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 511\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 512\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 513\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 514\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 515\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 516\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 517\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 518\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 519\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 520\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 521\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 522\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 523\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 524\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 525\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 526\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 527\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 528\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 529\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 530\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 531\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 532\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 533\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 534\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 535\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 536\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 537\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 538\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 539\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 540\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 541\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 542\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 543\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 544\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 545\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 546\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 547\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 548\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 549\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 550\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 551\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 552\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 553\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 554\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 555\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 556\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 557\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 558\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 559\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 560\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 561\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 562\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 563\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 564\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 565\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 566\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 567\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.93      0.90      0.92      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 568\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 569\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 570\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 571\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 572\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 573\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 574\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 575\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 576\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 577\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 578\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 579\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 580\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.93      0.90      0.91      1180\n",
      "           2       0.75      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 581\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 582\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 583\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 584\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 585\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 586\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 587\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 588\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 589\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 590\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 591\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 592\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 593\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 594\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 595\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 596\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 597\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 598\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 599\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 600\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 601\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 602\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 603\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 604\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 605\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 606\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 607\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.73      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 608\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 609\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 610\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 611\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 612\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 613\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.92      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 614\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 615\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 616\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 617\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 618\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 619\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 620\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 621\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 622\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 623\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 624\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 625\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 626\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 627\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 628\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 629\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 630\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.87      0.90      0.88      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 631\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 632\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 633\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 634\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 635\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.88      0.88      0.88      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 636\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 637\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 638\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 639\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.83      3538\n",
      "weighted avg       0.83      0.82      0.83      3538\n",
      "\n",
      "For max feature: 640\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 641\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.88      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 642\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 643\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 644\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 645\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 646\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 647\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 648\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 649\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 650\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 651\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 652\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 653\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 654\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 655\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 656\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 657\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 658\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 659\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 660\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 661\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 662\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 663\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 664\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 665\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 666\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 667\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 668\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 669\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 670\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 671\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 672\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 673\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 674\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 675\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 676\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 677\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 678\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 679\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 680\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 681\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 682\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 683\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 684\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 685\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 686\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 687\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 688\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 689\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 690\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 691\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 692\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 693\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 694\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 695\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.79      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 696\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 697\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 698\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 699\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 700\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 701\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 702\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 703\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 704\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 705\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 706\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 707\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 708\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 709\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 710\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.84      0.83      0.83      3538\n",
      "weighted avg       0.84      0.83      0.84      3538\n",
      "\n",
      "For max feature: 711\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 712\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 713\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.82      3538\n",
      "weighted avg       0.83      0.83      0.82      3538\n",
      "\n",
      "For max feature: 714\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 715\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 716\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 717\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 718\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 719\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 720\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.87      0.89      0.88      1180\n",
      "           2       0.74      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 721\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 722\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 723\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 724\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 725\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 726\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 727\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 728\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 729\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 730\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.88      0.91      0.89      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 731\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 732\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 733\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 734\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 735\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 736\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 737\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 738\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 739\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 740\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 741\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 742\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 743\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 744\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 745\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 746\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 747\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 748\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 749\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 750\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 751\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 752\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 753\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 754\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 755\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 756\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 757\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 758\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 759\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 760\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 761\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 762\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 763\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 764\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 765\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 766\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 767\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 768\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 769\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 770\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 771\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 772\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 773\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 774\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 775\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 776\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 777\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.81      3538\n",
      "weighted avg       0.82      0.82      0.81      3538\n",
      "\n",
      "For max feature: 778\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 779\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 780\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 781\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 782\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.74      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 783\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 784\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 785\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 786\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 787\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 788\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.73      0.73      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 789\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 790\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.92      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 791\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 792\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 793\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 794\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 795\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 796\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 797\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 798\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 799\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 800\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 801\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 802\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 803\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 804\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 805\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 806\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 807\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 808\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 809\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 810\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 811\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 812\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 813\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 814\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 815\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 816\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 817\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 818\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 819\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 820\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 821\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 822\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 823\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 824\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 825\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 826\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 827\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 828\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 829\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 830\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 831\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 832\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 833\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 834\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 835\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 836\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 837\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 838\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 839\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 840\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 841\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 842\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 843\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 844\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 845\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 846\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 847\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 848\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 849\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 850\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 851\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 852\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 853\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 854\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 855\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 856\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 857\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 858\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 859\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 860\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 861\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 862\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 863\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 864\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.79      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 865\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 866\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 867\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 868\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 869\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 870\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.74      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 871\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 872\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 873\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 874\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 875\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 876\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 877\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 878\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 879\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.88      0.88      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.80      3538\n",
      "   macro avg       0.80      0.80      0.80      3538\n",
      "weighted avg       0.80      0.80      0.80      3538\n",
      "\n",
      "For max feature: 880\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 881\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 882\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 883\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 884\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 885\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 886\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 887\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.83      3538\n",
      "weighted avg       0.83      0.82      0.83      3538\n",
      "\n",
      "For max feature: 888\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 889\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 890\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 891\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 892\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 893\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 894\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 895\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 896\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 897\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.92      0.91      1180\n",
      "           2       0.79      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 898\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 899\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 900\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 901\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 902\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 903\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.73      0.74      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 904\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 905\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 906\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 907\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 908\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 909\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 910\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 911\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 912\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 913\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 914\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 915\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 916\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 917\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 918\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 919\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 920\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 921\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 922\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 923\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 924\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 925\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 926\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 927\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 928\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 929\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 930\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 931\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 932\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 933\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 934\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 935\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 936\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 937\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 938\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 939\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 940\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 941\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 942\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 943\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 944\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 945\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 946\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 947\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 948\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.84      0.83      0.84      3538\n",
      "weighted avg       0.84      0.83      0.84      3538\n",
      "\n",
      "For max feature: 949\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 950\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 951\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 952\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 953\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 954\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 955\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 956\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 957\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 958\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 959\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 960\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 961\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 962\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 963\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 964\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 965\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 966\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 967\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 968\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.92      0.92      0.92      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 969\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 970\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 971\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 972\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 973\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 974\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 975\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 976\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 977\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 978\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 979\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 980\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 981\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 982\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 983\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 984\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 985\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 986\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 987\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 988\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 989\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 990\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 991\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 992\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 993\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 994\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 995\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 996\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 997\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 998\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 999\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1000\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1001\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1002\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1003\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1004\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1005\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1006\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1007\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1008\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1009\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1010\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1011\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1012\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1013\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1014\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1015\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1016\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1017\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1018\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1019\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1020\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.87      0.89      1180\n",
      "           2       0.74      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1021\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1022\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1023\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1024\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1025\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1026\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1027\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1028\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1029\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1030\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1031\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1032\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1033\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1034\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1035\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1036\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1037\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1038\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1039\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1040\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1041\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1042\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1043\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1044\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1045\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1046\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1047\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1048\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1049\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1050\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1051\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1052\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1053\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1054\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1055\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1056\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1057\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1058\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1059\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1060\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1061\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1062\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1063\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1064\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1065\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1066\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1067\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.75      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1068\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1069\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1070\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1071\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1072\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1073\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1074\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1075\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1076\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1077\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1078\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1079\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1080\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1081\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1082\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1083\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 1084\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1085\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1086\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1087\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1088\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1089\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1090\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1091\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1092\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1093\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1094\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1095\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1096\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1097\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1098\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1099\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.88      0.89      0.88      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.73      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.843\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.79      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.71      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.79      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.83      3538\n",
      "weighted avg       0.83      0.82      0.83      3538\n",
      "\n",
      "For max feature: 1191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.92      0.92      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.93      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.73      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.79      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.92      0.88      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.87      0.88      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.83      0.84      0.83      3538\n",
      "weighted avg       0.83      0.84      0.83      3538\n",
      "\n",
      "For max feature: 1288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1289\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1290\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1291\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1292\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1293\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1294\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1295\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1296\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1297\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1298\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1299\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1300\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1301\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1302\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1178\n",
      "           1       0.92      0.88      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1303\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1304\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1305\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1306\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1307\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1308\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 1309\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1310\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1311\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1312\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1313\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1314\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1315\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1316\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1317\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1318\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1319\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1320\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1321\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1322\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1323\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1324\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1325\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1326\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1327\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1328\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1329\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1330\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1331\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1332\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1333\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1334\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1335\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1336\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1337\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1338\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1339\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1340\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1341\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1342\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1343\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1344\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1345\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1346\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1347\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1348\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1349\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1350\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1351\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1352\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1353\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1354\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1355\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1356\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1357\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1358\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1359\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1360\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1361\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1362\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1363\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1364\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1365\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1366\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1367\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1368\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1369\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1370\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1371\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1372\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1373\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1374\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1375\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1376\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1377\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1378\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1379\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1380\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1381\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1382\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.79      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1383\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1384\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1385\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1386\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1387\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1388\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1389\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.83      0.84      0.83      3538\n",
      "weighted avg       0.83      0.84      0.83      3538\n",
      "\n",
      "For max feature: 1390\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1391\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1392\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1393\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1394\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1395\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1396\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1397\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1398\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1399\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1400\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1401\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1402\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1403\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1404\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1405\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1406\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1407\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1408\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1409\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1410\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1411\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1412\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1413\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1414\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1415\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1416\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1417\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1418\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1419\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1420\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1421\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1422\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1423\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1424\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1425\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1426\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1427\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1428\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1429\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1430\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1431\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1432\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1433\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1434\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1435\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1436\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1437\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1438\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1439\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1440\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1441\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1442\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1443\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1444\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1445\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1446\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1447\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1448\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1449\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1450\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1451\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.92      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1452\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1453\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1454\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1455\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1456\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1457\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.88      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1458\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1459\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1460\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1461\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1462\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1463\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1464\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1465\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1466\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1467\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1468\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1469\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1470\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1471\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1472\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1473\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1474\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1475\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1476\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1477\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1478\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1479\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1480\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.79      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1481\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1482\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1483\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1484\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1485\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1486\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1487\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1488\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1489\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1490\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1491\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1492\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1493\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1494\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1495\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1496\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1497\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1498\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1499\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1500\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1501\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1502\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1503\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.92      0.92      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1504\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1505\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1506\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1507\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1508\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1509\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1510\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1511\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1512\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1513\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1514\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1515\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1516\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1517\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1518\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1519\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1520\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1521\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1522\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1523\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1524\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1525\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1526\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1527\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1528\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1529\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1530\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1531\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1532\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1533\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.81      3538\n",
      "weighted avg       0.82      0.82      0.81      3538\n",
      "\n",
      "For max feature: 1534\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1535\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1536\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1537\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1538\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1539\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1540\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1541\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1542\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1543\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1544\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1545\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1546\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.80      0.76      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1547\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1548\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1549\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1550\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1551\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1552\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1553\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1554\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1555\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1556\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1557\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1558\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1559\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1560\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1561\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1562\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1563\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1564\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1565\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.81      3538\n",
      "weighted avg       0.81      0.82      0.81      3538\n",
      "\n",
      "For max feature: 1566\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1567\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1568\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1569\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1570\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.88      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1571\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1572\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1573\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1574\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1575\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1576\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1577\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1578\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1579\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1580\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1581\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1582\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1583\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1584\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1585\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1586\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1587\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1588\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1589\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1590\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1591\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1592\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1593\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1594\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1595\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1596\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1597\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1598\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1599\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1600\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1601\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1602\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1603\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1604\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1605\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1606\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1607\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1608\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1609\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1610\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1611\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1612\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1613\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1614\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1615\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1616\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1617\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1618\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1619\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1620\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1621\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1622\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1623\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1624\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1625\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1626\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1627\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1628\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1629\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1630\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1631\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1632\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1633\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1634\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1635\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1636\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.79      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1637\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1638\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1639\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1640\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1641\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1642\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1643\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1644\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1645\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1646\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.88      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1647\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1648\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1649\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1650\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1651\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1652\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1653\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1654\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1655\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1656\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1657\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1658\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1659\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1660\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1661\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1662\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.83      3538\n",
      "weighted avg       0.83      0.82      0.83      3538\n",
      "\n",
      "For max feature: 1663\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1664\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1665\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1666\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1667\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1668\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1669\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1670\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1671\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1672\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1673\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1674\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1675\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1676\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1677\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1678\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1679\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1680\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1681\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1682\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1683\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1684\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1685\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1686\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1687\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1688\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1689\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1690\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1691\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1692\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1693\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1694\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1695\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1696\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1697\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1698\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1699\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1700\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1701\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1702\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1703\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1704\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1705\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1706\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1707\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1708\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1709\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1710\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1711\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1712\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1713\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1714\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1715\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1716\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1717\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1718\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1719\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1720\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1721\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1722\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1723\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1724\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.73      0.77      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1725\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1726\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.87      0.90      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1727\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1728\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1729\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1730\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1731\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1732\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1733\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1734\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1735\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1736\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1737\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1738\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.92      0.92      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1739\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1740\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1741\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1742\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1743\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1744\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1745\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1746\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1747\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1748\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1749\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1750\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1751\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1752\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1753\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1754\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1755\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1756\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1757\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1758\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1759\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1760\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1761\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1762\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1763\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1764\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1765\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1766\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1767\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1768\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1769\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1770\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1771\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.93      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1772\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1773\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1774\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1775\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1776\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1777\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.93      0.91      0.92      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1778\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1779\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1780\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1781\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1782\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1783\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.92      0.91      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1784\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1785\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1786\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1787\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.93      0.91      0.92      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1788\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1789\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.93      0.89      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1790\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1791\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1792\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1793\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1794\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1795\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1796\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1797\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1798\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1799\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1800\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1801\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1802\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1803\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1804\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1805\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1806\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1807\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1808\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1809\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1810\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1811\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1812\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1813\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1814\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1815\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1816\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1817\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1818\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1819\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1820\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1821\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1822\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1823\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1824\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1825\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1826\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1827\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1828\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1829\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1830\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1831\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1832\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1833\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1834\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1835\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1836\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1837\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1838\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1839\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1840\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1841\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1842\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1843\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 1844\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1845\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1846\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1847\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1848\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1849\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1850\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1851\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1852\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1853\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1854\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1855\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1856\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1857\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1858\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1859\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1860\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1861\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1862\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1863\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1864\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1865\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1866\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1867\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1868\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1869\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1870\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1871\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1872\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1873\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1874\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1875\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1876\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1877\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1878\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1879\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1880\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1881\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1882\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1883\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1884\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1885\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1886\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1887\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1888\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1889\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1890\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1891\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1892\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1893\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1894\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1895\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1896\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1897\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1898\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1899\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1900\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1901\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1902\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1903\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1904\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1905\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1906\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1907\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1908\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1909\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1910\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1911\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1912\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1913\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1914\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1915\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1916\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1917\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1918\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1919\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1920\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1921\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1922\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1923\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1924\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1925\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1926\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1927\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1928\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1929\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1930\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1931\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1932\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1933\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1934\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1935\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1936\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1937\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1938\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.83      3538\n",
      "weighted avg       0.82      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1939\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.78      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1940\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1941\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1942\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.82      3538\n",
      "weighted avg       0.81      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1943\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1944\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1945\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.93      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1946\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1947\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1948\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1949\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1950\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1951\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1952\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1953\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1954\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1955\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.87      0.89      1180\n",
      "           2       0.73      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1956\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1957\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1958\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1959\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1960\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1961\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1962\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1963\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1964\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1965\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1966\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1967\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1968\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1969\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1970\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1971\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 1972\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1973\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1974\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 1975\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1976\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1977\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1978\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1979\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1980\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1981\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1982\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1983\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1984\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.88      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1985\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1986\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1987\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1988\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1989\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1990\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1991\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1992\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 1993\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1994\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1995\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1996\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1997\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1998\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 1999\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2000\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2001\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2002\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2003\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2004\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2005\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2006\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2007\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2008\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.78      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2009\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2010\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2011\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2012\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2013\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2014\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2015\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2016\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2017\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2018\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.78      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2019\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.73      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.82      3538\n",
      "weighted avg       0.82      0.81      0.82      3538\n",
      "\n",
      "For max feature: 2020\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2021\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2022\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2023\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2024\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2025\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2026\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2027\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2028\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2029\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2030\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2031\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2032\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2033\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2034\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2035\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2036\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2037\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2038\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2039\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2040\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2041\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2042\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2043\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2044\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.93      0.92      0.92      1180\n",
      "           2       0.78      0.77      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2045\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2046\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2047\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2048\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2049\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2050\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2051\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2052\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2053\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.88      0.90      0.89      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 2054\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2055\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.92      0.89      0.91      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2056\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2057\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2058\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2059\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2060\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2061\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2062\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.88      0.89      1180\n",
      "           2       0.74      0.75      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2063\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.77      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2064\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2065\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2066\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2067\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 2068\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2069\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2070\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2071\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2072\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2073\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2074\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2075\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2076\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2077\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2078\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2079\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2080\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2081\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.82      0.81      0.81      3538\n",
      "weighted avg       0.82      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2082\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2083\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2084\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2085\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2086\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2087\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2088\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2089\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2090\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2091\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2092\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2093\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2094\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2095\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2096\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2097\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2098\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2099\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.72      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 2116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.83      3538\n",
      "weighted avg       0.83      0.82      0.83      3538\n",
      "\n",
      "For max feature: 2121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.84      0.83      0.83      3538\n",
      "weighted avg       0.84      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.83      0.84      0.84      3538\n",
      "weighted avg       0.83      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.72      0.73      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.73      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.74      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.91      0.89      1180\n",
      "           2       0.77      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.81      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.88      0.89      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.92      0.91      0.92      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.73      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.91      0.88      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.93      0.91      0.92      1180\n",
      "           2       0.77      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.92      0.91      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.75      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.77      0.78      0.78      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.92      0.92      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1178\n",
      "           1       0.92      0.89      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.78      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.89      0.89      0.89      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.92      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.90      0.89      0.89      1180\n",
      "           2       0.76      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.78      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n",
      "For max feature: 2258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.78      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.89      0.90      1180\n",
      "           2       0.75      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.76      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.91      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.90      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.91      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.73      0.74      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.75      0.77      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.83      0.82      0.82      3538\n",
      "weighted avg       0.83      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1178\n",
      "           1       0.89      0.91      0.90      1180\n",
      "           2       0.77      0.77      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.89      0.90      0.89      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1178\n",
      "           1       0.91      0.88      0.89      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.77      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.74      0.76      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.90      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.89      0.90      0.90      1180\n",
      "           2       0.76      0.76      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.77      0.74      0.76      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.82      3538\n",
      "   macro avg       0.82      0.82      0.82      3538\n",
      "weighted avg       0.82      0.82      0.82      3538\n",
      "\n",
      "For max feature: 2285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1178\n",
      "           1       0.91      0.91      0.91      1180\n",
      "           2       0.76      0.75      0.76      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.82      0.83      0.82      3538\n",
      "weighted avg       0.82      0.83      0.82      3538\n",
      "\n",
      "For max feature: 2286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1178\n",
      "           1       0.90      0.89      0.90      1180\n",
      "           2       0.74      0.74      0.74      1180\n",
      "\n",
      "    accuracy                           0.81      3538\n",
      "   macro avg       0.81      0.81      0.81      3538\n",
      "weighted avg       0.81      0.81      0.81      3538\n",
      "\n",
      "For max feature: 2287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1178\n",
      "           1       0.91      0.90      0.90      1180\n",
      "           2       0.75      0.75      0.75      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n",
      "For max feature: 2288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1178\n",
      "           1       0.92      0.92      0.92      1180\n",
      "           2       0.78      0.75      0.77      1180\n",
      "\n",
      "    accuracy                           0.83      3538\n",
      "   macro avg       0.83      0.83      0.83      3538\n",
      "weighted avg       0.83      0.83      0.83      3538\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d940c52e5b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = list(range(1,X_train.shape[1]))\n",
    "\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For max feature:\", max_feature)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"501: 84%, 1138: 84.3%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Top Performing Parameters to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1138 , max_depth: 10 , min samples_split: 0.1\n",
      "===== Accuracy Train: 0.762\n",
      "===== Accuracy Test: 0.738\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72      1178\n",
      "           1       0.85      0.81      0.83      1180\n",
      "           2       0.62      0.72      0.67      1180\n",
      "\n",
      "    accuracy                           0.74      3538\n",
      "   macro avg       0.75      0.74      0.74      3538\n",
      "weighted avg       0.75      0.74      0.74      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum Samples Leaf is excluded since it underperformed by a great margin in comparison \n",
    "# to the No Hyperparameter Tuning model, in terms of accuracy\n",
    "# For one instance both incorrect wear of face mask and correct wear of face mask classifications are never predicted\n",
    "# Since Incorrect Wear of Face Masks is the top performing classification, and performed worse for this parameter tuning\n",
    "# this parameter was excluded.\n",
    "\n",
    "best_max_depth = 10\n",
    "best_max_feature = 1138\n",
    "best_min_samples_split = 0.1 # consider also excluding due to underperformance in parameter exploration\n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=10, min_samples_split=best_min_samples_split)\n",
    "dt.fit(X_train, y_train)\n",
    "train_pred = dt.predict(X_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"For max feature:\", best_max_feature, \", max_depth:\", best_max_depth, \", min samples_split:\", best_min_samples_split)\n",
    "print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Both `Minimum Samples Leaf` and `Minimum Samples Split` Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1138 , max_depth: 10\n",
      "===== Accuracy Train: 0.949\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum Samples Leaf is excluded since it underperformed by a great margin in comparison \n",
    "# to the No Hyperparameter Tuning model, in terms of accuracy\n",
    "# For one instance both incorrect wear of face mask and correct wear of face mask classifications are never predicted\n",
    "# Since Incorrect Wear of Face Masks is the top performing classification, and performed worse for this parameter tuning\n",
    "# this parameter was excluded.\n",
    "\n",
    "best_max_depth = 10\n",
    "best_max_feature = 1138\n",
    "\n",
    "# Excluding due to underperformance in parameter exploration\n",
    "# best_min_samples_split = 0.1 \n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "train_pred = dt.predict(X_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"For max feature:\", best_max_feature, \", max_depth:\", best_max_depth)\n",
    "print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# This set of features perform slightly better than the no hyperparameter tuning model with ~84% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Hyperparameter Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1178\n",
      "           1       0.92      0.90      0.91      1180\n",
      "           2       0.78      0.76      0.77      1180\n",
      "\n",
      "    accuracy                           0.84      3538\n",
      "   macro avg       0.84      0.84      0.84      3538\n",
      "weighted avg       0.84      0.84      0.84      3538\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix for \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Greens_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test: {0}'.format(accuracy_score(y_test, y_pred))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nHyperparameter Tuning Classification Report\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14149, 153)\n",
      "(14149, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(X_train) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(X_test) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)\n",
    "\n",
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1\n",
      "===== Accuracy Train: 0.435\n",
      "===== Accuracy Test: 0.426\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.70      0.52      1178\n",
      "           1       0.43      0.43      0.43      1180\n",
      "           2       0.47      0.14      0.22      1180\n",
      "\n",
      "    accuracy                           0.43      3538\n",
      "   macro avg       0.44      0.43      0.39      3538\n",
      "weighted avg       0.44      0.43      0.39      3538\n",
      "\n",
      "For max feature: 2\n",
      "===== Accuracy Train: 0.527\n",
      "===== Accuracy Test: 0.543\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.48      0.32      0.38      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.54      0.54      0.53      3538\n",
      "weighted avg       0.54      0.54      0.53      3538\n",
      "\n",
      "For max feature: 3\n",
      "===== Accuracy Train: 0.487\n",
      "===== Accuracy Test: 0.473\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.59      0.55      1178\n",
      "           1       0.42      0.13      0.20      1180\n",
      "           2       0.45      0.69      0.55      1180\n",
      "\n",
      "    accuracy                           0.47      3538\n",
      "   macro avg       0.46      0.47      0.43      3538\n",
      "weighted avg       0.46      0.47      0.43      3538\n",
      "\n",
      "For max feature: 4\n",
      "===== Accuracy Train: 0.441\n",
      "===== Accuracy Test: 0.434\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.35      0.42      1178\n",
      "           1       0.42      0.53      0.47      1180\n",
      "           2       0.40      0.42      0.41      1180\n",
      "\n",
      "    accuracy                           0.43      3538\n",
      "   macro avg       0.44      0.43      0.43      3538\n",
      "weighted avg       0.44      0.43      0.43      3538\n",
      "\n",
      "For max feature: 5\n",
      "===== Accuracy Train: 0.451\n",
      "===== Accuracy Test: 0.454\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56      1178\n",
      "           1       0.43      0.14      0.21      1180\n",
      "           2       0.44      0.52      0.48      1180\n",
      "\n",
      "    accuracy                           0.45      3538\n",
      "   macro avg       0.45      0.45      0.42      3538\n",
      "weighted avg       0.45      0.45      0.42      3538\n",
      "\n",
      "For max feature: 6\n",
      "===== Accuracy Train: 0.557\n",
      "===== Accuracy Test: 0.557\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.58      1178\n",
      "           1       0.55      0.81      0.65      1180\n",
      "           2       0.46      0.34      0.40      1180\n",
      "\n",
      "    accuracy                           0.56      3538\n",
      "   macro avg       0.56      0.56      0.54      3538\n",
      "weighted avg       0.56      0.56      0.54      3538\n",
      "\n",
      "For max feature: 7\n",
      "===== Accuracy Train: 0.491\n",
      "===== Accuracy Test: 0.487\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.68      0.59      1178\n",
      "           1       0.45      0.54      0.49      1180\n",
      "           2       0.49      0.24      0.32      1180\n",
      "\n",
      "    accuracy                           0.49      3538\n",
      "   macro avg       0.49      0.49      0.47      3538\n",
      "weighted avg       0.49      0.49      0.47      3538\n",
      "\n",
      "For max feature: 8\n",
      "===== Accuracy Train: 0.546\n",
      "===== Accuracy Test: 0.519\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.47      0.51      1178\n",
      "           1       0.65      0.49      0.56      1180\n",
      "           2       0.43      0.60      0.50      1180\n",
      "\n",
      "    accuracy                           0.52      3538\n",
      "   macro avg       0.54      0.52      0.52      3538\n",
      "weighted avg       0.54      0.52      0.52      3538\n",
      "\n",
      "For max feature: 9\n",
      "===== Accuracy Train: 0.588\n",
      "===== Accuracy Test: 0.593\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.48      0.57      0.52      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.61      0.59      0.60      3538\n",
      "weighted avg       0.61      0.59      0.60      3538\n",
      "\n",
      "For max feature: 10\n",
      "===== Accuracy Train: 0.497\n",
      "===== Accuracy Test: 0.490\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.49      1178\n",
      "           1       0.45      0.65      0.53      1180\n",
      "           2       0.46      0.42      0.44      1180\n",
      "\n",
      "    accuracy                           0.49      3538\n",
      "   macro avg       0.51      0.49      0.49      3538\n",
      "weighted avg       0.51      0.49      0.49      3538\n",
      "\n",
      "For max feature: 11\n",
      "===== Accuracy Train: 0.530\n",
      "===== Accuracy Test: 0.518\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54      1178\n",
      "           1       0.50      0.58      0.53      1180\n",
      "           2       0.47      0.48      0.48      1180\n",
      "\n",
      "    accuracy                           0.52      3538\n",
      "   macro avg       0.52      0.52      0.52      3538\n",
      "weighted avg       0.52      0.52      0.52      3538\n",
      "\n",
      "For max feature: 12\n",
      "===== Accuracy Train: 0.531\n",
      "===== Accuracy Test: 0.527\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60      1178\n",
      "           1       0.51      0.44      0.47      1180\n",
      "           2       0.52      0.47      0.49      1180\n",
      "\n",
      "    accuracy                           0.53      3538\n",
      "   macro avg       0.53      0.53      0.52      3538\n",
      "weighted avg       0.53      0.53      0.52      3538\n",
      "\n",
      "For max feature: 13\n",
      "===== Accuracy Train: 0.470\n",
      "===== Accuracy Test: 0.467\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48      1178\n",
      "           1       0.45      0.72      0.55      1180\n",
      "           2       0.40      0.26      0.31      1180\n",
      "\n",
      "    accuracy                           0.47      3538\n",
      "   macro avg       0.47      0.47      0.45      3538\n",
      "weighted avg       0.47      0.47      0.45      3538\n",
      "\n",
      "For max feature: 14\n",
      "===== Accuracy Train: 0.531\n",
      "===== Accuracy Test: 0.521\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50      1178\n",
      "           1       0.61      0.63      0.62      1180\n",
      "           2       0.46      0.42      0.44      1180\n",
      "\n",
      "    accuracy                           0.52      3538\n",
      "   macro avg       0.52      0.52      0.52      3538\n",
      "weighted avg       0.52      0.52      0.52      3538\n",
      "\n",
      "For max feature: 15\n",
      "===== Accuracy Train: 0.541\n",
      "===== Accuracy Test: 0.525\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56      1178\n",
      "           1       0.83      0.25      0.38      1180\n",
      "           2       0.47      0.74      0.57      1180\n",
      "\n",
      "    accuracy                           0.53      3538\n",
      "   macro avg       0.61      0.53      0.50      3538\n",
      "weighted avg       0.61      0.53      0.50      3538\n",
      "\n",
      "For max feature: 16\n",
      "===== Accuracy Train: 0.550\n",
      "===== Accuracy Test: 0.536\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.45      0.55      1178\n",
      "           1       0.53      0.58      0.56      1180\n",
      "           2       0.46      0.57      0.51      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.56      0.54      0.54      3538\n",
      "weighted avg       0.56      0.54      0.54      3538\n",
      "\n",
      "For max feature: 17\n",
      "===== Accuracy Train: 0.538\n",
      "===== Accuracy Test: 0.542\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55      1178\n",
      "           1       0.57      0.64      0.60      1180\n",
      "           2       0.46      0.48      0.47      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.54      0.54      0.54      3538\n",
      "weighted avg       0.54      0.54      0.54      3538\n",
      "\n",
      "For max feature: 18\n",
      "===== Accuracy Train: 0.579\n",
      "===== Accuracy Test: 0.579\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.62      1178\n",
      "           1       0.52      0.74      0.61      1180\n",
      "           2       0.53      0.48      0.50      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.61      0.58      0.58      3538\n",
      "weighted avg       0.61      0.58      0.58      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 19\n",
      "===== Accuracy Train: 0.571\n",
      "===== Accuracy Test: 0.575\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.41      0.55      1178\n",
      "           1       0.55      0.77      0.64      1180\n",
      "           2       0.50      0.54      0.52      1180\n",
      "\n",
      "    accuracy                           0.57      3538\n",
      "   macro avg       0.62      0.57      0.57      3538\n",
      "weighted avg       0.62      0.57      0.57      3538\n",
      "\n",
      "For max feature: 20\n",
      "===== Accuracy Train: 0.543\n",
      "===== Accuracy Test: 0.537\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.61      1178\n",
      "           1       0.50      0.54      0.52      1180\n",
      "           2       0.48      0.48      0.48      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.54      0.54      0.54      3538\n",
      "weighted avg       0.54      0.54      0.54      3538\n",
      "\n",
      "For max feature: 21\n",
      "===== Accuracy Train: 0.598\n",
      "===== Accuracy Test: 0.594\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.53      0.47      0.49      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.59      0.59      0.59      3538\n",
      "weighted avg       0.59      0.59      0.59      3538\n",
      "\n",
      "For max feature: 22\n",
      "===== Accuracy Train: 0.540\n",
      "===== Accuracy Test: 0.523\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55      1178\n",
      "           1       0.53      0.55      0.54      1180\n",
      "           2       0.48      0.48      0.48      1180\n",
      "\n",
      "    accuracy                           0.52      3538\n",
      "   macro avg       0.52      0.52      0.52      3538\n",
      "weighted avg       0.52      0.52      0.52      3538\n",
      "\n",
      "For max feature: 23\n",
      "===== Accuracy Train: 0.589\n",
      "===== Accuracy Test: 0.602\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.53      0.48      0.50      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.60      3538\n",
      "weighted avg       0.60      0.60      0.60      3538\n",
      "\n",
      "For max feature: 24\n",
      "===== Accuracy Train: 0.513\n",
      "===== Accuracy Test: 0.496\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61      1178\n",
      "           1       0.47      0.37      0.41      1180\n",
      "           2       0.43      0.46      0.45      1180\n",
      "\n",
      "    accuracy                           0.50      3538\n",
      "   macro avg       0.49      0.50      0.49      3538\n",
      "weighted avg       0.49      0.50      0.49      3538\n",
      "\n",
      "For max feature: 25\n",
      "===== Accuracy Train: 0.546\n",
      "===== Accuracy Test: 0.542\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58      1178\n",
      "           1       0.49      0.79      0.61      1180\n",
      "           2       0.54      0.30      0.39      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.56      0.54      0.53      3538\n",
      "weighted avg       0.56      0.54      0.53      3538\n",
      "\n",
      "For max feature: 26\n",
      "===== Accuracy Train: 0.552\n",
      "===== Accuracy Test: 0.551\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59      1178\n",
      "           1       0.54      0.66      0.60      1180\n",
      "           2       0.46      0.49      0.47      1180\n",
      "\n",
      "    accuracy                           0.55      3538\n",
      "   macro avg       0.57      0.55      0.55      3538\n",
      "weighted avg       0.57      0.55      0.55      3538\n",
      "\n",
      "For max feature: 27\n",
      "===== Accuracy Train: 0.577\n",
      "===== Accuracy Test: 0.558\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57      1178\n",
      "           1       0.55      0.59      0.57      1180\n",
      "           2       0.54      0.52      0.53      1180\n",
      "\n",
      "    accuracy                           0.56      3538\n",
      "   macro avg       0.56      0.56      0.56      3538\n",
      "weighted avg       0.56      0.56      0.56      3538\n",
      "\n",
      "For max feature: 28\n",
      "===== Accuracy Train: 0.579\n",
      "===== Accuracy Test: 0.569\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      1178\n",
      "           1       0.60      0.81      0.69      1180\n",
      "           2       0.52      0.32      0.40      1180\n",
      "\n",
      "    accuracy                           0.57      3538\n",
      "   macro avg       0.56      0.57      0.55      3538\n",
      "weighted avg       0.56      0.57      0.55      3538\n",
      "\n",
      "For max feature: 29\n",
      "===== Accuracy Train: 0.599\n",
      "===== Accuracy Test: 0.600\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60      1178\n",
      "           1       0.60      0.79      0.68      1180\n",
      "           2       0.54      0.47      0.50      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.59      3538\n",
      "weighted avg       0.60      0.60      0.59      3538\n",
      "\n",
      "For max feature: 30\n",
      "===== Accuracy Train: 0.591\n",
      "===== Accuracy Test: 0.591\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61      1178\n",
      "           1       0.68      0.60      0.64      1180\n",
      "           2       0.49      0.59      0.54      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.60      0.59      0.59      3538\n",
      "weighted avg       0.60      0.59      0.59      3538\n",
      "\n",
      "For max feature: 31\n",
      "===== Accuracy Train: 0.603\n",
      "===== Accuracy Test: 0.602\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1178\n",
      "           1       0.67      0.60      0.63      1180\n",
      "           2       0.52      0.54      0.53      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.60      3538\n",
      "weighted avg       0.60      0.60      0.60      3538\n",
      "\n",
      "For max feature: 32\n",
      "===== Accuracy Train: 0.627\n",
      "===== Accuracy Test: 0.622\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59      1178\n",
      "           1       0.71      0.77      0.74      1180\n",
      "           2       0.52      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.62      3538\n",
      "weighted avg       0.62      0.62      0.62      3538\n",
      "\n",
      "For max feature: 33\n",
      "===== Accuracy Train: 0.565\n",
      "===== Accuracy Test: 0.563\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60      1178\n",
      "           1       0.55      0.57      0.56      1180\n",
      "           2       0.52      0.53      0.53      1180\n",
      "\n",
      "    accuracy                           0.56      3538\n",
      "   macro avg       0.56      0.56      0.56      3538\n",
      "weighted avg       0.56      0.56      0.56      3538\n",
      "\n",
      "For max feature: 34\n",
      "===== Accuracy Train: 0.575\n",
      "===== Accuracy Test: 0.571\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61      1178\n",
      "           1       0.49      0.77      0.60      1180\n",
      "           2       0.57      0.44      0.50      1180\n",
      "\n",
      "    accuracy                           0.57      3538\n",
      "   macro avg       0.61      0.57      0.57      3538\n",
      "weighted avg       0.61      0.57      0.57      3538\n",
      "\n",
      "For max feature: 35\n",
      "===== Accuracy Train: 0.596\n",
      "===== Accuracy Test: 0.599\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.57      0.58      1178\n",
      "           1       0.68      0.68      0.68      1180\n",
      "           2       0.52      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.60      3538\n",
      "weighted avg       0.60      0.60      0.60      3538\n",
      "\n",
      "For max feature: 36\n",
      "===== Accuracy Train: 0.562\n",
      "===== Accuracy Test: 0.565\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.51      0.58      1178\n",
      "           1       0.52      0.83      0.64      1180\n",
      "           2       0.55      0.36      0.43      1180\n",
      "\n",
      "    accuracy                           0.57      3538\n",
      "   macro avg       0.58      0.57      0.55      3538\n",
      "weighted avg       0.58      0.57      0.55      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 37\n",
      "===== Accuracy Train: 0.609\n",
      "===== Accuracy Test: 0.607\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62      1178\n",
      "           1       0.70      0.63      0.66      1180\n",
      "           2       0.51      0.60      0.55      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.61      3538\n",
      "weighted avg       0.62      0.61      0.61      3538\n",
      "\n",
      "For max feature: 38\n",
      "===== Accuracy Train: 0.550\n",
      "===== Accuracy Test: 0.541\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.49      0.58      1178\n",
      "           1       0.51      0.61      0.56      1180\n",
      "           2       0.47      0.52      0.50      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.56      0.54      0.54      3538\n",
      "weighted avg       0.56      0.54      0.54      3538\n",
      "\n",
      "For max feature: 39\n",
      "===== Accuracy Train: 0.581\n",
      "===== Accuracy Test: 0.583\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.52      0.42      0.47      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.58      0.58      0.58      3538\n",
      "weighted avg       0.58      0.58      0.58      3538\n",
      "\n",
      "For max feature: 40\n",
      "===== Accuracy Train: 0.643\n",
      "===== Accuracy Test: 0.644\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.48      0.58      1178\n",
      "           1       0.73      0.76      0.74      1180\n",
      "           2       0.53      0.69      0.60      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.67      0.64      0.64      3538\n",
      "weighted avg       0.67      0.64      0.64      3538\n",
      "\n",
      "For max feature: 41\n",
      "===== Accuracy Train: 0.531\n",
      "===== Accuracy Test: 0.538\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62      1178\n",
      "           1       0.51      0.42      0.46      1180\n",
      "           2       0.47      0.62      0.53      1180\n",
      "\n",
      "    accuracy                           0.54      3538\n",
      "   macro avg       0.55      0.54      0.54      3538\n",
      "weighted avg       0.55      0.54      0.54      3538\n",
      "\n",
      "For max feature: 42\n",
      "===== Accuracy Train: 0.603\n",
      "===== Accuracy Test: 0.598\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1178\n",
      "           1       0.74      0.51      0.60      1180\n",
      "           2       0.51      0.64      0.57      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.62      0.60      0.60      3538\n",
      "weighted avg       0.62      0.60      0.60      3538\n",
      "\n",
      "For max feature: 43\n",
      "===== Accuracy Train: 0.597\n",
      "===== Accuracy Test: 0.605\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.52      0.51      0.51      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.60      3538\n",
      "weighted avg       0.61      0.61      0.60      3538\n",
      "\n",
      "For max feature: 44\n",
      "===== Accuracy Train: 0.590\n",
      "===== Accuracy Test: 0.592\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67      1178\n",
      "           1       0.64      0.62      0.63      1180\n",
      "           2       0.50      0.43      0.46      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.59      0.59      0.59      3538\n",
      "weighted avg       0.59      0.59      0.59      3538\n",
      "\n",
      "For max feature: 45\n",
      "===== Accuracy Train: 0.585\n",
      "===== Accuracy Test: 0.578\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      1178\n",
      "           1       0.64      0.75      0.69      1180\n",
      "           2       0.44      0.35      0.39      1180\n",
      "\n",
      "    accuracy                           0.58      3538\n",
      "   macro avg       0.57      0.58      0.57      3538\n",
      "weighted avg       0.57      0.58      0.57      3538\n",
      "\n",
      "For max feature: 46\n",
      "===== Accuracy Train: 0.608\n",
      "===== Accuracy Test: 0.610\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61      1178\n",
      "           1       0.59      0.78      0.67      1180\n",
      "           2       0.55      0.51      0.53      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.61      3538\n",
      "weighted avg       0.62      0.61      0.61      3538\n",
      "\n",
      "For max feature: 47\n",
      "===== Accuracy Train: 0.628\n",
      "===== Accuracy Test: 0.627\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62      1178\n",
      "           1       0.70      0.76      0.73      1180\n",
      "           2       0.52      0.55      0.53      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.63      0.63      0.63      3538\n",
      "weighted avg       0.63      0.63      0.63      3538\n",
      "\n",
      "For max feature: 48\n",
      "===== Accuracy Train: 0.599\n",
      "===== Accuracy Test: 0.602\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64      1178\n",
      "           1       0.66      0.68      0.67      1180\n",
      "           2       0.52      0.47      0.49      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.60      3538\n",
      "weighted avg       0.60      0.60      0.60      3538\n",
      "\n",
      "For max feature: 49\n",
      "===== Accuracy Train: 0.606\n",
      "===== Accuracy Test: 0.601\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      1178\n",
      "           1       0.60      0.81      0.69      1180\n",
      "           2       0.58      0.39      0.47      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.59      3538\n",
      "weighted avg       0.60      0.60      0.59      3538\n",
      "\n",
      "For max feature: 50\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.613\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1178\n",
      "           1       0.59      0.83      0.69      1180\n",
      "           2       0.58      0.37      0.45      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.60      3538\n",
      "weighted avg       0.61      0.61      0.60      3538\n",
      "\n",
      "For max feature: 51\n",
      "===== Accuracy Train: 0.584\n",
      "===== Accuracy Test: 0.588\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1178\n",
      "           1       0.71      0.49      0.58      1180\n",
      "           2       0.48      0.64      0.55      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.61      0.59      0.59      3538\n",
      "weighted avg       0.61      0.59      0.59      3538\n",
      "\n",
      "For max feature: 52\n",
      "===== Accuracy Train: 0.592\n",
      "===== Accuracy Test: 0.603\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66      1178\n",
      "           1       0.60      0.87      0.71      1180\n",
      "           2       0.60      0.22      0.32      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.56      3538\n",
      "weighted avg       0.60      0.60      0.56      3538\n",
      "\n",
      "For max feature: 53\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.626\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      1178\n",
      "           1       0.65      0.75      0.69      1180\n",
      "           2       0.52      0.51      0.52      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.63      0.63      0.62      3538\n",
      "weighted avg       0.63      0.63      0.62      3538\n",
      "\n",
      "For max feature: 54\n",
      "===== Accuracy Train: 0.596\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.74      0.64      1178\n",
      "           1       0.63      0.83      0.72      1180\n",
      "           2       0.60      0.21      0.32      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.56      3538\n",
      "weighted avg       0.60      0.60      0.56      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 55\n",
      "===== Accuracy Train: 0.620\n",
      "===== Accuracy Test: 0.613\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61      1178\n",
      "           1       0.74      0.65      0.69      1180\n",
      "           2       0.52      0.57      0.54      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.62      3538\n",
      "weighted avg       0.62      0.61      0.62      3538\n",
      "\n",
      "For max feature: 56\n",
      "===== Accuracy Train: 0.638\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61      1178\n",
      "           1       0.73      0.79      0.76      1180\n",
      "           2       0.54      0.52      0.53      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.63      0.63      0.63      3538\n",
      "weighted avg       0.63      0.63      0.63      3538\n",
      "\n",
      "For max feature: 57\n",
      "===== Accuracy Train: 0.606\n",
      "===== Accuracy Test: 0.610\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.50      0.58      0.54      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.61      3538\n",
      "weighted avg       0.62      0.61      0.61      3538\n",
      "\n",
      "For max feature: 58\n",
      "===== Accuracy Train: 0.607\n",
      "===== Accuracy Test: 0.594\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61      1178\n",
      "           1       0.65      0.69      0.67      1180\n",
      "           2       0.52      0.48      0.50      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.59      0.59      0.59      3538\n",
      "weighted avg       0.59      0.59      0.59      3538\n",
      "\n",
      "For max feature: 59\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.609\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1178\n",
      "           1       0.61      0.84      0.71      1180\n",
      "           2       0.60      0.34      0.43      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.59      3538\n",
      "weighted avg       0.61      0.61      0.59      3538\n",
      "\n",
      "For max feature: 60\n",
      "===== Accuracy Train: 0.649\n",
      "===== Accuracy Test: 0.645\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.57      0.55      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.65      3538\n",
      "weighted avg       0.65      0.64      0.65      3538\n",
      "\n",
      "For max feature: 61\n",
      "===== Accuracy Train: 0.620\n",
      "===== Accuracy Test: 0.620\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62      1178\n",
      "           1       0.69      0.75      0.72      1180\n",
      "           2       0.53      0.49      0.51      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.62      3538\n",
      "weighted avg       0.62      0.62      0.62      3538\n",
      "\n",
      "For max feature: 62\n",
      "===== Accuracy Train: 0.605\n",
      "===== Accuracy Test: 0.606\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.69      0.68      0.68      1180\n",
      "           2       0.49      0.60      0.54      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.61      3538\n",
      "weighted avg       0.62      0.61      0.61      3538\n",
      "\n",
      "For max feature: 63\n",
      "===== Accuracy Train: 0.639\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.73      0.76      0.74      1180\n",
      "           2       0.54      0.63      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 64\n",
      "===== Accuracy Train: 0.594\n",
      "===== Accuracy Test: 0.594\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1178\n",
      "           1       0.61      0.82      0.70      1180\n",
      "           2       0.53      0.33      0.41      1180\n",
      "\n",
      "    accuracy                           0.59      3538\n",
      "   macro avg       0.58      0.59      0.58      3538\n",
      "weighted avg       0.58      0.59      0.58      3538\n",
      "\n",
      "For max feature: 65\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 66\n",
      "===== Accuracy Train: 0.619\n",
      "===== Accuracy Test: 0.624\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.54      0.63      1178\n",
      "           1       0.69      0.70      0.70      1180\n",
      "           2       0.50      0.62      0.55      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.64      0.62      0.63      3538\n",
      "weighted avg       0.64      0.62      0.63      3538\n",
      "\n",
      "For max feature: 67\n",
      "===== Accuracy Train: 0.658\n",
      "===== Accuracy Test: 0.646\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.57      0.52      0.55      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 68\n",
      "===== Accuracy Train: 0.641\n",
      "===== Accuracy Test: 0.637\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.73      0.73      0.73      1180\n",
      "           2       0.53      0.64      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 69\n",
      "===== Accuracy Train: 0.634\n",
      "===== Accuracy Test: 0.636\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68      1178\n",
      "           1       0.69      0.71      0.70      1180\n",
      "           2       0.59      0.44      0.50      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.63      0.64      0.63      3538\n",
      "weighted avg       0.63      0.64      0.63      3538\n",
      "\n",
      "For max feature: 70\n",
      "===== Accuracy Train: 0.607\n",
      "===== Accuracy Test: 0.610\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62      1178\n",
      "           1       0.77      0.57      0.66      1180\n",
      "           2       0.49      0.68      0.57      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.64      0.61      0.62      3538\n",
      "weighted avg       0.64      0.61      0.62      3538\n",
      "\n",
      "For max feature: 71\n",
      "===== Accuracy Train: 0.594\n",
      "===== Accuracy Test: 0.602\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.49      0.59      1178\n",
      "           1       0.57      0.87      0.69      1180\n",
      "           2       0.55      0.44      0.49      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.62      0.60      0.59      3538\n",
      "weighted avg       0.62      0.60      0.59      3538\n",
      "\n",
      "For max feature: 72\n",
      "===== Accuracy Train: 0.649\n",
      "===== Accuracy Test: 0.645\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.57      0.55      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.65      3538\n",
      "weighted avg       0.65      0.64      0.65      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 73\n",
      "===== Accuracy Train: 0.597\n",
      "===== Accuracy Test: 0.605\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.52      0.51      0.51      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.60      3538\n",
      "weighted avg       0.61      0.61      0.60      3538\n",
      "\n",
      "For max feature: 74\n",
      "===== Accuracy Train: 0.648\n",
      "===== Accuracy Test: 0.650\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 75\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 76\n",
      "===== Accuracy Train: 0.597\n",
      "===== Accuracy Test: 0.605\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.52      0.51      0.51      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.60      3538\n",
      "weighted avg       0.61      0.61      0.60      3538\n",
      "\n",
      "For max feature: 77\n",
      "===== Accuracy Train: 0.613\n",
      "===== Accuracy Test: 0.616\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.57      0.39      0.46      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.61      0.62      0.60      3538\n",
      "weighted avg       0.61      0.62      0.60      3538\n",
      "\n",
      "For max feature: 78\n",
      "===== Accuracy Train: 0.612\n",
      "===== Accuracy Test: 0.621\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.57      0.37      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 79\n",
      "===== Accuracy Train: 0.630\n",
      "===== Accuracy Test: 0.635\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61      1178\n",
      "           1       0.73      0.79      0.76      1180\n",
      "           2       0.53      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.63      0.64      0.63      3538\n",
      "weighted avg       0.63      0.64      0.63      3538\n",
      "\n",
      "For max feature: 80\n",
      "===== Accuracy Train: 0.636\n",
      "===== Accuracy Test: 0.628\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.52      0.65      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.66      0.63      0.63      3538\n",
      "weighted avg       0.66      0.63      0.63      3538\n",
      "\n",
      "For max feature: 81\n",
      "===== Accuracy Train: 0.640\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.49      0.76      0.60      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.68      0.62      0.63      3538\n",
      "weighted avg       0.68      0.62      0.63      3538\n",
      "\n",
      "For max feature: 82\n",
      "===== Accuracy Train: 0.619\n",
      "===== Accuracy Test: 0.628\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.68      0.71      0.69      1180\n",
      "           2       0.51      0.53      0.52      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.63      0.63      0.63      3538\n",
      "weighted avg       0.63      0.63      0.63      3538\n",
      "\n",
      "For max feature: 83\n",
      "===== Accuracy Train: 0.642\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.79      0.66      0.72      1180\n",
      "           2       0.52      0.66      0.58      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.67      0.65      0.66      3538\n",
      "weighted avg       0.67      0.65      0.66      3538\n",
      "\n",
      "For max feature: 84\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 85\n",
      "===== Accuracy Train: 0.644\n",
      "===== Accuracy Test: 0.644\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.53      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.65      3538\n",
      "weighted avg       0.65      0.64      0.65      3538\n",
      "\n",
      "For max feature: 86\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 87\n",
      "===== Accuracy Train: 0.591\n",
      "===== Accuracy Test: 0.600\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61      1178\n",
      "           1       0.61      0.83      0.70      1180\n",
      "           2       0.60      0.34      0.43      1180\n",
      "\n",
      "    accuracy                           0.60      3538\n",
      "   macro avg       0.60      0.60      0.58      3538\n",
      "weighted avg       0.60      0.60      0.58      3538\n",
      "\n",
      "For max feature: 88\n",
      "===== Accuracy Train: 0.641\n",
      "===== Accuracy Test: 0.638\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.53      0.57      0.55      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.64      0.64      0.64      3538\n",
      "weighted avg       0.64      0.64      0.64      3538\n",
      "\n",
      "For max feature: 89\n",
      "===== Accuracy Train: 0.657\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.54      0.62      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 90\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 91\n",
      "===== Accuracy Train: 0.639\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.73      0.76      0.74      1180\n",
      "           2       0.54      0.63      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 92\n",
      "===== Accuracy Train: 0.629\n",
      "===== Accuracy Test: 0.635\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.49      0.78      0.60      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.70      0.63      0.64      3538\n",
      "weighted avg       0.70      0.63      0.64      3538\n",
      "\n",
      "For max feature: 93\n",
      "===== Accuracy Train: 0.642\n",
      "===== Accuracy Test: 0.625\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.59      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.49      0.76      0.60      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.63      3538\n",
      "weighted avg       0.68      0.63      0.63      3538\n",
      "\n",
      "For max feature: 94\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 95\n",
      "===== Accuracy Train: 0.642\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.79      0.66      0.72      1180\n",
      "           2       0.52      0.66      0.58      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.67      0.65      0.66      3538\n",
      "weighted avg       0.67      0.65      0.66      3538\n",
      "\n",
      "For max feature: 96\n",
      "===== Accuracy Train: 0.644\n",
      "===== Accuracy Test: 0.644\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.53      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.65      3538\n",
      "weighted avg       0.65      0.64      0.65      3538\n",
      "\n",
      "For max feature: 97\n",
      "===== Accuracy Train: 0.640\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.52      0.55      0.53      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 98\n",
      "===== Accuracy Train: 0.658\n",
      "===== Accuracy Test: 0.646\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.57      0.52      0.55      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 99\n",
      "===== Accuracy Train: 0.644\n",
      "===== Accuracy Test: 0.644\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.53      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.65      3538\n",
      "weighted avg       0.65      0.64      0.65      3538\n",
      "\n",
      "For max feature: 100\n",
      "===== Accuracy Train: 0.605\n",
      "===== Accuracy Test: 0.606\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.69      0.68      0.68      1180\n",
      "           2       0.49      0.60      0.54      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.62      0.61      0.61      3538\n",
      "weighted avg       0.62      0.61      0.61      3538\n",
      "\n",
      "For max feature: 101\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 102\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 103\n",
      "===== Accuracy Train: 0.658\n",
      "===== Accuracy Test: 0.646\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.57      0.52      0.55      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 104\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 105\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 106\n",
      "===== Accuracy Train: 0.631\n",
      "===== Accuracy Test: 0.636\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.69      0.73      0.71      1180\n",
      "           2       0.52      0.54      0.53      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.64      0.64      0.64      3538\n",
      "weighted avg       0.64      0.64      0.64      3538\n",
      "\n",
      "For max feature: 107\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 108\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 109\n",
      "===== Accuracy Train: 0.597\n",
      "===== Accuracy Test: 0.605\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.52      0.51      0.51      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.61      0.61      0.60      3538\n",
      "weighted avg       0.61      0.61      0.60      3538\n",
      "\n",
      "For max feature: 110\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 111\n",
      "===== Accuracy Train: 0.609\n",
      "===== Accuracy Test: 0.615\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.47      0.58      0.52      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.65      0.61      0.62      3538\n",
      "weighted avg       0.65      0.61      0.62      3538\n",
      "\n",
      "For max feature: 112\n",
      "===== Accuracy Train: 0.649\n",
      "===== Accuracy Test: 0.656\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1178\n",
      "           1       0.79      0.66      0.72      1180\n",
      "           2       0.53      0.66      0.59      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.68      0.66      0.66      3538\n",
      "weighted avg       0.68      0.66      0.66      3538\n",
      "\n",
      "For max feature: 113\n",
      "===== Accuracy Train: 0.608\n",
      "===== Accuracy Test: 0.615\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.60      0.83      0.70      1180\n",
      "           2       0.57      0.36      0.44      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.61      0.62      0.60      3538\n",
      "weighted avg       0.61      0.62      0.60      3538\n",
      "\n",
      "For max feature: 114\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 115\n",
      "===== Accuracy Train: 0.658\n",
      "===== Accuracy Test: 0.646\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.57      0.52      0.55      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 116\n",
      "===== Accuracy Train: 0.642\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.79      0.66      0.72      1180\n",
      "           2       0.52      0.66      0.58      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.67      0.65      0.66      3538\n",
      "weighted avg       0.67      0.65      0.66      3538\n",
      "\n",
      "For max feature: 117\n",
      "===== Accuracy Train: 0.642\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1178\n",
      "           1       0.79      0.66      0.72      1180\n",
      "           2       0.52      0.66      0.58      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.67      0.65      0.66      3538\n",
      "weighted avg       0.67      0.65      0.66      3538\n",
      "\n",
      "For max feature: 118\n",
      "===== Accuracy Train: 0.658\n",
      "===== Accuracy Test: 0.646\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65      1178\n",
      "           1       0.79      0.71      0.75      1180\n",
      "           2       0.57      0.52      0.55      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 119\n",
      "===== Accuracy Train: 0.639\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.73      0.76      0.74      1180\n",
      "           2       0.54      0.63      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 120\n",
      "===== Accuracy Train: 0.648\n",
      "===== Accuracy Test: 0.650\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 121\n",
      "===== Accuracy Train: 0.648\n",
      "===== Accuracy Test: 0.650\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 122\n",
      "===== Accuracy Train: 0.610\n",
      "===== Accuracy Test: 0.618\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      1178\n",
      "           1       0.60      0.88      0.71      1180\n",
      "           2       0.61      0.36      0.46      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.60      3538\n",
      "weighted avg       0.62      0.62      0.60      3538\n",
      "\n",
      "For max feature: 123\n",
      "===== Accuracy Train: 0.631\n",
      "===== Accuracy Test: 0.630\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62      1178\n",
      "           1       0.72      0.73      0.73      1180\n",
      "           2       0.52      0.58      0.55      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.64      0.63      0.63      3538\n",
      "weighted avg       0.64      0.63      0.63      3538\n",
      "\n",
      "For max feature: 124\n",
      "===== Accuracy Train: 0.612\n",
      "===== Accuracy Test: 0.620\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.48      0.58      0.53      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.66      0.62      0.63      3538\n",
      "weighted avg       0.66      0.62      0.63      3538\n",
      "\n",
      "For max feature: 125\n",
      "===== Accuracy Train: 0.648\n",
      "===== Accuracy Test: 0.650\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 126\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 127\n",
      "===== Accuracy Train: 0.639\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60      1178\n",
      "           1       0.73      0.76      0.74      1180\n",
      "           2       0.54      0.63      0.58      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 128\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 129\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 130\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 131\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 132\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 133\n",
      "===== Accuracy Train: 0.616\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.61      0.85      0.71      1180\n",
      "           2       0.58      0.36      0.45      1180\n",
      "\n",
      "    accuracy                           0.62      3538\n",
      "   macro avg       0.62      0.62      0.61      3538\n",
      "weighted avg       0.62      0.62      0.61      3538\n",
      "\n",
      "For max feature: 134\n",
      "===== Accuracy Train: 0.647\n",
      "===== Accuracy Test: 0.651\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63      1178\n",
      "           1       0.79      0.74      0.76      1180\n",
      "           2       0.58      0.55      0.56      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 135\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 136\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 137\n",
      "===== Accuracy Train: 0.640\n",
      "===== Accuracy Test: 0.642\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.74      0.73      0.74      1180\n",
      "           2       0.52      0.55      0.53      1180\n",
      "\n",
      "    accuracy                           0.64      3538\n",
      "   macro avg       0.65      0.64      0.64      3538\n",
      "weighted avg       0.65      0.64      0.64      3538\n",
      "\n",
      "For max feature: 138\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 139\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 140\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 141\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 142\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 143\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 144\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 145\n",
      "===== Accuracy Train: 0.633\n",
      "===== Accuracy Test: 0.634\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.50      0.69      0.58      1180\n",
      "\n",
      "    accuracy                           0.63      3538\n",
      "   macro avg       0.68      0.63      0.64      3538\n",
      "weighted avg       0.68      0.63      0.64      3538\n",
      "\n",
      "For max feature: 146\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 147\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 148\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 149\n",
      "===== Accuracy Train: 0.648\n",
      "===== Accuracy Test: 0.650\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.53      0.55      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 150\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 151\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n",
      "For max feature: 152\n",
      "===== Accuracy Train: 0.651\n",
      "===== Accuracy Test: 0.652\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1178\n",
      "           1       0.75      0.75      0.75      1180\n",
      "           2       0.54      0.54      0.54      1180\n",
      "\n",
      "    accuracy                           0.65      3538\n",
      "   macro avg       0.65      0.65      0.65      3538\n",
      "weighted avg       0.65      0.65      0.65      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since max features changed with PCA fitting, determine best about of features again\n",
    "max_features = list(range(1,X_transformed.shape[1]))\n",
    "\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "    dt.fit(X_transformed, y_train)\n",
    "    train_pred = dt.predict(X_transformed)\n",
    "    y_pred = dt.predict(X_test_transformed)\n",
    "    \n",
    "    print(\"For max feature:\", max_feature)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 82.2% accuracy with max features 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.510\n",
      "===== Accuracy Test: 0.519\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.87      0.59      1178\n",
      "           1       0.64      0.69      0.67      1180\n",
      "           2       0.00      0.00      0.00      1180\n",
      "\n",
      "    accuracy                           0.52      3538\n",
      "   macro avg       0.36      0.52      0.42      3538\n",
      "weighted avg       0.36      0.52      0.42      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 2.0\n",
      "===== Accuracy Train: 0.607\n",
      "===== Accuracy Test: 0.612\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.74      0.64      1178\n",
      "           1       0.87      0.60      0.71      1180\n",
      "           2       0.49      0.50      0.49      1180\n",
      "\n",
      "    accuracy                           0.61      3538\n",
      "   macro avg       0.64      0.61      0.62      3538\n",
      "weighted avg       0.64      0.61      0.62      3538\n",
      "\n",
      "For max depth: 3.0\n",
      "===== Accuracy Train: 0.662\n",
      "===== Accuracy Test: 0.664\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1178\n",
      "           1       0.74      0.82      0.78      1180\n",
      "           2       0.57      0.50      0.53      1180\n",
      "\n",
      "    accuracy                           0.66      3538\n",
      "   macro avg       0.66      0.66      0.66      3538\n",
      "weighted avg       0.66      0.66      0.66      3538\n",
      "\n",
      "For max depth: 4.0\n",
      "===== Accuracy Train: 0.717\n",
      "===== Accuracy Test: 0.709\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72      1178\n",
      "           1       0.84      0.78      0.81      1180\n",
      "           2       0.63      0.56      0.59      1180\n",
      "\n",
      "    accuracy                           0.71      3538\n",
      "   macro avg       0.71      0.71      0.71      3538\n",
      "weighted avg       0.71      0.71      0.71      3538\n",
      "\n",
      "For max depth: 5.0\n",
      "===== Accuracy Train: 0.739\n",
      "===== Accuracy Test: 0.715\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      1178\n",
      "           1       0.86      0.77      0.81      1180\n",
      "           2       0.62      0.60      0.61      1180\n",
      "\n",
      "    accuracy                           0.72      3538\n",
      "   macro avg       0.72      0.72      0.72      3538\n",
      "weighted avg       0.72      0.72      0.72      3538\n",
      "\n",
      "For max depth: 6.0\n",
      "===== Accuracy Train: 0.776\n",
      "===== Accuracy Test: 0.725\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73      1178\n",
      "           1       0.83      0.81      0.82      1180\n",
      "           2       0.63      0.62      0.62      1180\n",
      "\n",
      "    accuracy                           0.72      3538\n",
      "   macro avg       0.73      0.72      0.72      3538\n",
      "weighted avg       0.73      0.72      0.72      3538\n",
      "\n",
      "For max depth: 7.0\n",
      "===== Accuracy Train: 0.816\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.67      0.67      0.67      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 8.0\n",
      "===== Accuracy Train: 0.851\n",
      "===== Accuracy Test: 0.770\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1178\n",
      "           1       0.86      0.85      0.85      1180\n",
      "           2       0.68      0.69      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 9.0\n",
      "===== Accuracy Train: 0.890\n",
      "===== Accuracy Test: 0.774\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      1178\n",
      "           1       0.85      0.84      0.85      1180\n",
      "           2       0.70      0.68      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 10.0\n",
      "===== Accuracy Train: 0.925\n",
      "===== Accuracy Test: 0.772\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78      1178\n",
      "           1       0.85      0.85      0.85      1180\n",
      "           2       0.70      0.67      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 11.0\n",
      "===== Accuracy Train: 0.951\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1178\n",
      "           1       0.84      0.85      0.84      1180\n",
      "           2       0.70      0.67      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 12.0\n",
      "===== Accuracy Train: 0.969\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1178\n",
      "           1       0.84      0.85      0.85      1180\n",
      "           2       0.71      0.66      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 13.0\n",
      "===== Accuracy Train: 0.979\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      1178\n",
      "           1       0.83      0.85      0.84      1180\n",
      "           2       0.71      0.66      0.68      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 14.0\n",
      "===== Accuracy Train: 0.986\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1178\n",
      "           1       0.83      0.84      0.84      1180\n",
      "           2       0.70      0.66      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 15.0\n",
      "===== Accuracy Train: 0.989\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1178\n",
      "           1       0.83      0.84      0.83      1180\n",
      "           2       0.69      0.66      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 16.0\n",
      "===== Accuracy Train: 0.991\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1178\n",
      "           1       0.83      0.84      0.83      1180\n",
      "           2       0.70      0.68      0.69      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 17.0\n",
      "===== Accuracy Train: 0.993\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1178\n",
      "           1       0.83      0.85      0.84      1180\n",
      "           2       0.69      0.65      0.67      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 18.0\n",
      "===== Accuracy Train: 0.994\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1178\n",
      "           1       0.83      0.85      0.84      1180\n",
      "           2       0.70      0.68      0.69      1180\n",
      "\n",
      "    accuracy                           0.77      3538\n",
      "   macro avg       0.77      0.77      0.77      3538\n",
      "weighted avg       0.77      0.77      0.77      3538\n",
      "\n",
      "For max depth: 19.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1178\n",
      "           1       0.83      0.85      0.84      1180\n",
      "           2       0.70      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 20.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1178\n",
      "           1       0.83      0.84      0.83      1180\n",
      "           2       0.69      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 21.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1178\n",
      "           1       0.82      0.85      0.84      1180\n",
      "           2       0.70      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 22.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1178\n",
      "           1       0.82      0.85      0.83      1180\n",
      "           2       0.68      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.75      0.76      0.75      3538\n",
      "weighted avg       0.75      0.76      0.75      3538\n",
      "\n",
      "For max depth: 23.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.69      0.66      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 24.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.69      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 25.0\n",
      "===== Accuracy Train: 0.997\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.69      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.75      0.76      0.76      3538\n",
      "weighted avg       0.75      0.76      0.76      3538\n",
      "\n",
      "For max depth: 26.0\n",
      "===== Accuracy Train: 0.997\n",
      "===== Accuracy Test: 0.754\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1178\n",
      "           1       0.82      0.83      0.82      1180\n",
      "           2       0.69      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max depth: 27.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.68      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max depth: 28.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1178\n",
      "           1       0.83      0.84      0.83      1180\n",
      "           2       0.68      0.67      0.67      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 29.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.754\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1178\n",
      "           1       0.83      0.83      0.83      1180\n",
      "           2       0.69      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max depth: 30.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.69      0.67      0.68      1180\n",
      "\n",
      "    accuracy                           0.76      3538\n",
      "   macro avg       0.76      0.76      0.76      3538\n",
      "weighted avg       0.76      0.76      0.76      3538\n",
      "\n",
      "For max depth: 31.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.754\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      1178\n",
      "           1       0.83      0.84      0.83      1180\n",
      "           2       0.68      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n",
      "For max depth: 32.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.754\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1178\n",
      "           1       0.82      0.84      0.83      1180\n",
      "           2       0.68      0.66      0.67      1180\n",
      "\n",
      "    accuracy                           0.75      3538\n",
      "   macro avg       0.75      0.75      0.75      3538\n",
      "weighted avg       0.75      0.75      0.75      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "\n",
    "for depth in max_depths:\n",
    "    # Initialize Classifier with max_depth\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_transformed, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_transformed)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test_transformed)\n",
    "    \n",
    "    print(\"For max depth:\", depth)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Depth 77.7%, max-depth=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params\n",
      "=====Accuracy Train PCA: 0.9481942186726977\n",
      "=====Accuracy Test PCA: 0.7747314867156586\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = 11\n",
    "best_max_feature = 134\n",
    "\n",
    "# Initialize Decision Trees model for PCA instance with best params\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=best_max_depth)\n",
    "\n",
    "# Use training data to fit Decision Trees model with transformed X_train\n",
    "dt.fit(X_transformed, y_train.values.ravel())\n",
    "\n",
    "# make prediction on entire train data\n",
    "train_pred_pca = dt.predict(X_transformed)\n",
    "y_pred_pca = dt.predict(X_test_transformed)\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(\"=====Accuracy Train PCA:\", accuracy_score(y_train, train_pred_pca))\n",
    "print(\"=====Accuracy Test PCA:\", accuracy_score(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Bias \n",
    "\n",
    "Two datasets will be examined and used as unseen test data for our model.\n",
    "- People of Color (POC) dataset\n",
    "- White Individuals (W) dataset\n",
    "\n",
    "We will be using the Decision Trees Model with the best parameters discovered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features, poc_X shape:  (309, 4096)\n",
      "Target, poc_y shape:  (309,)\n",
      "Features, w_X shape:  (309, 4096)\n",
      "Target, w_y shape:  (309,)\n"
     ]
    }
   ],
   "source": [
    "# Load POC datasets\n",
    "pickle_in = open(\"X_test_POC.pickle\", \"rb\")\n",
    "poc_X = pickle.load(pickle_in)\n",
    "pickle_in = open(\"y_test_POC.pickle\", \"rb\")\n",
    "poc_y = pickle.load(pickle_in)\n",
    "\n",
    "# POC target and feature set shape\n",
    "print(\"Features, poc_X shape: \", poc_X.shape)\n",
    "print(\"Target, poc_y shape: \", poc_y.shape)\n",
    "\n",
    "# Normalize the pixel values\n",
    "poc_X = poc_X / 255.0\n",
    "\n",
    "#===================================================================\n",
    "\n",
    "# Load W datasets\n",
    "pickle_in = open(\"X_test_W.pickle\", \"rb\")\n",
    "w_X = pickle.load(pickle_in)\n",
    "pickle_in = open(\"y_test_W.pickle\", \"rb\")\n",
    "w_y = pickle.load(pickle_in)\n",
    "\n",
    "# W target and feature set shape\n",
    "print(\"Features, w_X shape: \", w_X.shape)\n",
    "print(\"Target, w_y shape: \", w_y.shape)\n",
    "\n",
    "# Normalize the pixel values\n",
    "w_X = w_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth = 10\n",
    "best_max_feature = 1138\n",
    "\n",
    "# Re-initialize Decision Trees model with best params and fit it\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=best_max_depth)\n",
    "dt.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# make prediction on entire train data\n",
    "train_pred = dt.predict(X_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# make prediction on the entire POC dataset\n",
    "y_pred_poc = dt.predict(poc_X)\n",
    "\n",
    "# make prediction on the entire W dataset\n",
    "y_pred_w = dt.predict(w_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POC Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.20      0.27       100\n",
      "           1       0.71      0.89      0.79       102\n",
      "           2       0.46      0.57      0.51       107\n",
      "\n",
      "    accuracy                           0.56       309\n",
      "   macro avg       0.53      0.55      0.52       309\n",
      "weighted avg       0.53      0.56      0.52       309\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evalutation\n",
    "\n",
    "# Calculate Confusion Matrix for POC dataset on DT Model\n",
    "cm = confusion_matrix(poc_y, y_pred_poc)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Reds_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test POC: {0}'.format(accuracy_score(poc_y, y_pred_poc))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nPOC Classification Report\\n\", classification_report(poc_y, y_pred_poc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "W Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.17      0.21       100\n",
      "           1       0.25      0.12      0.16       103\n",
      "           2       0.34      0.64      0.45       106\n",
      "\n",
      "    accuracy                           0.31       309\n",
      "   macro avg       0.29      0.31      0.27       309\n",
      "weighted avg       0.29      0.31      0.27       309\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evalutation\n",
    "\n",
    "# Calculate Confusion Matrix for W dataset on DT Model\n",
    "cm = confusion_matrix(w_y, y_pred_w)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Reds_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test W: {0}'.format(accuracy_score(w_y, y_pred_w))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nW Classification Report\\n\", classification_report(w_y, y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Trees Classifier performs fairly well for detecting incorrect wear of mask (with ~89-92% accuracy) or no mask wear (with ~80-84% accuracy) categories. However, across the different hyperparameter tuning models, it appears that it underperforms for classifying correct wear of face mask with an accuracy of ~70-76%. In fact, the ```UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.``` warning that is thrown several times in the hyperparameter tuning process for this classifier suggests that there are a few cases where label 2, or the `correct face mask` wear, is never predicted. In other words, given the true target values of the test set, y_test, the prediction class for `correctly worn face masks` is never predicted in y_pred for the model.\n",
    "\n",
    "A learning goal that arises in the hyperparameter tuning phase for this model is that 100% training accuracy (a.k.a. extreme overfitting) does not improve the model's ability to classify new information.\n",
    "\n",
    "### Bias Evaluation\n",
    "The Decision Trees model constructed above performed poorly for both bias evaluations, but surprisingly more so for white individuals (W) datset. In general terms, the overall performance of the model against these new instances of data reveals that our model is likely overfitting for the training dataset. It also might be likely that the images in which we trained our data on are distinctively different from the images from our bias datasets collection, and we might have to reconsider our approaches for overall feature selection, feature relevancy and data preprocessing measures.\n",
    "\n",
    "In regards to the extreme 20% discrepancy between the POC dataset's performance, and W dataset's performance, an important question arises from the integrity of our training dataset. Further examination is required to measure the differences between each dataset in comparison to out training datatset, but the performance metrics alone suggests that white individuals were not as properly represented in our dataset as people of color were. \n",
    "\n",
    "Nevertheless both performance metrics on this decision trees model performed very poorly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources Referenced for constructing this model:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
